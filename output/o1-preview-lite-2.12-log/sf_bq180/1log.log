2025-01-26 02:52:37 - openai._base_client - INFO - Retrying request to /chat/completions in 0.381371 seconds
2025-01-26 02:53:22 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com/openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-01-26 02:53:22 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:22 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:22 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:24 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-01-26 02:53:24 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:24 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:24 - root - INFO - SQL:
SELECT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Results:
sample_path
src/pyudev/_ctypeslib/__init__.py
networking_cisco/neutronclient/policyprofile.py
base_contact/__openerp__.py
GPy/testing/state_space_main_tests.py
esky/sudo/sudo_base.py
xlsxwriter/test/comparison/test_chart_column08.py
geomath/__init__.py
conda_manager/__init__.py
product_taxes_group/tests/test_product_taxes_group.py
newsfeed/migrations/0004_auto__chg_field_featuredsection_image.py
ulauncher/search/file_browser/FileBrowserMode.py
module/plugins/crypter/UploadableChFolder.py
lib/pegasus/python/Pegasus/service/base.py
rinoh/document.py
monasca_agent/collector/checks_d/postfix.py
keystone/tests/unit/identity/backends/test_ldap_common.py
corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py
registry/windows2012Users.py
poppy/storage/base/__init__.py
tests/mixins.py
scale/ingest/apps.py
memsource/api.py
hotbit/test/C6H6_cell_game.py
plexapi/myplex.py
tests/wizard/test_cookiestorage.py
cosmic-core/test/integration/testpaths/testpath_usage.py
public_plugins/help.py
tests/test_spec.py
kale/queue_selector.py
pyconjpbot/plugins/calc.py
bulbs/poll/managers.py
maininterface/settings.py
murano/cmd/cfapi.py
idtxl/estimators_cmi.py
src/script/anomalie_faux_positif.py
tests/test_graph_helpers.py
pygram/pg_threading.py
libraryusers/migrations/0002_libraryuser_books.py
webcrawler/utils/stdout.py
pam/__init__.py
wiggum/users/migrations/0008_user_external_service.py
alaudacli/execute.py
doc/source/conf.py
FontNote.glyphsPalette/Contents/Resources/FontNote.py
spirit/core/utils/markdown/block.py
tableloader/tableFunctions/blueprints.py
llvm_p86/codegen.py
doc/tutorials/examples/jython/swing/gui.py
tools/sqlmap/lib/utils/hashdb.py
ycmd/tests/server_utils_test.py
tools/sqlmap/plugins/generic/search.py
euca2ools/commands/autoscaling/putnotificationconfiguration.py
openedx/core/djangoapps/common_views/xblock.py
gemrb/GUIScripts/bg1/ImportFile.py
pyjswidgets/pyjamas/gmaps/Marker.py
conpot/helpers.py
tests/install_tests/test_utils.py
fuel/converters/ilsvrc2010.py
ngrinder-core/src/test/resources/test.py
examples/blink.py
clc/eucadmin/eucadmin/reportsrequest.py
nova/cmd/api_metadata.py
tests/checker/test_unknown.py
resources/lib/relativedelta.py
segments/hostname.py
regtests/go/class.py
tests/unit/test_req_file.py
crits/indicators/api.py
tests/test_logs.py
scripts/analyze_memdump.py
python/solutii/iulian_bute/search.py
password_policies/tests/__init__.py
python27/win32/Lib/site-packages/pycparser/c_ast.py
luigi_bigquery/config.py
lino/core/utils.py
utils.py
content/migrations/0024_auto_20160426_0830.py
gunnery/account/migrations/0002_auto__del_field_customuser_is_staff.py
mendeley/resources/groups.py
tests/url_parsing.py
make-estimation-spreadsheet.py
dynamic_forms/forms.py
scripts/encrypt.py
qa/ui_tests/test_routers.py
myconnectome/taskbehavior/mkfiles_task005.py
mcscf/test/test_c2h4.py
montanha/migrations/0011_auto__add_alternativelegislatorname__del_field_legislator_original_id.py
nova/tests/unit/virt/hyperv/test_block_device_manager.py
orchestra/models/__init__.py
example/simple_multiview.py
src/seagoatvision_ros/scripts/CapraVision/server/filters/implementation/yuv2bgr.py
neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py
venv/bin/createfontdatachunk.py
loafer/example/message_translator.py
matrixtoolkit/__init__.py
noggin/playbook/Formations.py
networking_mlnx/tests/unit/ml2/test_mechanism_sdn.py
pwatcher/mains/pwatcher.py
dlstats/fetchers/bis.py
pyperform/tools.py

2025-01-26 02:53:24 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:24 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:24 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:26 - snowflake.connector.cursor - INFO - Number of results in first chunk: 27
2025-01-26 02:53:26 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:26 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:26 - root - INFO - SQL:
SELECT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
Results:
sample_path
R/series.R
tests/testthat/test-normalizuj.R
books/Gelman_BDA2_ARM/doc/Book_Codes/Ch.25/25.0_Missing data in R and Bugs.R
R/newLonLat.R
checkDecodedFiles.R
src/R/model/multicontext_model_genData.R
test/impact_plot_test.R
tests/src/test/R/mget.R
R/getCensusApi.R
inst/ShinyStan/ui_files/model_code.R
src/test/scripts/applications/cspline/CsplineDS.R
src/library/base/R/lazyload.R
packages/utils/src/main/R/prompt.R
lib/perl/Genome/Model/Tools/EdgeR/FilterCountsFile.pm.R
examples/undocumented/r_modular/kernel_poly_modular.R
_ignore/benchmarkingNewEnvs.R
books/Gelman_BDA2_ARM/doc/arm2/chicks/chickens.R
shiny/trabalho/global.R
r_modules/analysisPackages/PLSR/inst/unitTests/test_PLSR.R
h2o-docs/src/booklets/v2_2015/source/R_Vignette_code_examples/r_import_file.R
h2o-r/tests/testdir_algos/gbm/runit_GBM_weights_gaussian.R
JASP-Engine/JASP/R/ttestbayesianonesample.R
src/library/utils/R/zip.R
src/extra/testr/filtered-test-suite/isloaded/tc_isloaded_1.R
src/extra/testr/filtered-test-suite/tabulate/tc_tabulate_3.R
src/extra/testr/filtered-test-suite/gettext/tc_gettext_5.R
R/genCov_trackViz.R

2025-01-26 02:53:26 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:26 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:26 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:27 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-01-26 02:53:27 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:28 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:28 - root - INFO - SQL:
SELECT DISTINCT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Results:
sample_path
doc/tutorials/examples/jython/swing/gui.py
ycmd/tests/server_utils_test.py
euca2ools/commands/autoscaling/putnotificationconfiguration.py
openedx/core/djangoapps/common_views/xblock.py
conpot/helpers.py
tests/test_logs.py
scripts/analyze_memdump.py
resources/lib/relativedelta.py
geonode/groups/models.py
src/_cffi_src/openssl/asn1.py
src/cwmp/tr/vendor/bup/cmd/daemon-cmd.py
mne/decoding/base.py
py/test/selenium/webdriver/remote/remote_firefox_profile_tests.py
common/test/acceptance/tests/lms/test_lms_problems.py
components/org.apache.stratos.python.cartridge.agent/src/main/python/cartridge.agent/cartridge.agent/modules/event/instance/status/events.py
direct/src/controls/ControlManager.py
py/testdir_single_jvm/test_exec2_operators4.py
examples/util/wordcount_hdfs.py
lib/jython/Lib/test/test_int.py
madcow/include/twisted/_version.py
plugin/snippets/clang_complete.py
tests/test_arsc.py
code/python/external/platform/darwin/numpy/matrixlib/tests/test_multiarray.py
python/phonenumbers/shortdata/region_YE.py
tools/chrome_proxy/common/inspector_network.py
python/main-classic/channels/filmpertutti.py
backend/db/base.py
tests/glyphs/AnnularWedge.py
venv/lib/python2.7/site-packages/flask/globals.py
osx_build/nefi2_osx_amd64_xcode_2015/site-packages/numpy_1.11/numpy/distutils/mingw32ccompiler.py
zippy/benchmarks/src/benchmarks/sympy/sympy/mpmath/visualization.py
crits/core/management/commands/get_duplicate_targets.py
pymatgen/io/feff/sets.py
client_lib/test/unit/test_commands_history.py
scipy/interpolate/tests/test_polyint.py
tests/test_stats.py
SimpleCV/Features/HaarLikeFeatureExtractor.py
lib/third/youtube_dl/extractor/roxwel.py
backend/db/local_client.py
networking_cisco/neutronclient/policyprofile.py
GPy/testing/state_space_main_tests.py
conda_manager/__init__.py
password_policies/tests/__init__.py
content/migrations/0024_auto_20160426_0830.py
myconnectome/taskbehavior/mkfiles_task005.py
mcscf/test/test_c2h4.py
nova/tests/unit/virt/hyperv/test_block_device_manager.py
tests/test_exchange.py
tests/features/environment.py
bctools/bc_disk_access_v2.py
grr/config/grr-response-server/setup.py
banner_grabber.py
meinheld/common.py
examples/gevent/poll.py
experimental/serengeti/IAAI/betaTest2.py
src/core/files.py
position_tagger.py
Modules/DNSScanner.py
editorconfig_gedit2.py
kademlia/protocol.py
HFH/Contentdisposition.py
analytical/templatetags/olark.py
runtests.py
test/tests/api/v2_0/nodes_tests.py
maec/utils/merge.py
tests/test_mesh_interp.py
simple_rest/utils/serializers.py
MR-OCP/MROCPdjango/computation/tests/eigs/check_eigs.py
pyphi/compute/big_phi.py
shmaplib/logger.py
treeio/services/api/tests.py
awlsim/core/instructions/insn_zr.py
example/PypeTest.py
chromium/src/third_party/WebKit/Tools/Scripts/webkitpy/tool/commands/stepsequence.py
Version-1.0/pyxiewps-ES-sin Aircrack.py
nbodykit/distributedarray.py
hazelcast/protocol/codec/replicated_map_entry_set_codec.py
tests/test_xml.py
src/braille_alphabets-activity/BrailleChar.py
wordpress_xmlrpc/methods/comments.py
monolithe/config.py
zippy/lib-python/3/test/test_socket.py
openelex/api/base.py
share/gscreen/skins/spartan/spartan_handler.py
win64-vc/2.76/scripts/modules/bl_i18n_utils/settings.py
module/plugins/crypter/UploadableChFolder.py
rinoh/document.py
keystone/tests/unit/identity/backends/test_ldap_common.py
corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py
registry/windows2012Users.py
public_plugins/help.py
tests/test_spec.py
kale/queue_selector.py
maininterface/settings.py
pygram/pg_threading.py
webcrawler/utils/stdout.py
pam/__init__.py
wiggum/users/migrations/0008_user_external_service.py
alaudacli/execute.py
FontNote.glyphsPalette/Contents/Resources/FontNote.py

2025-01-26 02:53:28 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:28 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:28 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:29 - snowflake.connector.cursor - INFO - Number of results in first chunk: 27
2025-01-26 02:53:29 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:30 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:30 - root - INFO - SQL:
SELECT DISTINCT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
Results:
sample_path
R/series.R
tests/testthat/test-normalizuj.R
R/newLonLat.R
checkDecodedFiles.R
src/R/model/multicontext_model_genData.R
test/impact_plot_test.R
R/getCensusApi.R
inst/ShinyStan/ui_files/model_code.R
src/library/base/R/lazyload.R
packages/utils/src/main/R/prompt.R
shiny/trabalho/global.R
r_modules/analysisPackages/PLSR/inst/unitTests/test_PLSR.R
src/test/scripts/applications/cspline/CsplineDS.R
lib/perl/Genome/Model/Tools/EdgeR/FilterCountsFile.pm.R
examples/undocumented/r_modular/kernel_poly_modular.R
_ignore/benchmarkingNewEnvs.R
books/Gelman_BDA2_ARM/doc/arm2/chicks/chickens.R
h2o-docs/src/booklets/v2_2015/source/R_Vignette_code_examples/r_import_file.R
h2o-r/tests/testdir_algos/gbm/runit_GBM_weights_gaussian.R
JASP-Engine/JASP/R/ttestbayesianonesample.R
src/library/utils/R/zip.R
src/extra/testr/filtered-test-suite/isloaded/tc_isloaded_1.R
books/Gelman_BDA2_ARM/doc/Book_Codes/Ch.25/25.0_Missing data in R and Bugs.R
tests/src/test/R/mget.R
src/extra/testr/filtered-test-suite/tabulate/tc_tabulate_3.R
src/extra/testr/filtered-test-suite/gettext/tc_gettext_5.R
R/genCov_trackViz.R

2025-01-26 02:53:30 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:30 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:30 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:32 - snowflake.connector.cursor - INFO - Number of results in first chunk: 13
2025-01-26 02:53:33 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:33 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:33 - root - INFO - SQL:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Results:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Business Applications
#    Copyright (C) 2013-TODAY OpenERP S.A. (<http://openerp.com>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

{
    'name': 'Contacts Management',
    'summary': u""[DEPRECATED] Manage your contacts separately"",
    'version': '8.0.2.0.0',
    'author': ""OpenERP SA,Odoo Community Association (OCA)"",
    'website': 'http://www.openerp.com',
    'category': 'Customer Relationship Management',
    'depends': [
        'partner_contact_birthdate',
        'partner_contact_in_several_companies',
        'partner_contact_nationality',
    ],
    'installable': False,
}
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1]

2025-01-26 02:53:33 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:33 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:33 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:35 - snowflake.connector.cursor - INFO - Number of results in first chunk: 9
2025-01-26 02:53:36 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:36 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:36 - root - INFO - SQL:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
Results:
Too long, hard cut:
content
"library(raster)
library(data.table)
library(microbenchmark)
library(SpaDES)

N=1e4
sim <- new.env(parent = .GlobalEnv)
sim <- new.env()
sim$landscapeDT = data.table(test=1:(N^2), hello = sample(1:(N^2),(N^2)))
sim$ras <- raster(x=extent(0,N,0,N), res=1)
sim$ras[] = sim$landscapeDT$test


landscapeDT = copy(sim$landscapeDT)
ras <- raster(x=extent(0,N,0,N), res=1)
ras[] = -sim$landscapeDT$test

vec <- getValues(ras)

ras2 <- 1:10

# Note return invisible empty ... means no copy is made. The object is actually modified in place
#  as long as it is the same name, i.e., sim, as the environment name
changeValDT  <- function(sim, index, val) {
  sim$landscapeDT[index,hello:=val]
  invisible()
}

changeValDTNoSim  <- function(sim, index, val) {
  landscapeDT[index,hello:=val]
  invisible()
}

changeValRas  <- function(sim, index, val) {
  sim$ras[index]  <- val
  invisible()
}

index=sample(N^2, 5); print(index)

# Note - exact same time, meaning no copying is happening
microbenchmark(times=2000,
               new=changeValDT(sim, index=index, val=index),
               old=#{landscape <- getGlobal(""landscape""); 
                landscapeDT[index,hello:=index],
               alt=changeValDTNoSim(sim, index=index, val=index)
               # assignGlobal(""landscape"")}
               )
print(sim$landscapeDT[index,])
print(landscapeDT[index,])
print(landscapeDT[index,])

# Note - exact same time, meaning no copying is happening
microbenchmark(times=10,
               changeValRas(sim, index, index),
               ras[index]<-index,
               vec[index] <- index)

sim = new.env()
microbenchmark(times=100,
               makeEnv={sim$ras <- ras; sim$landscape <- landscape},
               makeList={sim2=list(ras, landscape)})

names(sim$ras) <- ""Fires""
setColors(sim$ras) <- c(""white"", rev(heat.colors(9)))
sim$ras <- setValues(sim$ras, 1)

"
"chickens <- read.table (""chickens.dat"", header=T)
attach.all (chickens)
diff <- mean.control - mean.treated
se.diff <- sqrt (se.treated^2 + se.control^2)

postscript (""c:/books/multilevel/blackman1.ps"", horizontal=T, height=4, width=4.5)
plot (freq, diff, xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Est. treatment effect"", type=""n"",
      main=expression(""Estimates with statistical significance""), mgp=c(1.5,.5,0))
w <- 2.5
freq[freq==165] <- 165+c(-w,w)
freq[freq==180] <- 180+c(-w,w)
freq[freq==405] <- 405+c(-w,w)
pvalue <- 2*pt(-diff/se.diff,n.treated+n.control-2)
for (i in 1:nrow(chickens))
  polygon (freq[i] + c(-w,-w,w,w), c(diff[i],0,0,diff[i]),
           col=ifelse(pvalue[i]<.05,""black"",0), lwd=.5)
dev.off()

postscript (""c:/books/multilevel/blackman2.ps"", horizontal=T, height=4, width=4.5)
plot (range(freq), range(c(diff+se.diff,diff-se.diff)),
      xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Est. treatment effect"", type=""n"",
      main=expression(""Estimates"" %+-% ""standard errors""), mgp=c(1.5,.5,0))
abline (0,0,lty=2,lwd=.5)
points (freq, diff, pch=20)
for (i in 1:nrow(chickens))
  lines (rep(freq[i],2), diff[i]+se.diff[i]*c(-1,1), lwd=.5)
dev.off()

if (0){
plot (range(freq), range(c(mean.control+se.control,mean.control-se.control))-1,
      xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Estimated treatment effect"", type=""n"",
      main=expression(""Estimates"" %+-% ""standard errors""))
abline (0,0,lty=2,lwd=.5)
points (freq, mean.control-1, pch=20)
for (i in 1:nrow(chickens))
  lines (rep(freq[i],2), mean.control[i]+se.control[i]*c(-1,1)-1, lwd=.5)
}


y <- diff
J <- length(diff)
sigma.y <- se.diff
schools.data <- list (""J"", ""y"", ""sigma.y"")
schools.inits <- function()
  list (theta=rnorm(J,0,1), mu.theta=rnorm(1,0,100),
        sigma.theta=runif(1,0,100))
schools.parameters <- c(""theta"", ""mu.theta"", ""sigma.theta"", ""e.theta"", ""y.rep"")
# run in winbugs14
schools.sim <- bugs (schools.data, schools.inits, schools.parameters, ""schools.bug"", n.chains=3, n.iter=1000, version=1.4)
lambda.theta <- 1 - var (apply (e.theta, 2, mean)) / mean (apply (e.theta, 1, var))
print (lambda.theta)

theta.hat <- apply(theta,2,mean)
se.theta <- apply(theta,2,sd)
postscript (""c:/books/multilevel/blackman3.ps"", horizontal=T, height=4, width=4.5)
plot (range(freq), range(c(diff+se.diff,diff-se.diff)),
      xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Est. treatment effect"", type=""n"",
      main=expression(""Multilevel estimates"" %+-% ""standard errors""), mgp=c(1.5,.5,0))
abline (0,0,lty=2,lwd=.5)
points (freq, theta.hat, pch=20)
for (i in 1:nrow(chickens))
  lines (rep(freq[i],2), theta.hat[i]+se.theta[i]*c(-1,1), lwd=.5)
dev.off()


"
"library(sptrans)
olhovivo_login()
"
"#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you

2025-01-26 02:53:36 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:36 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:36 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:38 - snowflake.connector.cursor - INFO - Number of results in first chunk: 11
2025-01-26 02:53:39 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:39 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:40 - root - INFO - SQL:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import %'
   LIMIT 100;
Results:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    -------

2025-01-26 02:53:40 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:40 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:40 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:41 - snowflake.connector.cursor - INFO - Number of results in first chunk: 7
2025-01-26 02:53:41 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:41 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:42 - root - INFO - SQL:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R' AND "content" ILIKE '%library(%'
   LIMIT 100;
Results:
Too long, hard cut:
content
"library(raster)
library(data.table)
library(microbenchmark)
library(SpaDES)

N=1e4
sim <- new.env(parent = .GlobalEnv)
sim <- new.env()
sim$landscapeDT = data.table(test=1:(N^2), hello = sample(1:(N^2),(N^2)))
sim$ras <- raster(x=extent(0,N,0,N), res=1)
sim$ras[] = sim$landscapeDT$test


landscapeDT = copy(sim$landscapeDT)
ras <- raster(x=extent(0,N,0,N), res=1)
ras[] = -sim$landscapeDT$test

vec <- getValues(ras)

ras2 <- 1:10

# Note return invisible empty ... means no copy is made. The object is actually modified in place
#  as long as it is the same name, i.e., sim, as the environment name
changeValDT  <- function(sim, index, val) {
  sim$landscapeDT[index,hello:=val]
  invisible()
}

changeValDTNoSim  <- function(sim, index, val) {
  landscapeDT[index,hello:=val]
  invisible()
}

changeValRas  <- function(sim, index, val) {
  sim$ras[index]  <- val
  invisible()
}

index=sample(N^2, 5); print(index)

# Note - exact same time, meaning no copying is happening
microbenchmark(times=2000,
               new=changeValDT(sim, index=index, val=index),
               old=#{landscape <- getGlobal(""landscape""); 
                landscapeDT[index,hello:=index],
               alt=changeValDTNoSim(sim, index=index, val=index)
               # assignGlobal(""landscape"")}
               )
print(sim$landscapeDT[index,])
print(landscapeDT[index,])
print(landscapeDT[index,])

# Note - exact same time, meaning no copying is happening
microbenchmark(times=10,
               changeValRas(sim, index, index),
               ras[index]<-index,
               vec[index] <- index)

sim = new.env()
microbenchmark(times=100,
               makeEnv={sim$ras <- ras; sim$landscape <- landscape},
               makeList={sim2=list(ras, landscape)})

names(sim$ras) <- ""Fires""
setColors(sim$ras) <- c(""white"", rev(heat.colors(9)))
sim$ras <- setValues(sim$ras, 1)

"
"library(sptrans)
olhovivo_login()
"
"#!/usr/bin/env Rscript

library(edgeR)
library(getopt)

filterCountsFile <- function(inputFile, countsPerMillion, numSamples, outputFile) {
    counts <- read.table(inputFile, head=T, row.names=1)
    keep <- rowSums(cpm(counts)>countsPerMillion) >= numSamples
    output <- counts[keep,]
    write.table(output, outputFile,  quote=FALSE, sep=""\t"",
        row.names=TRUE, col.names=NA)
}

parseOptions <- function(optSpec) {
    opts <- getopt(optSpec)

    if (!is.null(opts$help)) {
        cat(getopt(optSpec, usage=TRUE))
        q(status=0)
    }

    required <- optSpec[optSpec[,3] == ""1"", 1]
    for (req in required) {
        if (is.null(opts[[req]])) {
            cat(paste(""Required option"", req, ""missing!\n""))
            q(status=1)
        }
    }

    opts
}

optSpec = matrix(c(
    ""help"", ""h"", 0, NA,
    ""input-file"", ""i"", 1, ""character"",
    ""counts-per-million"", ""c"", 1, ""integer"",
    ""num-samples"", ""n"", 1, ""integer"",
    ""output-file"", ""o"", 1, ""character""
    ), byrow=TRUE, ncol=4)

opts <- parseOptions(optSpec)

dge <- filterCountsFile(opts$`input-file`, opts$`counts-per-million`, opts$`num-samples`, opts$`output-file`)
"
"library(shogun)

fm_train_real <- t(as.matrix(read.table('../data/fm_train_real.dat')))
fm_test_real <- t(as.matrix(read.table('../data/fm_test_real.dat')))

# poly
print('Poly')

feats_train <- RealFeatures()
dummy <- feats_train$set_feature_matrix(fm_train_real)
feats_test <- RealFeatures()
dummy <- feats_test$set_feature_matrix(fm_test_real)
degree <- as.integer(4)
inhomogene <- FALSE

kernel <- PolyKernel(
	feats_train, feats_train, degree, inhomogene)

km_train <- kernel$get_kernel_matrix()
dump <- kernel$init(feats_train, feats_test)
km_test <- kernel$get_kernel_matrix()
"
"library(PLSR)
library(RUnit)
library(DEMOdz)
library(TCGAgbm)
Sys.setlocale(""LC_ALL"", ""C"")

if(!exists(""marker.genes.545"")){
    print(load(system.file(package=""TCGAgbm"", ""extdata"", ""genesets.RData"")))
    marker.genes.545 <- genesets$marker.genes.545
    tcga.GBM.classifiers <- genesets$tcga.GBM.classifiers
    }
#----------------------------------------------------------------------------------------------------
runTests <- function()
{
  test_constructor()
  test_summarizePatientNumericFactors()
  test_summarizePatientNumericFactors_TCGAgbm_poorPatientOverlap()
  test_summarizePatientNumericFactors_DEMOdz()
  test_createClassificationMatrix()
  test_createClassificationMatrix.1factor()
  test_createClassificationMatrix.2factors()
  test_createBigClassificationMatrix()
  test_calculateTiny.ageDxDemo()
  #test_calculateTiny.ageDxAndSurvival.demo()
  test_calculateSmall.ageDxOnly()
  test_calculateSmall.survivalOnly()
  test_calculateSmall()
  test_calculateBig()
  test_changeDataSetsAndCalculateSmall()

} # runTests
#----------------------------------------------------------------------------------------------------
test_constructor = function()
{
   printf(""--- test_constructor"")
   demoDz <- DEMOdz()
   mrna.datasets <- sort(grep(""mtx.mrna"", manifest(demoDz)$

2025-01-26 02:53:42 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:42 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:42 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:43 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-01-26 02:53:43 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:43 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:43 - root - INFO - SQL:
SELECT "sample_repo_name", "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Results:
Too long, hard cut:
sample_repo_name,sample_path
pyudev/pyudev,src/pyudev/_ctypeslib/__init__.py
CiscoSystems/networking-cisco,networking_cisco/neutronclient/policyprofile.py
OCA/partner-contact,base_contact/__openerp__.py
SheffieldML/GPy,GPy/testing/state_space_main_tests.py
cloudmatrix/esky,esky/sudo/sudo_base.py
jmcnamara/XlsxWriter,xlsxwriter/test/comparison/test_chart_column08.py
vmesel/GeoMath,geomath/__init__.py
spyder-ide/conda-manager,conda_manager/__init__.py
grap/odoo-addons-misc,product_taxes_group/tests/test_product_taxes_group.py
openfun/fun-apps,newsfeed/migrations/0004_auto__chg_field_featuredsection_image.py
Ulauncher/Ulauncher,ulauncher/search/file_browser/FileBrowserMode.py
dischinator/pyload,module/plugins/crypter/UploadableChFolder.py
pegasus-isi/pegasus,lib/pegasus/python/Pegasus/service/base.py
brechtm/rinohtype,rinoh/document.py
openstack/monasca-agent,monasca_agent/collector/checks_d/postfix.py
openstack/keystone,keystone/tests/unit/identity/backends/test_ldap_common.py
dimagi/commcare-hq,corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py
SekoiaLab/Fastir_Collector,registry/windows2012Users.py
openstack/poppy,poppy/storage/base/__init__.py
praus/shapy,tests/mixins.py
ngageoint/scale,scale/ingest/apps.py
gengo/memsource-wrap,memsource/api.py
pekkosk/hotbit,hotbit/test/C6H6_cell_game.py
mjs7231/python-plexapi,plexapi/myplex.py
django/django-formtools,tests/wizard/test_cookiestorage.py
MissionCriticalCloud/cosmic,cosmic-core/test/integration/testpaths/testpath_usage.py
gradiuscypher/discord_gradiusbot,public_plugins/help.py
rhosqeauto/InfraRed,tests/test_spec.py
Nextdoor/ndkale,kale/queue_selector.py
pyconjp/pyconjpbot,pyconjpbot/plugins/calc.py
theonion/django-bulbs,bulbs/poll/managers.py
semiautomaticgit/SemiAutomaticClassificationPlugin,maininterface/settings.py
openstack/murano,murano/cmd/cfapi.py
pwollstadt/IDTxl,idtxl/estimators_cmi.py
lprat/AEE,src/script/anomalie_faux_positif.py
harrymvr/absorbing-centrality,tests/test_graph_helpers.py
RedXBeard/pygram,pygram/pg_threading.py
jacinda/pycon_library,libraryusers/migrations/0002_libraryuser_books.py
mrafayaleem/simple-crawler,webcrawler/utils/stdout.py
MartinPyka/Parametric-Anatomical-Modeling,pam/__init__.py
qdqmedia/wiggum,wiggum/users/migrations/0008_user_external_service.py
alaudacloud/alauda-CLI,alaudacli/execute.py
openstack/fuel-plugin-midonet,doc/source/conf.py
mekkablue/NotePalettes,FontNote.glyphsPalette/Contents/Resources/FontNote.py
nitely/Spirit,spirit/core/utils/markdown/block.py
fuzzysteve/yamlloader,tableloader/tableFunctions/blueprints.py
john-tornblom/llvm-p86,llvm_p86/codegen.py
hydralabs/pyamf,doc/tutorials/examples/jython/swing/gui.py
golismero/golismero,tools/sqlmap/lib/utils/hashdb.py
Valloric/ycmd,ycmd/tests/server_utils_test.py
golismero/golismero,tools/sqlmap/plugins/generic/search.py
eucalyptus/euca2ools,euca2ools/commands/autoscaling/putnotificationconfiguration.py
edx/edx-platform,openedx/core/djangoapps/common_views/xblock.py
gemrb/gemrb,gemrb/GUIScripts/bg1/ImportFile.py
pyjs/pyjs,pyjswidgets/pyjamas/gmaps/Marker.py
mushorg/conpot,conpot/helpers.py
pfnet/chainer,tests/install_tests/test_utils.py
mila-udem/fuel,fuel/converters/ilsvrc2010.py
naver/ngrinder,ngrinder-core/src/test/resources/test.py
jadonk/bone101,examples/blink.py
eucalyptus/eucalyptus,clc/eucadmin/eucadmin/reportsrequest.py
openstack/nova,nova/cmd/api_metadata.py
wummel/linkchecker,tests/checker/test_unknown.py
robweber/xbmcbackup,resources/lib/relativedelta.py
milkbikis/powerline-shell,segments/hostname.py
rusthon/Rusthon,regtests/go/class.py
pypa/pip,tests/unit/test_req_file.py
MITRECND/crits,crits/indicators/api.py
nvbn/thefuck,tests/test_logs.py
wummel/linkchecker,scripts/analyze_memdump.py
alexandrucoman/labs,python/solutii/iulian_bute/search.py
tarak/django-password-policies,password_policies/tests/__init__.py
aliyun/oss-ftp,python27/win32/Lib/site-packages/pycparser/c_ast.py
hakobera/luigi-bigquery,luigi_bigquery/config.py
lsaffre/lino,lino/core/utils.py
Nymphet/sexinsex-crawler,utils.py
djangogirlscodecamp/lightandleadership,content/migrations/0024_auto_20160426_0830.py
gunnery/gunnery,gunnery/account/migrations/0002_auto__del_field_customuser_is_staff.py
Mendeley/mendeley-python-sdk,mendeley/resources/groups.py
jvanasco/metadata_parser,tests/url_parsing.py
mhl/github-issues-scripts,make-estimation-spreadsheet.py
MarkusH/django-dynamic-forms,dynamic_forms/forms.py
czcorpus/kontext,scripts/encrypt.py
paypal/aurora,qa/ui_tests/test_routers.py
poldrack/myconnectome,myconnectome/taskbehavior/mkfiles_task005.py
sunqm/pyscf,mcscf/test/test_c2h4.py
olhoneles/olhoneles,montanha/migrations/0011_auto__add_alternativelegislatorname__del_field_legislator_original_id.py
openstack/nova,nova/tests/unit/virt/hyperv/test_block_device_manager.py
unlimitedlabs/orchestra,orchestra/models/__init__.py
tu-rbo/concarne,example/simple_multiview.py
clubcapra/Ibex,src/seagoatvision_ros/scripts/CapraVision/server/filters/implementation/yuv2bgr.py
openstack/

2025-01-26 02:53:43 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:43 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:43 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:45 - snowflake.connector.cursor - INFO - Number of results in first chunk: 18
2025-01-26 02:53:46 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:46 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:47 - root - INFO - SQL:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%from % import %'
    LIMIT 100;
Results:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    -------

2025-01-26 02:53:47 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:47 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:47 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:48 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-01-26 02:53:48 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:48 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:48 - root - INFO - SQL:
SELECT DISTINCT "sample_repo_name"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
Results:
sample_repo_name
cloudmatrix/esky
vmesel/GeoMath
lsaffre/lino
gunnery/gunnery
jvanasco/metadata_parser
poldrack/myconnectome
olhoneles/olhoneles
openstack/nova
Nymphet/sexinsex-crawler
D-L/SimpleBookMarks
grundgruen/powerline
omab/psa-recovery
n3ko1/WrapMap
google/grr
DarkFenX/Pyfa
rocky/python3-trepan
piiswrong/dec
openconnectome/m2g
RealTimeWeb/blockpy
funkandwagnalls/pythonpentest
pyQode/pyqode.core
exaile/exaile
openstack/monasca-agent
feuervogel/django-taggit-templatetags
hpcugent/hanythingondemand
wreckage/django-happenings
openstack/rack
alexforencich/python-ivi
udp/json-parser
maxcutler/python-wordpress-xmlrpc
ejeschke/ginga
LinuxCNC/linuxcnc
networkx/networkx
drvink/epanos
wmayner/pyphi
mbuesch/awlsim
espadrine/opera
tgrosinger/aenea-grammars
openstack/cinder
ceph/ceph-installer
croach/django-simple-rest
svpcom/hyperloglog
dropbox/changes
openstack/python-neutronclient
OpenBazaar/OpenBazaar-Server
bdoin/GCompris
grap/odoo-addons-misc
Ulauncher/Ulauncher
pegasus-isi/pegasus
openstack/keystone
SekoiaLab/Fastir_Collector
openstack/murano
harrymvr/absorbing-centrality
jacinda/pycon_library
MartinPyka/Parametric-Anatomical-Modeling
qdqmedia/wiggum
openstack/fuel-plugin-midonet
alaudacloud/alauda-CLI
john-tornblom/llvm-p86
clubcapra/Ibex
openstack/neutron-vpnaas
cujomalainey/matrixtoolkit
openstack/networking-mlnx
Widukind/dlstats
lobocv/pyperform
jordens/rayopt
openstack/castellan
anoduck/recon-ng
OpenCanada/website
egrcc/zhihu-python
ShenNoether/MiniNero
paulo-romano/django-admin-gentelella
openstack/fuel-plugin-detach-rabbitmq
dkkline/EventManager
embedly/embedly-python
devilry/devilry-django
wbond/certvalidator
pingali/dgit
openstack/barbican
pior/caravan
tethysplatform/tethys
openstack/cloudkitty
rice-apps/rice-elections
danvk/oldnyc
watsonpy/watson-framework
taolei87/rcnn
tibonihoo/wateronmars
01org/qmsi
unlimitedlabs/orchestra
OpenTrading/OpenTrader
mekkablue/Glyphs-Scripts
317070/kaggle-heart
ronf/asyncssh
pjdietz/rester-sublime-http-client
globocom/GloboNetworkAPI-client-python
openstack/vitrage
hellysmile/django-redis-sessions-fork
getsentry/sentry-auth-google
hydralabs/pyamf
golismero/golismero

2025-01-26 02:53:48 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:48 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:48 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:50 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-01-26 02:53:50 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:50 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:50 - root - INFO - SQL:
SELECT "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
Results:
size
6556
2189
3459
1445
17043
17923
2535
23052
2807
473
951
4259
975
1395
1448
44812
3942
1636
184
285
638
27648
775
11355
1640
125539
240
4015
5311
761
590
18432
2147
14896
9381
5214
544
483
332
3519
451
2632
2736
8277
5111
3718
73117
7005
5349
8333
26113
2276
1057
2289
1138
1037
317
22903
317
203
2058
1654
2887
17115
836
430
22259
6933
478
3961
577
226
24133
1739
26622
669
1320
3528
2610
1537
4499
2101
385
3835
1681
1937
12907
13943
1086
8698
984
65273
600
372
50
5259
15991
227
18180
4049

2025-01-26 02:53:50 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:50 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:50 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:51 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-01-26 02:53:51 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:52 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:52 - root - INFO - SQL:
SELECT "sample_path", "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "size" > 1024
    LIMIT 100;
Results:
sample_path,size
product_taxes_group/tests/test_product_taxes_group.py,6556
newsfeed/migrations/0004_auto__chg_field_featuredsection_image.py,2189
ulauncher/search/file_browser/FileBrowserMode.py,3459
module/plugins/crypter/UploadableChFolder.py,1445
lib/pegasus/python/Pegasus/service/base.py,17043
rinoh/document.py,17923
monasca_agent/collector/checks_d/postfix.py,2535
keystone/tests/unit/identity/backends/test_ldap_common.py,23052
corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py,2807
tests/mixins.py,4259
networking_cisco/neutronclient/policyprofile.py,1395
base_contact/__openerp__.py,1448
GPy/testing/state_space_main_tests.py,44812
esky/sudo/sudo_base.py,3942
xlsxwriter/test/comparison/test_chart_column08.py,1636
python27/win32/Lib/site-packages/pycparser/c_ast.py,24133
luigi_bigquery/config.py,1739
lino/core/utils.py,26622
content/migrations/0024_auto_20160426_0830.py,1320
gunnery/account/migrations/0002_auto__del_field_customuser_is_staff.py,3528
mendeley/resources/groups.py,2610
tests/url_parsing.py,1537
make-estimation-spreadsheet.py,4499
dynamic_forms/forms.py,2101
qa/ui_tests/test_routers.py,3835
myconnectome/taskbehavior/mkfiles_task005.py,1681
mcscf/test/test_c2h4.py,1937
montanha/migrations/0011_auto__add_alternativelegislatorname__del_field_legislator_original_id.py,12907
nova/tests/unit/virt/hyperv/test_block_device_manager.py,13943
memsource/api.py,27648
plexapi/myplex.py,11355
tests/wizard/test_cookiestorage.py,1640
cosmic-core/test/integration/testpaths/testpath_usage.py,125539
tests/test_spec.py,4015
kale/queue_selector.py,5311
maininterface/settings.py,18432
murano/cmd/cfapi.py,2147
idtxl/estimators_cmi.py,14896
src/script/anomalie_faux_positif.py,9381
tests/test_graph_helpers.py,5214
pam/__init__.py,3519
alaudacli/execute.py,2632
doc/source/conf.py,2736
FontNote.glyphsPalette/Contents/Resources/FontNote.py,8277
spirit/core/utils/markdown/block.py,5111
tableloader/tableFunctions/blueprints.py,3718
llvm_p86/codegen.py,73117
doc/tutorials/examples/jython/swing/gui.py,7005
tools/sqlmap/lib/utils/hashdb.py,5349
ycmd/tests/server_utils_test.py,8333
tools/sqlmap/plugins/generic/search.py,26113
euca2ools/commands/autoscaling/putnotificationconfiguration.py,2276
openedx/core/djangoapps/common_views/xblock.py,1057
gemrb/GUIScripts/bg1/ImportFile.py,2289
pyjswidgets/pyjamas/gmaps/Marker.py,1138
conpot/helpers.py,1037
fuel/converters/ilsvrc2010.py,22903
clc/eucadmin/eucadmin/reportsrequest.py,2058
nova/cmd/api_metadata.py,1654
tests/checker/test_unknown.py,2887
resources/lib/relativedelta.py,17115
tests/unit/test_req_file.py,22259
crits/indicators/api.py,6933
scripts/analyze_memdump.py,3961
orchestra/models/__init__.py,1086
example/simple_multiview.py,8698
neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py,65273
noggin/playbook/Formations.py,5259
networking_mlnx/tests/unit/ml2/test_mechanism_sdn.py,15991
dlstats/fetchers/bis.py,18180
pyperform/tools.py,4049
geqe-ml/testModel.py,7175
rayopt/test/test_yaml.py,2027
castellan/key_manager/__init__.py,1205
pycouchdb/utils.py,3947
modules/exploitation/injection/xpath_bruter.py,6925
changes/buildsteps/base.py,6529
simple_sso/sso_server/migrations/0001_initial.py,1850
anubis/filters.py,7317
tests/test_global_fit.py,1673
test.py,11268
regparser/notice/diff.py,26343
src/user.py,1268
tests/test_exchange.py,3114
list_tree_and_table/listview/simple_listview_with_icon_filter.py,3519
tests/features/environment.py,2506
Modules/DNSScanner.py,1473
bctools/bc_disk_access_v2.py,62274
grr/config/grr-response-server/setup.py,3376
CGATPipelines/pipeline_docs/pipeline_intervals/trackers/Annotations.py,4641
service/port.py,28906
caffe/examples/web_demo/app.py,7659
tools/demo_server/test/util.py,6514
kademlia/protocol.py,4605
books/Introduction_to_Statistics_using_Python/Code3/fig_PDF.py,1243
packages/dtipreproc/parse_b.py,3071
lino/modlib/countries/mixins.py,8110
banner_grabber.py,2340
test/test_panels/test_line_nbr.py,1630
examples/gevent/poll.py,1153

2025-01-26 02:53:52 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:52 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:52 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:54 - snowflake.connector.cursor - INFO - Number of results in first chunk: 5
2025-01-26 02:53:55 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:55 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:55 - root - INFO - SQL:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import numpy%'
    LIMIT 100;
Results:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    tangent: float
        Factor with which independent variable is multiplied in linear equation.
    add_term: float
        Additive term in linear equation.
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    linear_function = lambda xx:  tangent*xx + add_term
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = linear_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points

def generate_brownian_data(x_points=None, kernel_var = 2.0, noise_var = 2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Generate brownian data - data from Brownian motion.
    First point is always 0, and \Beta(0) = 0  - standard conditions for Brownian motion.           
           
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    variance: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
      
    """"""    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)
        if x_points[0] != 0:
            x_points[0] = 0
    
    y_points = np.zeros( (points_num,) )
    for i in range(1, points_num):
        noise = np.random.randn() * np.sqrt(kernel_var * (x_points[i] - x_points[i-1]))
        y_points[i] = y_points[i-1] + noise
    
    y_points += np.random.randn( len(x_points) ) * np.sqrt(noise_var)
    
    return x_points, y_points   
        
def generate_linear_plus_sin(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
              

2025-01-26 02:53:55 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:55 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:55 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:57 - snowflake.connector.cursor - INFO - Number of results in first chunk: 3
2025-01-26 02:53:57 - snowflake.connector.connection - INFO - closed
2025-01-26 02:53:57 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:53:57 - root - INFO - SQL:
SELECT "language", COUNT(*) AS "script_count"
    FROM (
        SELECT CASE
            WHEN "sample_path" ILIKE '%.py' THEN 'Python'
            WHEN "sample_path" ILIKE '%.R' THEN 'R'
            ELSE 'Other'
        END AS "language"
        FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    ) AS script_languages
    GROUP BY "language"
    LIMIT 100;
Results:
language,script_count
Other,23516
Python,743
R,27

2025-01-26 02:53:57 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:53:57 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:53:57 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:53:59 - snowflake.connector.cursor - INFO - Number of results in first chunk: 11
2025-01-26 02:54:00 - snowflake.connector.connection - INFO - closed
2025-01-26 02:54:00 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:54:00 - root - INFO - SQL:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND ("content" ILIKE '%import %' OR "content" ILIKE '%from % import %')
    LIMIT 100;
Results:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    -------

2025-01-26 02:54:00 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:54:00 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:54:00 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:54:02 - snowflake.connector.cursor - INFO - Number of results in first chunk: 2
2025-01-26 02:54:02 - snowflake.connector.connection - INFO - closed
2025-01-26 02:54:02 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:54:02 - root - INFO - SQL:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.R' AND "content" ILIKE '%require(%'
    LIMIT 100;
Results:
Too long, hard cut:
content
"setwd(normalizePath(dirname(R.utils::commandArgs(asValues=TRUE)$""f"")))
source(""../../../scripts/h2o-r-test-setup.R"")
### This tests observation weights in glm ######




test_weights_by_row_duplication <- function() {
  
  require(testthat)
  
  #create data
  print(""create synthetic data with a numeric outcome"")
  set.seed(45541)
  n <- 100  #Number of training observations (also nrow(test) = n)
  p <- 20  #Number of features
  x <- matrix(rnorm(n*p), n, p)
  y <- rnorm(n)
  
  # Training data with weights
  # draw some random weights ~ Poisson, add 'x1' weight col and y to df, hdf
  set.seed(1234)
  x1 <- rpois(n, rep(2, n)) + 1  #Random integer-valued (>=1) weights
  df <- data.frame(x, x1, y)  #design matrix with weight and outcome cols
  hdf <- as.h2o(df, destination_frame = ""hdf"")  #for h2o
  
  # Training data (weights == 1.0 with repeated rows instead of weights)
  rep_idxs <- unlist(sapply(1:n, function(i) rep(i, df$x1[i])))
  rdf <- df[rep_idxs,]  #repeat rows
  rdf$x1 <- 1  #set weights back to 1.0
  rhdf <- as.h2o(rdf, destination_frame = ""rhdf"")  #for h2o
  
  ## for glmnet
  #df <- as.matrix(df)
  #rdf <- as.matrix(rdf)
  
  # Test data
  set.seed(2641)
  newx <- matrix(rnorm(n*p), n, p)
  newy <- rnorm(n)
  
  x1 <- rep(1, n)
  valid1 <- data.frame(newx, x1, y = newy)
  val1 <- as.h2o(valid1, destination_frame = ""val1"")
  valid1 <- as.matrix(valid1)
  
  print(""build models with weights vs repeated rows with h2o and lambda!=0"")
  hh1 <- h2o.gbm(x = 1:20, y = ""y"", 
                 training_frame = hdf, 
                 validation_frame = val1, 
                 ntrees = 50, 
                 weights_column = ""x1"")
  hh2 <- h2o.gbm(x = 1:20, y = ""y"", 
                 training_frame = rhdf, 
                 validation_frame = val1,
                 ntrees = 50, 
                 weights_column = ""x1"")
  
  print(""compare results"")
  expect_equal(hh1@model$training_metrics@metrics$MSE, 
               hh2@model$training_metrics@metrics$MSE,
               tolerance = 1e-6)
  expect_equal(hh1@model$training_metrics@metrics$r2, 
               hh2@model$training_metrics@metrics$r2,
               tolerance = 1e-6)

  expect_equal(hh1@model$validation_metrics@metrics$MSE,
               hh2@model$validation_metrics@metrics$MSE,
               tolerance = 1e-6)
  expect_equal(hh1@model$validation_metrics@metrics$r2,
               hh2@model$validation_metrics@metrics$r2,
               tolerance = 1e-6)
  
    
  #predictions
  print(""compare predictions"")
  ph1 <- as.data.frame(h2o.predict(object = hh1, newdata = val1))
  ph2 <- as.data.frame(h2o.predict(object = hh2, newdata = val1))
  mse1 <- mean((ph1$predict - newy)^2)
  mse2 <- mean((ph2$predict - newy)^2)
  #expect_equal(mse1, mse2)  #1.49 - 1.46 == 0.0291
  
  
  
}


doTest(""GBM weight Test: GBM w/ weights test by row duplication"", test_weights_by_row_duplication)
"
"## This script checks whether the reads in each splitted file belong to the same barcode
## and whether the file name contains the corresponding sample id name.
## Note, this script is a memory hog. 
## It was used to check the idemp output for one of our miseq runs.
##source(""http://bioconductor.org/biocLite.R"")
##biocLite(""ShortRead"")
require(ShortRead)

#### Files original and decoded ####
barcodeFile=""barcode_sample.txt""
I1File=""~/projects/141104_M03249_0008_000000000-ABY6R/Data/Intensities/BaseCalls/Undetermined_S0_L001_I1_001.fastq.gz""
R1File=""~/projects/141104_M03249_0008_000000000-ABY6R/Data/Intensities/BaseCalls/Undetermined_S0_L001_R1_001.fastq.gz"" 
R2File=""~/projects/141104_M03249_0008_000000000-ABY6R/Data/Intensities/BaseCalls/Undetermined_S0_L001_R2_001.fastq.gz""
decodedFile=list.files(""./"", pattern=""*.fastq.gz$"")

#### Read in barcode table, sequence names and barcodes ####
firstLine=readLines(""barcode_sample.txt"",1)
barcodeTable=read.table(barcodeFile, header=grepl(""arcode"", firstLine))
### Read in seqquence names and barcodes ###
barcodeReads=readFastq(I1File)
I1Names=unname(sapply(as.character(id(barcodeReads)), function(x) (strsplit(x,"" "")[[1]][1] ) ) )
I1Barcodes=as.character(sread(barcodeReads))

#### Loop through decoded files ####
for( i in 1:length(decodedFile) ) {
  cat(i, "" of "", length(decodedFile), ""\n"")
  cat(decodedFile[i],""\n"")
  decodedReads=readFastq(decodedFile[i])
  seqNames=unname(sapply(as.character(id(decodedReads)), function(x) (strsplit(x,"" "")[[1]][1] ) ) )
  seqBarcodes=as.character(sread(decodedReads))
  
  idx=match(seqNames, I1Names)
  #table(I1Barcodes[idx])
  #sort(table(I1Barcodes[idx]), decreasing=T)
  bctable=sort(table(I1Barcodes[idx]), decreasing=T)
  if ( length(bctable)> 1000 ) {
    message(length(bctable), "" barcodes found out of "", length(seqNames), "" reads."") 
  }
  if ( length( grep(names(bctable)[1], barcodeTable[,1]) )==0 ) {
    message(""most frequent barcode "",names(bctable)[1], "" not matched."") 
    next
  }
  if ( length(bctable)> 1000 ) n

2025-01-26 02:54:02 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:54:02 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:54:02 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:54:04 - snowflake.connector.cursor - INFO - Number of results in first chunk: 3
2025-01-26 02:54:04 - snowflake.connector.connection - INFO - closed
2025-01-26 02:54:04 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:54:04 - root - INFO - SQL:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import pandas%' AND "content" ILIKE '%import numpy%'
    LIMIT 100;
Results:
Too long, hard cut:
content
"import os
import time
import cPickle
import datetime
import logging
import flask
import werkzeug
import optparse
import tornado.wsgi
import tornado.httpserver
import numpy as np
import pandas as pd
from PIL import Image as PILImage
import cStringIO as StringIO
import urllib
import caffe
import exifutil

REPO_DIRNAME = os.path.abspath(os.path.dirname(__file__) + '/../..')
UPLOAD_FOLDER = '/tmp/caffe_demos_uploads'
ALLOWED_IMAGE_EXTENSIONS = set(['png', 'bmp', 'jpg', 'jpe', 'jpeg', 'gif'])

# Obtain the flask app object
app = flask.Flask(__name__)


@app.route('/')
def index():
    return flask.render_template('index.html', has_result=False)


@app.route('/classify_url', methods=['GET'])
def classify_url():
    imageurl = flask.request.args.get('imageurl', '')
    try:
        string_buffer = StringIO.StringIO(
            urllib.urlopen(imageurl).read())
        image = caffe.io.load_image(string_buffer)

    except Exception as err:
        # For any exception we encounter in reading the image, we will just
        # not continue.
        logging.info('URL Image open error: %s', err)
        return flask.render_template(
            'index.html', has_result=True,
            result=(False, 'Cannot open image from URL.')
        )

    logging.info('Image: %s', imageurl)
    result = app.clf.classify_image(image)
    return flask.render_template(
        'index.html', has_result=True, result=result, imagesrc=imageurl)


@app.route('/classify_upload', methods=['POST'])
def classify_upload():
    try:
        # We will save the file to disk for possible data collection.
        imagefile = flask.request.files['imagefile']
        filename_ = str(datetime.datetime.now()).replace(' ', '_') + \
            werkzeug.secure_filename(imagefile.filename)
        filename = os.path.join(UPLOAD_FOLDER, filename_)
        imagefile.save(filename)
        logging.info('Saving to %s.', filename)
        image = exifutil.open_oriented_im(filename)

    except Exception as err:
        logging.info('Uploaded image open error: %s', err)
        return flask.render_template(
            'index.html', has_result=True,
            result=(False, 'Cannot open uploaded image.')
        )

    result = app.clf.classify_image(image)
    return flask.render_template(
        'index.html', has_result=True, result=result,
        imagesrc=embed_image_html(image)
    )


def embed_image_html(image):
    """"""Creates an image embedded in HTML base64 format.""""""
    image_pil = PILImage.fromarray((255 * image).astype('uint8'))
    image_pil = image_pil.resize((256, 256))
    string_buf = StringIO.StringIO()
    image_pil.save(string_buf, format='png')
    data = string_buf.getvalue().encode('base64').replace('\n', '')
    return 'data:image/png;base64,' + data


def allowed_file(filename):
    return (
        '.' in filename and
        filename.rsplit('.', 1)[1] in ALLOWED_IMAGE_EXTENSIONS
    )


class ImagenetClassifier(object):
    default_args = {
        'model_def_file': (
            '{}/models/bvlc_reference_caffenet/deploy.prototxt'.format(REPO_DIRNAME)),
        'pretrained_model_file': (
            '{}/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'.format(REPO_DIRNAME)),
        'mean_file': (
            '{}/python/caffe/imagenet/ilsvrc_2012_mean.npy'.format(REPO_DIRNAME)),
        'class_labels_file': (
            '{}/data/ilsvrc12/synset_words.txt'.format(REPO_DIRNAME)),
        'bet_file': (
            '{}/data/ilsvrc12/imagenet.bet.pickle'.format(REPO_DIRNAME)),
    }
    for key, val in default_args.iteritems():
        if not os.path.exists(val):
            raise Exception(
                ""File for {} is missing. Should be at: {}"".format(key, val))
    default_args['image_dim'] = 227
    default_args['raw_scale'] = 255.
    default_args['gpu_mode'] = False

    def __init__(self, model_def_file, pretrained_model_file, mean_file,
                 raw_scale, class_labels_file, bet_file, image_dim, gpu_mode):
        logging.info('Loading net and associated files...')
        self.net = caffe.Classifier(
            model_def_file, pretrained_model_file,
            image_dims=(image_dim, image_dim), raw_scale=raw_scale,
            mean=np.load(mean_file), channel_swap=(2, 1, 0), gpu=gpu_mode
        )

        with open(class_labels_file) as f:
            labels_df = pd.DataFrame([
                {
                    'synset_id': l.strip().split(' ')[0],
                    'name': ' '.join(l.strip().split(' ')[1:]).split(',')[0]
                }
                for l in f.readlines()
            ])
        self.labels = labels_df.sort('synset_id')['name'].values

        self.bet = cPickle.load(open(bet_file))
        # A bias to prefer children nodes in single-chain paths
        # I am setting the value to 0.1 as a quick, simple model.
        # We could use better psychological models here...
        self.bet['infogain'] -= np.array(self.bet['preferences']) * 0.1

    def 

2025-01-26 02:54:04 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:54:04 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:54:04 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:54:06 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-01-26 02:54:06 - snowflake.connector.connection - INFO - closed
2025-01-26 02:54:06 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:54:06 - root - INFO - SQL:
SELECT SPLIT_PART("content", '\n', 1) AS "first_line"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
Results:
first_line
# -*- coding: utf-8 -*-
"# Copyright 2015 Cisco Systems, Inc."
# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
"#  Copyright (c) 2009-2010, Cloud Matrix Pty. Ltd."
###############################################################################
""""""""
# -*- coding:utf-8 -*-
#!/usr/bin/env python
from password_policies.tests.forms import *
"#-----------------------------------------------------------------"
import os
# Copyright 2010-2016 Luc Saffre
"from urllib import request, parse"
# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
"from mendeley.models.groups import Group, GroupMember"
import metadata_parser
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#!/usr/bin/python
from uibasetest import *
""""""""
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright (c) 2016 Cloudbase Solutions Srl
# vim: set encoding=utf-8
#coding: utf8
from unittest import TestCase
#!/usr/bin/env python
# -*- coding: utf-8 -*-
try:
"from django.conf.urls import patterns, url"
# code by n3ko1 2015 - @n3ko101
#!/usr/bin/python3
#!/usr/bin/env python
import os
from editorconfig_plugin.gedit2 import *
#===============================================================================
#!/usr/bin/env python
import os
#!/usr/bin/python
from sklearn_pmml.convert import IntegerCategoricalFeature
import random
""""""""
#!/usr/bin/env python
class Job(object):
# -*- coding: UTF-8 -*-
# -*- coding: utf-8 -*-
a = r'''this is some
#!/usr/bin/env python
from pyqode.core.api import TextHelper
from meinheld import server
import gevent
#!/usr/bin/env python
""
from django.shortcuts import Http404
#
#!/usr/bin/python
# -*- coding: utf-8 -*-
# Copyright 2011 OpenStack Foundation
__author__ = 'cpaulson'
"""""""Test asyncio support"""""""
# This file is part of Tryton.  The COPYRIGHT file at the top level of
#
""""""""
import datetime
# (C) Copyright 2015 Hewlett Packard Enterprise Development Company LP
#!/usr/bin/env python
# Copyright (c) The PyAMF Project.
#!/usr/bin/env python
# Copyright (C) 2016 ycmd contributors
#!/usr/bin/env python
"# Copyright 2013 Eucalyptus Systems, Inc."
""""""""
# GemRB - Infinity Engine Emulator
# Copyright (C) 2009 Daniel Carvalho <idnael@gmail.com>
# https://www.bountysource.com/issues/4335201-ssl-broken-for-python-2-7-9
import unittest
from __future__ import division
from net.grinder.script.Grinder import grinder
import Adafruit_BBIO.GPIO as GPIO
"# Copyright 2011-2012 Eucalyptus Systems, Inc."
# Copyright 2010 United States Government as represented by the
# -*- coding: iso-8859-1 -*-
""""""""
def add_hostname_segment(powerline):
'''
import os
import datetime
import pytest
#!/usr/bin/env python
""""""""
# -*- coding: utf-8 -*-
#
#!/usr/bin/env python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
import sys
""

2025-01-26 02:54:06 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:54:06 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:54:06 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:54:08 - snowflake.connector.cursor - INFO - Number of results in first chunk: 27
2025-01-26 02:54:08 - snowflake.connector.connection - INFO - closed
2025-01-26 02:54:08 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:54:08 - root - INFO - SQL:
SELECT "sample_path", "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.R'
    LIMIT 100;
Results:
sample_path,size
R/series.R,2440
tests/testthat/test-normalizuj.R,881
books/Gelman_BDA2_ARM/doc/Book_Codes/Ch.25/25.0_Missing data in R and Bugs.R,556
R/newLonLat.R,1596
checkDecodedFiles.R,2616
src/R/model/multicontext_model_genData.R,10515
test/impact_plot_test.R,2587
tests/src/test/R/mget.R,263
R/getCensusApi.R,2612
inst/ShinyStan/ui_files/model_code.R,818
src/test/scripts/applications/cspline/CsplineDS.R,1899
src/library/base/R/lazyload.R,4387
packages/utils/src/main/R/prompt.R,16242
lib/perl/Genome/Model/Tools/EdgeR/FilterCountsFile.pm.R,1153
examples/undocumented/r_modular/kernel_poly_modular.R,584
_ignore/benchmarkingNewEnvs.R,1866
books/Gelman_BDA2_ARM/doc/arm2/chicks/chickens.R,2694
shiny/trabalho/global.R,34
r_modules/analysisPackages/PLSR/inst/unitTests/test_PLSR.R,32005
h2o-docs/src/booklets/v2_2015/source/R_Vignette_code_examples/r_import_file.R,707
h2o-r/tests/testdir_algos/gbm/runit_GBM_weights_gaussian.R,2886
JASP-Engine/JASP/R/ttestbayesianonesample.R,103789
src/library/utils/R/zip.R,4110
src/extra/testr/filtered-test-suite/isloaded/tc_isloaded_1.R,202
src/extra/testr/filtered-test-suite/tabulate/tc_tabulate_3.R,176
src/extra/testr/filtered-test-suite/gettext/tc_gettext_5.R,222
R/genCov_trackViz.R,1934

2025-01-26 02:54:08 - root - INFO - itercount: 0
2025-01-26 02:54:08 - root - INFO - Database Name: GITHUB_REPOS
Schema Name: GITHUB_REPOS
DDL describes table information.
,0
table_name,SAMPLE_FILES
description,
DDL,"create or replace TABLE SAMPLE_FILES (
	""repo_name"" VARCHAR(16777216),
	""ref"" VARCHAR(16777216),
	""path"" VARCHAR(16777216),
	""mode"" NUMBER(38,0),
	""id"" VARCHAR(16777216),
	""symlink_target"" VARCHAR(16777216)
);"

,1
table_name,LANGUAGES
description,
DDL,"create or replace TABLE LANGUAGES (
	""repo_name"" VARCHAR(16777216),
	""language"" VARIANT
);"

,2
table_name,LICENSES
description,
DDL,"create or replace TABLE LICENSES (
	""repo_name"" VARCHAR(16777216),
	""license"" VARCHAR(16777216)
);"

,3
table_name,SAMPLE_COMMITS
description,
DDL,"create or replace TABLE SAMPLE_COMMITS (
	""commit"" VARCHAR(16777216),
	""tree"" VARCHAR(16777216),
	""parent"" VARIANT,
	""author"" VARIANT,
	""committer"" VARIANT,
	""subject"" VARCHAR(16777216),
	""message"" VARCHAR(16777216),
	""trailer"" VARIANT,
	""difference"" VARIANT,
	""difference_truncated"" BOOLEAN,
	""repo_name"" VARCHAR(16777216),
	""encoding"" VARCHAR(16777216)
);"

,4
table_name,SAMPLE_CONTENTS
description,
DDL,"create or replace TABLE SAMPLE_CONTENTS (
	""id"" VARCHAR(16777216),
	""size"" NUMBER(38,0),
	""content"" VARCHAR(16777216),
	""binary"" BOOLEAN,
	""copies"" NUMBER(38,0),
	""sample_repo_name"" VARCHAR(16777216),
	""sample_ref"" VARCHAR(16777216),
	""sample_path"" VARCHAR(16777216),
	""sample_mode"" NUMBER(38,0),
	""sample_symlink_target"" VARCHAR(16777216)
);"

,5
table_name,SAMPLE_REPOS
description,
DDL,"create or replace TABLE SAMPLE_REPOS (
	""repo_name"" VARCHAR(16777216),
	""watch_count"" NUMBER(38,0)
);"

External knowledge that might be helpful: 
None
The table structure information is ({database name: {schema name: {table name}}}): 
{'GITHUB_REPOS': {'GITHUB_REPOS': ['LANGUAGES', 'LICENSES', 'SAMPLE_COMMITS', 'SAMPLE_CONTENTS', 'SAMPLE_FILES', 'SAMPLE_REPOS']}}
Begin Exploring Related Columns
**Relevant Tables and Columns:**

- **Table:** `GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS`
  - **Column:** `"sample_path"`: Potential usage - To identify Python (`.py`) and R (`.R`) script files by their file extensions.
  - **Column:** `"content"`: Potential usage - Contains the content of the files; can be analyzed to extract module names used in the scripts.
  - **Column:** `"sample_repo_name"`: Potential usage - To associate scripts with their repositories.
  - **Column:** `"size"`: Potential usage - To filter scripts based on size if needed.

**Conditions that may be used:**

- Filter where `"sample_path"` ends with `'.py'` or `'.R'` to select Python and R scripts respectively.
- Use the `ILIKE` operator for case-insensitive matching of file extensions.
- Search for import statements in `"content"` to identify module names:
  - Python: Lines containing `'import '` or `'from '` statements.
  - R: Lines containing `'library('` or `'require('` statements.

---

**SQL Queries to Explore the Data:**

1. **Retrieve sample paths for Python scripts:**

   ```sql
   SELECT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
   ```

2. **Retrieve sample paths for R scripts:**

   ```sql
   SELECT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
   ```

3. **Get distinct sample paths for Python scripts:**

   ```sql
   SELECT DISTINCT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
   ```

4. **Get distinct sample paths for R scripts:**

   ```sql
   SELECT DISTINCT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
   ```

5. **Retrieve content of Python scripts:**

   ```sql
   SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
   ```

6. **Retrieve content of R scripts:**

   ```sql
   SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
   ```

7. **Find Python scripts containing `'import '` statement:**

   ```sql
   SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import %'
   LIMIT 100;
   ```

8. **Find R scripts containing `'library('` statement:**

   ```sql
   SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R' AND "content" ILIKE '%library(%'
   LIMIT 100;
   ```

9. **Retrieve `'sample_repo_name'` and `'sample_path'` for Python scripts:**

   ```sql
   SELECT "sample_repo_name", "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
   ```

10. **Find Python scripts containing `'from'` imports:**

    ```sql
    SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%from % import %'
    LIMIT 100;
    ```

11. **Get distinct `'sample_repo_name'` for Python scripts:**

    ```sql
    SELECT DISTINCT "sample_repo_name"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
    ```

12. **Retrieve the size of Python scripts:**

    ```sql
    SELECT "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
    ```

13. **Find Python scripts larger than 1KB:**

    ```sql
    SELECT "sample_path", "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "size" > 1024
    LIMIT 100;
    ```

14. **Retrieve content of Python scripts containing `'import numpy'`:**

    ```sql
    SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import numpy%'
    LIMIT 100;
    ```

15. **Find counts of Python and R scripts:**

    ```sql
    SELECT "language", COUNT(*) AS "script_count"
    FROM (
        SELECT CASE
            WHEN "sample_path" ILIKE '%.py' THEN 'Python'
            WHEN "sample_path" ILIKE '%.R' THEN 'R'
            ELSE 'Other'
        END AS "language"
        FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    ) AS script_languages
    GROUP BY "language"
    LIMIT 100;
    ```

16. **List all import statements in Python scripts:**

    ```sql
    SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND ("content" ILIKE '%import %' OR "content" ILIKE '%from % import %')
    LIMIT 100;
    ```

17. **Find R scripts containing `'require('` statement:**

    ```sql
    SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.R' AND "content" ILIKE '%require(%'
    LIMIT 100;
    ```

18. **Retrieve Python scripts with both `'import pandas'` and `'import numpy'`:**

    ```sql
    SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import pandas%' AND "content" ILIKE '%import numpy%'
    LIMIT 100;
    ```

19. **Get the first 100 lines of content from Python scripts:**

    ```sql
    SELECT SPLIT_PART("content", '\n', 1) AS "first_line"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
    ```

20. **Retrieve sample paths and sizes of R scripts:**

    ```sql
    SELECT "sample_path", "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.R'
    LIMIT 100;
    ```

These SQL queries help in understanding the contents and structure of the relevant columns, which can be used to extract information about module usage in Python and R scripts. By examining the `"sample_path"` and `"content"` columns, we can identify scripts and analyze their content for import statements to ultimately determine the most frequently used modules.

---

**Note:** The queries above are designed to explore the data and gain insights into the columns that are relevant to retrieving the top 5 most frequently used module names from Python and R scripts. They range from simple selections to more complex searches using the `ILIKE` operator for pattern matching.

If you need further assistance or have additional questions, feel free to ask!Query:
SELECT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Answer:
sample_path
src/pyudev/_ctypeslib/__init__.py
networking_cisco/neutronclient/policyprofile.py
base_contact/__openerp__.py
GPy/testing/state_space_main_tests.py
esky/sudo/sudo_base.py
xlsxwriter/test/comparison/test_chart_column08.py
geomath/__init__.py
conda_manager/__init__.py
product_taxes_group/tests/test_product_taxes_group.py
newsfeed/migrations/0004_auto__chg_field_featuredsection_image.py
ulauncher/search/file_browser/FileBrowserMode.py
module/plugins/crypter/UploadableChFolder.py
lib/pegasus/python/Pegasus/service/base.py
rinoh/document.py
monasca_agent/collector/checks_d/postfix.py
keystone/tests/unit/identity/backends/test_ldap_common.py
corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py
registry/windows2012Users.py
poppy/storage/base/__init__.py
tests/mixins.py
scale/ingest/apps.py
memsource/api.py
hotbit/test/C6H6_cell_game.py
plexapi/myplex.py
tests/wizard/test_cookiestorage.py
cosmic-core/test/integration/testpaths/testpath_usage.py
public_plugins/help.py
tests/test_spec.py
kale/queue_selector.py
pyconjpbot/plugins/calc.py
bulbs/poll/managers.py
maininterface/settings.py
murano/cmd/cfapi.py
idtxl/estimators_cmi.py
src/script/anomalie_faux_positif.py
tests/test_graph_helpers.py
pygram/pg_threading.py
libraryusers/migrations/0002_libraryuser_books.py
webcrawler/utils/stdout.py
pam/__init__.py
wiggum/users/migrations/0008_user_external_service.py
alaudacli/execute.py
doc/source/conf.py
FontNote.glyphsPalette/Contents/Resources/FontNote.py
spirit/core/utils/markdown/block.py
tableloader/tableFunctions/blueprints.py
llvm_p86/codegen.py
doc/tutorials/examples/jython/swing/gui.py
tools/sqlmap/lib/utils/hashdb.py
ycmd/tests/server_utils_test.py
tools/sqlmap/plugins/generic/search.py
euca2ools/commands/autoscaling/putnotificationconfiguration.py
openedx/core/djangoapps/common_views/xblock.py
gemrb/GUIScripts/bg1/ImportFile.py
pyjswidgets/pyjamas/gmaps/Marker.py
conpot/helpers.py
tests/install_tests/test_utils.py
fuel/converters/ilsvrc2010.py
ngrinder-core/src/test/resources/test.py
examples/blink.py
clc/eucadmin/eucadmin/reportsrequest.py
nova/cmd/api_metadata.py
tests/checker/test_unknown.py
resources/lib/relativedelta.py
segments/hostname.py
regtests/go/class.py
tests/unit/test_req_file.py
crits/indicators/api.py
tests/test_logs.py
scripts/analyze_memdump.py
python/solutii/iulian_bute/search.py
password_policies/tests/__init__.py
python27/win32/Lib/site-packages/pycparser/c_ast.py
luigi_bigquery/config.py
lino/core/utils.py
utils.py
content/migrations/0024_auto_20160426_0830.py
gunnery/account/migrations/0002_auto__del_field_customuser_is_staff.py
mendeley/resources/groups.py
tests/url_parsing.py
make-estimation-spreadsheet.py
dynamic_forms/forms.py
scripts/encrypt.py
qa/ui_tests/test_routers.py
myconnectome/taskbehavior/mkfiles_task005.py
mcscf/test/test_c2h4.py
montanha/migrations/0011_auto__add_alternativelegislatorname__del_field_legislator_original_id.py
nova/tests/unit/virt/hyperv/test_block_device_manager.py
orchestra/models/__init__.py
example/simple_multiview.py
src/seagoatvision_ros/scripts/CapraVision/server/filters/implementation/yuv2bgr.py
neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py
venv/bin/createfontdatachunk.py
loafer/example/message_translator.py
matrixtoolkit/__init__.py
noggin/playbook/Formations.py
networking_mlnx/tests/unit/ml2/test_mechanism_sdn.py
pwatcher/mains/pwatcher.py
dlstats/fetchers/bis.py
pyperform/tools.py
Query:
SELECT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
Answer:
sample_path
R/series.R
tests/testthat/test-normalizuj.R
books/Gelman_BDA2_ARM/doc/Book_Codes/Ch.25/25.0_Missing data in R and Bugs.R
R/newLonLat.R
checkDecodedFiles.R
src/R/model/multicontext_model_genData.R
test/impact_plot_test.R
tests/src/test/R/mget.R
R/getCensusApi.R
inst/ShinyStan/ui_files/model_code.R
src/test/scripts/applications/cspline/CsplineDS.R
src/library/base/R/lazyload.R
packages/utils/src/main/R/prompt.R
lib/perl/Genome/Model/Tools/EdgeR/FilterCountsFile.pm.R
examples/undocumented/r_modular/kernel_poly_modular.R
_ignore/benchmarkingNewEnvs.R
books/Gelman_BDA2_ARM/doc/arm2/chicks/chickens.R
shiny/trabalho/global.R
r_modules/analysisPackages/PLSR/inst/unitTests/test_PLSR.R
h2o-docs/src/booklets/v2_2015/source/R_Vignette_code_examples/r_import_file.R
h2o-r/tests/testdir_algos/gbm/runit_GBM_weights_gaussian.R
JASP-Engine/JASP/R/ttestbayesianonesample.R
src/library/utils/R/zip.R
src/extra/testr/filtered-test-suite/isloaded/tc_isloaded_1.R
src/extra/testr/filtered-test-suite/tabulate/tc_tabulate_3.R
src/extra/testr/filtered-test-suite/gettext/tc_gettext_5.R
R/genCov_trackViz.R
Query:
SELECT DISTINCT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Answer:
sample_path
doc/tutorials/examples/jython/swing/gui.py
ycmd/tests/server_utils_test.py
euca2ools/commands/autoscaling/putnotificationconfiguration.py
openedx/core/djangoapps/common_views/xblock.py
conpot/helpers.py
tests/test_logs.py
scripts/analyze_memdump.py
resources/lib/relativedelta.py
geonode/groups/models.py
src/_cffi_src/openssl/asn1.py
src/cwmp/tr/vendor/bup/cmd/daemon-cmd.py
mne/decoding/base.py
py/test/selenium/webdriver/remote/remote_firefox_profile_tests.py
common/test/acceptance/tests/lms/test_lms_problems.py
components/org.apache.stratos.python.cartridge.agent/src/main/python/cartridge.agent/cartridge.agent/modules/event/instance/status/events.py
direct/src/controls/ControlManager.py
py/testdir_single_jvm/test_exec2_operators4.py
examples/util/wordcount_hdfs.py
lib/jython/Lib/test/test_int.py
madcow/include/twisted/_version.py
plugin/snippets/clang_complete.py
tests/test_arsc.py
code/python/external/platform/darwin/numpy/matrixlib/tests/test_multiarray.py
python/phonenumbers/shortdata/region_YE.py
tools/chrome_proxy/common/inspector_network.py
python/main-classic/channels/filmpertutti.py
backend/db/base.py
tests/glyphs/AnnularWedge.py
venv/lib/python2.7/site-packages/flask/globals.py
osx_build/nefi2_osx_amd64_xcode_2015/site-packages/numpy_1.11/numpy/distutils/mingw32ccompiler.py
zippy/benchmarks/src/benchmarks/sympy/sympy/mpmath/visualization.py
crits/core/management/commands/get_duplicate_targets.py
pymatgen/io/feff/sets.py
client_lib/test/unit/test_commands_history.py
scipy/interpolate/tests/test_polyint.py
tests/test_stats.py
SimpleCV/Features/HaarLikeFeatureExtractor.py
lib/third/youtube_dl/extractor/roxwel.py
backend/db/local_client.py
networking_cisco/neutronclient/policyprofile.py
GPy/testing/state_space_main_tests.py
conda_manager/__init__.py
password_policies/tests/__init__.py
content/migrations/0024_auto_20160426_0830.py
myconnectome/taskbehavior/mkfiles_task005.py
mcscf/test/test_c2h4.py
nova/tests/unit/virt/hyperv/test_block_device_manager.py
tests/test_exchange.py
tests/features/environment.py
bctools/bc_disk_access_v2.py
grr/config/grr-response-server/setup.py
banner_grabber.py
meinheld/common.py
examples/gevent/poll.py
experimental/serengeti/IAAI/betaTest2.py
src/core/files.py
position_tagger.py
Modules/DNSScanner.py
editorconfig_gedit2.py
kademlia/protocol.py
HFH/Contentdisposition.py
analytical/templatetags/olark.py
runtests.py
test/tests/api/v2_0/nodes_tests.py
maec/utils/merge.py
tests/test_mesh_interp.py
simple_rest/utils/serializers.py
MR-OCP/MROCPdjango/computation/tests/eigs/check_eigs.py
pyphi/compute/big_phi.py
shmaplib/logger.py
treeio/services/api/tests.py
awlsim/core/instructions/insn_zr.py
example/PypeTest.py
chromium/src/third_party/WebKit/Tools/Scripts/webkitpy/tool/commands/stepsequence.py
Version-1.0/pyxiewps-ES-sin Aircrack.py
nbodykit/distributedarray.py
hazelcast/protocol/codec/replicated_map_entry_set_codec.py
tests/test_xml.py
src/braille_alphabets-activity/BrailleChar.py
wordpress_xmlrpc/methods/comments.py
monolithe/config.py
zippy/lib-python/3/test/test_socket.py
openelex/api/base.py
share/gscreen/skins/spartan/spartan_handler.py
win64-vc/2.76/scripts/modules/bl_i18n_utils/settings.py
module/plugins/crypter/UploadableChFolder.py
rinoh/document.py
keystone/tests/unit/identity/backends/test_ldap_common.py
corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py
registry/windows2012Users.py
public_plugins/help.py
tests/test_spec.py
kale/queue_selector.py
maininterface/settings.py
pygram/pg_threading.py
webcrawler/utils/stdout.py
pam/__init__.py
wiggum/users/migrations/0008_user_external_service.py
alaudacli/execute.py
FontNote.glyphsPalette/Contents/Resources/FontNote.py
Query:
SELECT DISTINCT "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
Answer:
sample_path
R/series.R
tests/testthat/test-normalizuj.R
R/newLonLat.R
checkDecodedFiles.R
src/R/model/multicontext_model_genData.R
test/impact_plot_test.R
R/getCensusApi.R
inst/ShinyStan/ui_files/model_code.R
src/library/base/R/lazyload.R
packages/utils/src/main/R/prompt.R
shiny/trabalho/global.R
r_modules/analysisPackages/PLSR/inst/unitTests/test_PLSR.R
src/test/scripts/applications/cspline/CsplineDS.R
lib/perl/Genome/Model/Tools/EdgeR/FilterCountsFile.pm.R
examples/undocumented/r_modular/kernel_poly_modular.R
_ignore/benchmarkingNewEnvs.R
books/Gelman_BDA2_ARM/doc/arm2/chicks/chickens.R
h2o-docs/src/booklets/v2_2015/source/R_Vignette_code_examples/r_import_file.R
h2o-r/tests/testdir_algos/gbm/runit_GBM_weights_gaussian.R
JASP-Engine/JASP/R/ttestbayesianonesample.R
src/library/utils/R/zip.R
src/extra/testr/filtered-test-suite/isloaded/tc_isloaded_1.R
books/Gelman_BDA2_ARM/doc/Book_Codes/Ch.25/25.0_Missing data in R and Bugs.R
tests/src/test/R/mget.R
src/extra/testr/filtered-test-suite/tabulate/tc_tabulate_3.R
src/extra/testr/filtered-test-suite/gettext/tc_gettext_5.R
R/genCov_trackViz.R
Query:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Answer:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Business Applications
#    Copyright (C) 2013-TODAY OpenERP S.A. (<http://openerp.com>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

{
    'name': 'Contacts Management',
    'summary': u""[DEPRECATED] Manage your contacts separately"",
    'version': '8.0.2.0.0',
    'author': ""OpenERP SA,Odoo Community Association (OCA)"",
    'website': 'http://www.openerp.com',
    'category': 'Customer Relationship Management',
    'depends': [
        'partner_contact_birthdate',
        'partner_contact_in_several_companies',
        'partner_contact_nationality',
    ],
    'installable': False,
}
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1]
Query:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R'
   LIMIT 100;
Answer:
Too long, hard cut:
content
"library(raster)
library(data.table)
library(microbenchmark)
library(SpaDES)

N=1e4
sim <- new.env(parent = .GlobalEnv)
sim <- new.env()
sim$landscapeDT = data.table(test=1:(N^2), hello = sample(1:(N^2),(N^2)))
sim$ras <- raster(x=extent(0,N,0,N), res=1)
sim$ras[] = sim$landscapeDT$test


landscapeDT = copy(sim$landscapeDT)
ras <- raster(x=extent(0,N,0,N), res=1)
ras[] = -sim$landscapeDT$test

vec <- getValues(ras)

ras2 <- 1:10

# Note return invisible empty ... means no copy is made. The object is actually modified in place
#  as long as it is the same name, i.e., sim, as the environment name
changeValDT  <- function(sim, index, val) {
  sim$landscapeDT[index,hello:=val]
  invisible()
}

changeValDTNoSim  <- function(sim, index, val) {
  landscapeDT[index,hello:=val]
  invisible()
}

changeValRas  <- function(sim, index, val) {
  sim$ras[index]  <- val
  invisible()
}

index=sample(N^2, 5); print(index)

# Note - exact same time, meaning no copying is happening
microbenchmark(times=2000,
               new=changeValDT(sim, index=index, val=index),
               old=#{landscape <- getGlobal(""landscape""); 
                landscapeDT[index,hello:=index],
               alt=changeValDTNoSim(sim, index=index, val=index)
               # assignGlobal(""landscape"")}
               )
print(sim$landscapeDT[index,])
print(landscapeDT[index,])
print(landscapeDT[index,])

# Note - exact same time, meaning no copying is happening
microbenchmark(times=10,
               changeValRas(sim, index, index),
               ras[index]<-index,
               vec[index] <- index)

sim = new.env()
microbenchmark(times=100,
               makeEnv={sim$ras <- ras; sim$landscape <- landscape},
               makeList={sim2=list(ras, landscape)})

names(sim$ras) <- ""Fires""
setColors(sim$ras) <- c(""white"", rev(heat.colors(9)))
sim$ras <- setValues(sim$ras, 1)

"
"chickens <- read.table (""chickens.dat"", header=T)
attach.all (chickens)
diff <- mean.control - mean.treated
se.diff <- sqrt (se.treated^2 + se.control^2)

postscript (""c:/books/multilevel/blackman1.ps"", horizontal=T, height=4, width=4.5)
plot (freq, diff, xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Est. treatment effect"", type=""n"",
      main=expression(""Estimates with statistical significance""), mgp=c(1.5,.5,0))
w <- 2.5
freq[freq==165] <- 165+c(-w,w)
freq[freq==180] <- 180+c(-w,w)
freq[freq==405] <- 405+c(-w,w)
pvalue <- 2*pt(-diff/se.diff,n.treated+n.control-2)
for (i in 1:nrow(chickens))
  polygon (freq[i] + c(-w,-w,w,w), c(diff[i],0,0,diff[i]),
           col=ifelse(pvalue[i]<.05,""black"",0), lwd=.5)
dev.off()

postscript (""c:/books/multilevel/blackman2.ps"", horizontal=T, height=4, width=4.5)
plot (range(freq), range(c(diff+se.diff,diff-se.diff)),
      xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Est. treatment effect"", type=""n"",
      main=expression(""Estimates"" %+-% ""standard errors""), mgp=c(1.5,.5,0))
abline (0,0,lty=2,lwd=.5)
points (freq, diff, pch=20)
for (i in 1:nrow(chickens))
  lines (rep(freq[i],2), diff[i]+se.diff[i]*c(-1,1), lwd=.5)
dev.off()

if (0){
plot (range(freq), range(c(mean.control+se.control,mean.control-se.control))-1,
      xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Estimated treatment effect"", type=""n"",
      main=expression(""Estimates"" %+-% ""standard errors""))
abline (0,0,lty=2,lwd=.5)
points (freq, mean.control-1, pch=20)
for (i in 1:nrow(chickens))
  lines (rep(freq[i],2), mean.control[i]+se.control[i]*c(-1,1)-1, lwd=.5)
}


y <- diff
J <- length(diff)
sigma.y <- se.diff
schools.data <- list (""J"", ""y"", ""sigma.y"")
schools.inits <- function()
  list (theta=rnorm(J,0,1), mu.theta=rnorm(1,0,100),
        sigma.theta=runif(1,0,100))
schools.parameters <- c(""theta"", ""mu.theta"", ""sigma.theta"", ""e.theta"", ""y.rep"")
# run in winbugs14
schools.sim <- bugs (schools.data, schools.inits, schools.parameters, ""schools.bug"", n.chains=3, n.iter=1000, version=1.4)
lambda.theta <- 1 - var (apply (e.theta, 2, mean)) / mean (apply (e.theta, 1, var))
print (lambda.theta)

theta.hat <- apply(theta,2,mean)
se.theta <- apply(theta,2,sd)
postscript (""c:/books/multilevel/blackman3.ps"", horizontal=T, height=4, width=4.5)
plot (range(freq), range(c(diff+se.diff,diff-se.diff)),
      xlab=""Frequency of magnetic field (Hz)"",
      ylab=""Est. treatment effect"", type=""n"",
      main=expression(""Multilevel estimates"" %+-% ""standard errors""), mgp=c(1.5,.5,0))
abline (0,0,lty=2,lwd=.5)
points (freq, theta.hat, pch=20)
for (i in 1:nrow(chickens))
  lines (rep(freq[i],2), theta.hat[i]+se.theta[i]*c(-1,1), lwd=.5)
dev.off()


"
"library(sptrans)
olhovivo_login()
"
"#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you
Query:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import %'
   LIMIT 100;
Answer:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    -------
Query:
SELECT "content"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.R' AND "content" ILIKE '%library(%'
   LIMIT 100;
Answer:
Too long, hard cut:
content
"library(raster)
library(data.table)
library(microbenchmark)
library(SpaDES)

N=1e4
sim <- new.env(parent = .GlobalEnv)
sim <- new.env()
sim$landscapeDT = data.table(test=1:(N^2), hello = sample(1:(N^2),(N^2)))
sim$ras <- raster(x=extent(0,N,0,N), res=1)
sim$ras[] = sim$landscapeDT$test


landscapeDT = copy(sim$landscapeDT)
ras <- raster(x=extent(0,N,0,N), res=1)
ras[] = -sim$landscapeDT$test

vec <- getValues(ras)

ras2 <- 1:10

# Note return invisible empty ... means no copy is made. The object is actually modified in place
#  as long as it is the same name, i.e., sim, as the environment name
changeValDT  <- function(sim, index, val) {
  sim$landscapeDT[index,hello:=val]
  invisible()
}

changeValDTNoSim  <- function(sim, index, val) {
  landscapeDT[index,hello:=val]
  invisible()
}

changeValRas  <- function(sim, index, val) {
  sim$ras[index]  <- val
  invisible()
}

index=sample(N^2, 5); print(index)

# Note - exact same time, meaning no copying is happening
microbenchmark(times=2000,
               new=changeValDT(sim, index=index, val=index),
               old=#{landscape <- getGlobal(""landscape""); 
                landscapeDT[index,hello:=index],
               alt=changeValDTNoSim(sim, index=index, val=index)
               # assignGlobal(""landscape"")}
               )
print(sim$landscapeDT[index,])
print(landscapeDT[index,])
print(landscapeDT[index,])

# Note - exact same time, meaning no copying is happening
microbenchmark(times=10,
               changeValRas(sim, index, index),
               ras[index]<-index,
               vec[index] <- index)

sim = new.env()
microbenchmark(times=100,
               makeEnv={sim$ras <- ras; sim$landscape <- landscape},
               makeList={sim2=list(ras, landscape)})

names(sim$ras) <- ""Fires""
setColors(sim$ras) <- c(""white"", rev(heat.colors(9)))
sim$ras <- setValues(sim$ras, 1)

"
"library(sptrans)
olhovivo_login()
"
"#!/usr/bin/env Rscript

library(edgeR)
library(getopt)

filterCountsFile <- function(inputFile, countsPerMillion, numSamples, outputFile) {
    counts <- read.table(inputFile, head=T, row.names=1)
    keep <- rowSums(cpm(counts)>countsPerMillion) >= numSamples
    output <- counts[keep,]
    write.table(output, outputFile,  quote=FALSE, sep=""\t"",
        row.names=TRUE, col.names=NA)
}

parseOptions <- function(optSpec) {
    opts <- getopt(optSpec)

    if (!is.null(opts$help)) {
        cat(getopt(optSpec, usage=TRUE))
        q(status=0)
    }

    required <- optSpec[optSpec[,3] == ""1"", 1]
    for (req in required) {
        if (is.null(opts[[req]])) {
            cat(paste(""Required option"", req, ""missing!\n""))
            q(status=1)
        }
    }

    opts
}

optSpec = matrix(c(
    ""help"", ""h"", 0, NA,
    ""input-file"", ""i"", 1, ""character"",
    ""counts-per-million"", ""c"", 1, ""integer"",
    ""num-samples"", ""n"", 1, ""integer"",
    ""output-file"", ""o"", 1, ""character""
    ), byrow=TRUE, ncol=4)

opts <- parseOptions(optSpec)

dge <- filterCountsFile(opts$`input-file`, opts$`counts-per-million`, opts$`num-samples`, opts$`output-file`)
"
"library(shogun)

fm_train_real <- t(as.matrix(read.table('../data/fm_train_real.dat')))
fm_test_real <- t(as.matrix(read.table('../data/fm_test_real.dat')))

# poly
print('Poly')

feats_train <- RealFeatures()
dummy <- feats_train$set_feature_matrix(fm_train_real)
feats_test <- RealFeatures()
dummy <- feats_test$set_feature_matrix(fm_test_real)
degree <- as.integer(4)
inhomogene <- FALSE

kernel <- PolyKernel(
	feats_train, feats_train, degree, inhomogene)

km_train <- kernel$get_kernel_matrix()
dump <- kernel$init(feats_train, feats_test)
km_test <- kernel$get_kernel_matrix()
"
"library(PLSR)
library(RUnit)
library(DEMOdz)
library(TCGAgbm)
Sys.setlocale(""LC_ALL"", ""C"")

if(!exists(""marker.genes.545"")){
    print(load(system.file(package=""TCGAgbm"", ""extdata"", ""genesets.RData"")))
    marker.genes.545 <- genesets$marker.genes.545
    tcga.GBM.classifiers <- genesets$tcga.GBM.classifiers
    }
#----------------------------------------------------------------------------------------------------
runTests <- function()
{
  test_constructor()
  test_summarizePatientNumericFactors()
  test_summarizePatientNumericFactors_TCGAgbm_poorPatientOverlap()
  test_summarizePatientNumericFactors_DEMOdz()
  test_createClassificationMatrix()
  test_createClassificationMatrix.1factor()
  test_createClassificationMatrix.2factors()
  test_createBigClassificationMatrix()
  test_calculateTiny.ageDxDemo()
  #test_calculateTiny.ageDxAndSurvival.demo()
  test_calculateSmall.ageDxOnly()
  test_calculateSmall.survivalOnly()
  test_calculateSmall()
  test_calculateBig()
  test_changeDataSetsAndCalculateSmall()

} # runTests
#----------------------------------------------------------------------------------------------------
test_constructor = function()
{
   printf(""--- test_constructor"")
   demoDz <- DEMOdz()
   mrna.datasets <- sort(grep(""mtx.mrna"", manifest(demoDz)$
Query:
SELECT "sample_repo_name", "sample_path"
   FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
   WHERE "sample_path" ILIKE '%.py'
   LIMIT 100;
Answer:
Too long, hard cut:
sample_repo_name,sample_path
pyudev/pyudev,src/pyudev/_ctypeslib/__init__.py
CiscoSystems/networking-cisco,networking_cisco/neutronclient/policyprofile.py
OCA/partner-contact,base_contact/__openerp__.py
SheffieldML/GPy,GPy/testing/state_space_main_tests.py
cloudmatrix/esky,esky/sudo/sudo_base.py
jmcnamara/XlsxWriter,xlsxwriter/test/comparison/test_chart_column08.py
vmesel/GeoMath,geomath/__init__.py
spyder-ide/conda-manager,conda_manager/__init__.py
grap/odoo-addons-misc,product_taxes_group/tests/test_product_taxes_group.py
openfun/fun-apps,newsfeed/migrations/0004_auto__chg_field_featuredsection_image.py
Ulauncher/Ulauncher,ulauncher/search/file_browser/FileBrowserMode.py
dischinator/pyload,module/plugins/crypter/UploadableChFolder.py
pegasus-isi/pegasus,lib/pegasus/python/Pegasus/service/base.py
brechtm/rinohtype,rinoh/document.py
openstack/monasca-agent,monasca_agent/collector/checks_d/postfix.py
openstack/keystone,keystone/tests/unit/identity/backends/test_ldap_common.py
dimagi/commcare-hq,corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py
SekoiaLab/Fastir_Collector,registry/windows2012Users.py
openstack/poppy,poppy/storage/base/__init__.py
praus/shapy,tests/mixins.py
ngageoint/scale,scale/ingest/apps.py
gengo/memsource-wrap,memsource/api.py
pekkosk/hotbit,hotbit/test/C6H6_cell_game.py
mjs7231/python-plexapi,plexapi/myplex.py
django/django-formtools,tests/wizard/test_cookiestorage.py
MissionCriticalCloud/cosmic,cosmic-core/test/integration/testpaths/testpath_usage.py
gradiuscypher/discord_gradiusbot,public_plugins/help.py
rhosqeauto/InfraRed,tests/test_spec.py
Nextdoor/ndkale,kale/queue_selector.py
pyconjp/pyconjpbot,pyconjpbot/plugins/calc.py
theonion/django-bulbs,bulbs/poll/managers.py
semiautomaticgit/SemiAutomaticClassificationPlugin,maininterface/settings.py
openstack/murano,murano/cmd/cfapi.py
pwollstadt/IDTxl,idtxl/estimators_cmi.py
lprat/AEE,src/script/anomalie_faux_positif.py
harrymvr/absorbing-centrality,tests/test_graph_helpers.py
RedXBeard/pygram,pygram/pg_threading.py
jacinda/pycon_library,libraryusers/migrations/0002_libraryuser_books.py
mrafayaleem/simple-crawler,webcrawler/utils/stdout.py
MartinPyka/Parametric-Anatomical-Modeling,pam/__init__.py
qdqmedia/wiggum,wiggum/users/migrations/0008_user_external_service.py
alaudacloud/alauda-CLI,alaudacli/execute.py
openstack/fuel-plugin-midonet,doc/source/conf.py
mekkablue/NotePalettes,FontNote.glyphsPalette/Contents/Resources/FontNote.py
nitely/Spirit,spirit/core/utils/markdown/block.py
fuzzysteve/yamlloader,tableloader/tableFunctions/blueprints.py
john-tornblom/llvm-p86,llvm_p86/codegen.py
hydralabs/pyamf,doc/tutorials/examples/jython/swing/gui.py
golismero/golismero,tools/sqlmap/lib/utils/hashdb.py
Valloric/ycmd,ycmd/tests/server_utils_test.py
golismero/golismero,tools/sqlmap/plugins/generic/search.py
eucalyptus/euca2ools,euca2ools/commands/autoscaling/putnotificationconfiguration.py
edx/edx-platform,openedx/core/djangoapps/common_views/xblock.py
gemrb/gemrb,gemrb/GUIScripts/bg1/ImportFile.py
pyjs/pyjs,pyjswidgets/pyjamas/gmaps/Marker.py
mushorg/conpot,conpot/helpers.py
pfnet/chainer,tests/install_tests/test_utils.py
mila-udem/fuel,fuel/converters/ilsvrc2010.py
naver/ngrinder,ngrinder-core/src/test/resources/test.py
jadonk/bone101,examples/blink.py
eucalyptus/eucalyptus,clc/eucadmin/eucadmin/reportsrequest.py
openstack/nova,nova/cmd/api_metadata.py
wummel/linkchecker,tests/checker/test_unknown.py
robweber/xbmcbackup,resources/lib/relativedelta.py
milkbikis/powerline-shell,segments/hostname.py
rusthon/Rusthon,regtests/go/class.py
pypa/pip,tests/unit/test_req_file.py
MITRECND/crits,crits/indicators/api.py
nvbn/thefuck,tests/test_logs.py
wummel/linkchecker,scripts/analyze_memdump.py
alexandrucoman/labs,python/solutii/iulian_bute/search.py
tarak/django-password-policies,password_policies/tests/__init__.py
aliyun/oss-ftp,python27/win32/Lib/site-packages/pycparser/c_ast.py
hakobera/luigi-bigquery,luigi_bigquery/config.py
lsaffre/lino,lino/core/utils.py
Nymphet/sexinsex-crawler,utils.py
djangogirlscodecamp/lightandleadership,content/migrations/0024_auto_20160426_0830.py
gunnery/gunnery,gunnery/account/migrations/0002_auto__del_field_customuser_is_staff.py
Mendeley/mendeley-python-sdk,mendeley/resources/groups.py
jvanasco/metadata_parser,tests/url_parsing.py
mhl/github-issues-scripts,make-estimation-spreadsheet.py
MarkusH/django-dynamic-forms,dynamic_forms/forms.py
czcorpus/kontext,scripts/encrypt.py
paypal/aurora,qa/ui_tests/test_routers.py
poldrack/myconnectome,myconnectome/taskbehavior/mkfiles_task005.py
sunqm/pyscf,mcscf/test/test_c2h4.py
olhoneles/olhoneles,montanha/migrations/0011_auto__add_alternativelegislatorname__del_field_legislator_original_id.py
openstack/nova,nova/tests/unit/virt/hyperv/test_block_device_manager.py
unlimitedlabs/orchestra,orchestra/models/__init__.py
tu-rbo/concarne,example/simple_multiview.py
clubcapra/Ibex,src/seagoatvision_ros/scripts/CapraVision/server/filters/implementation/yuv2bgr.py
openstack/
Query:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%from % import %'
    LIMIT 100;
Answer:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    -------
Query:
SELECT DISTINCT "sample_repo_name"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
Answer:
sample_repo_name
cloudmatrix/esky
vmesel/GeoMath
lsaffre/lino
gunnery/gunnery
jvanasco/metadata_parser
poldrack/myconnectome
olhoneles/olhoneles
openstack/nova
Nymphet/sexinsex-crawler
D-L/SimpleBookMarks
grundgruen/powerline
omab/psa-recovery
n3ko1/WrapMap
google/grr
DarkFenX/Pyfa
rocky/python3-trepan
piiswrong/dec
openconnectome/m2g
RealTimeWeb/blockpy
funkandwagnalls/pythonpentest
pyQode/pyqode.core
exaile/exaile
openstack/monasca-agent
feuervogel/django-taggit-templatetags
hpcugent/hanythingondemand
wreckage/django-happenings
openstack/rack
alexforencich/python-ivi
udp/json-parser
maxcutler/python-wordpress-xmlrpc
ejeschke/ginga
LinuxCNC/linuxcnc
networkx/networkx
drvink/epanos
wmayner/pyphi
mbuesch/awlsim
espadrine/opera
tgrosinger/aenea-grammars
openstack/cinder
ceph/ceph-installer
croach/django-simple-rest
svpcom/hyperloglog
dropbox/changes
openstack/python-neutronclient
OpenBazaar/OpenBazaar-Server
bdoin/GCompris
grap/odoo-addons-misc
Ulauncher/Ulauncher
pegasus-isi/pegasus
openstack/keystone
SekoiaLab/Fastir_Collector
openstack/murano
harrymvr/absorbing-centrality
jacinda/pycon_library
MartinPyka/Parametric-Anatomical-Modeling
qdqmedia/wiggum
openstack/fuel-plugin-midonet
alaudacloud/alauda-CLI
john-tornblom/llvm-p86
clubcapra/Ibex
openstack/neutron-vpnaas
cujomalainey/matrixtoolkit
openstack/networking-mlnx
Widukind/dlstats
lobocv/pyperform
jordens/rayopt
openstack/castellan
anoduck/recon-ng
OpenCanada/website
egrcc/zhihu-python
ShenNoether/MiniNero
paulo-romano/django-admin-gentelella
openstack/fuel-plugin-detach-rabbitmq
dkkline/EventManager
embedly/embedly-python
devilry/devilry-django
wbond/certvalidator
pingali/dgit
openstack/barbican
pior/caravan
tethysplatform/tethys
openstack/cloudkitty
rice-apps/rice-elections
danvk/oldnyc
watsonpy/watson-framework
taolei87/rcnn
tibonihoo/wateronmars
01org/qmsi
unlimitedlabs/orchestra
OpenTrading/OpenTrader
mekkablue/Glyphs-Scripts
317070/kaggle-heart
ronf/asyncssh
pjdietz/rester-sublime-http-client
globocom/GloboNetworkAPI-client-python
openstack/vitrage
hellysmile/django-redis-sessions-fork
getsentry/sentry-auth-google
hydralabs/pyamf
golismero/golismero
Query:
SELECT "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
Answer:
size
6556
2189
3459
1445
17043
17923
2535
23052
2807
473
951
4259
975
1395
1448
44812
3942
1636
184
285
638
27648
775
11355
1640
125539
240
4015
5311
761
590
18432
2147
14896
9381
5214
544
483
332
3519
451
2632
2736
8277
5111
3718
73117
7005
5349
8333
26113
2276
1057
2289
1138
1037
317
22903
317
203
2058
1654
2887
17115
836
430
22259
6933
478
3961
577
226
24133
1739
26622
669
1320
3528
2610
1537
4499
2101
385
3835
1681
1937
12907
13943
1086
8698
984
65273
600
372
50
5259
15991
227
18180
4049
Query:
SELECT "sample_path", "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "size" > 1024
    LIMIT 100;
Answer:
sample_path,size
product_taxes_group/tests/test_product_taxes_group.py,6556
newsfeed/migrations/0004_auto__chg_field_featuredsection_image.py,2189
ulauncher/search/file_browser/FileBrowserMode.py,3459
module/plugins/crypter/UploadableChFolder.py,1445
lib/pegasus/python/Pegasus/service/base.py,17043
rinoh/document.py,17923
monasca_agent/collector/checks_d/postfix.py,2535
keystone/tests/unit/identity/backends/test_ldap_common.py,23052
corehq/ex-submodules/pillow_retry/south_migrations/006_add_doc_meta.py,2807
tests/mixins.py,4259
networking_cisco/neutronclient/policyprofile.py,1395
base_contact/__openerp__.py,1448
GPy/testing/state_space_main_tests.py,44812
esky/sudo/sudo_base.py,3942
xlsxwriter/test/comparison/test_chart_column08.py,1636
python27/win32/Lib/site-packages/pycparser/c_ast.py,24133
luigi_bigquery/config.py,1739
lino/core/utils.py,26622
content/migrations/0024_auto_20160426_0830.py,1320
gunnery/account/migrations/0002_auto__del_field_customuser_is_staff.py,3528
mendeley/resources/groups.py,2610
tests/url_parsing.py,1537
make-estimation-spreadsheet.py,4499
dynamic_forms/forms.py,2101
qa/ui_tests/test_routers.py,3835
myconnectome/taskbehavior/mkfiles_task005.py,1681
mcscf/test/test_c2h4.py,1937
montanha/migrations/0011_auto__add_alternativelegislatorname__del_field_legislator_original_id.py,12907
nova/tests/unit/virt/hyperv/test_block_device_manager.py,13943
memsource/api.py,27648
plexapi/myplex.py,11355
tests/wizard/test_cookiestorage.py,1640
cosmic-core/test/integration/testpaths/testpath_usage.py,125539
tests/test_spec.py,4015
kale/queue_selector.py,5311
maininterface/settings.py,18432
murano/cmd/cfapi.py,2147
idtxl/estimators_cmi.py,14896
src/script/anomalie_faux_positif.py,9381
tests/test_graph_helpers.py,5214
pam/__init__.py,3519
alaudacli/execute.py,2632
doc/source/conf.py,2736
FontNote.glyphsPalette/Contents/Resources/FontNote.py,8277
spirit/core/utils/markdown/block.py,5111
tableloader/tableFunctions/blueprints.py,3718
llvm_p86/codegen.py,73117
doc/tutorials/examples/jython/swing/gui.py,7005
tools/sqlmap/lib/utils/hashdb.py,5349
ycmd/tests/server_utils_test.py,8333
tools/sqlmap/plugins/generic/search.py,26113
euca2ools/commands/autoscaling/putnotificationconfiguration.py,2276
openedx/core/djangoapps/common_views/xblock.py,1057
gemrb/GUIScripts/bg1/ImportFile.py,2289
pyjswidgets/pyjamas/gmaps/Marker.py,1138
conpot/helpers.py,1037
fuel/converters/ilsvrc2010.py,22903
clc/eucadmin/eucadmin/reportsrequest.py,2058
nova/cmd/api_metadata.py,1654
tests/checker/test_unknown.py,2887
resources/lib/relativedelta.py,17115
tests/unit/test_req_file.py,22259
crits/indicators/api.py,6933
scripts/analyze_memdump.py,3961
orchestra/models/__init__.py,1086
example/simple_multiview.py,8698
neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py,65273
noggin/playbook/Formations.py,5259
networking_mlnx/tests/unit/ml2/test_mechanism_sdn.py,15991
dlstats/fetchers/bis.py,18180
pyperform/tools.py,4049
geqe-ml/testModel.py,7175
rayopt/test/test_yaml.py,2027
castellan/key_manager/__init__.py,1205
pycouchdb/utils.py,3947
modules/exploitation/injection/xpath_bruter.py,6925
changes/buildsteps/base.py,6529
simple_sso/sso_server/migrations/0001_initial.py,1850
anubis/filters.py,7317
tests/test_global_fit.py,1673
test.py,11268
regparser/notice/diff.py,26343
src/user.py,1268
tests/test_exchange.py,3114
list_tree_and_table/listview/simple_listview_with_icon_filter.py,3519
tests/features/environment.py,2506
Modules/DNSScanner.py,1473
bctools/bc_disk_access_v2.py,62274
grr/config/grr-response-server/setup.py,3376
CGATPipelines/pipeline_docs/pipeline_intervals/trackers/Annotations.py,4641
service/port.py,28906
caffe/examples/web_demo/app.py,7659
tools/demo_server/test/util.py,6514
kademlia/protocol.py,4605
books/Introduction_to_Statistics_using_Python/Code3/fig_PDF.py,1243
packages/dtipreproc/parse_b.py,3071
lino/modlib/countries/mixins.py,8110
banner_grabber.py,2340
test/test_panels/test_line_nbr.py,1630
examples/gevent/poll.py,1153
Query:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import numpy%'
    LIMIT 100;
Answer:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    tangent: float
        Factor with which independent variable is multiplied in linear equation.
    add_term: float
        Additive term in linear equation.
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    linear_function = lambda xx:  tangent*xx + add_term
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = linear_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points

def generate_brownian_data(x_points=None, kernel_var = 2.0, noise_var = 2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Generate brownian data - data from Brownian motion.
    First point is always 0, and \Beta(0) = 0  - standard conditions for Brownian motion.           
           
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    variance: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
      
    """"""    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)
        if x_points[0] != 0:
            x_points[0] = 0
    
    y_points = np.zeros( (points_num,) )
    for i in range(1, points_num):
        noise = np.random.randn() * np.sqrt(kernel_var * (x_points[i] - x_points[i-1]))
        y_points[i] = y_points[i-1] + noise
    
    y_points += np.random.randn( len(x_points) ) * np.sqrt(noise_var)
    
    return x_points, y_points   
        
def generate_linear_plus_sin(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
              
Query:
SELECT "language", COUNT(*) AS "script_count"
    FROM (
        SELECT CASE
            WHEN "sample_path" ILIKE '%.py' THEN 'Python'
            WHEN "sample_path" ILIKE '%.R' THEN 'R'
            ELSE 'Other'
        END AS "language"
        FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    ) AS script_languages
    GROUP BY "language"
    LIMIT 100;
Answer:
language,script_count
Other,23516
Python,743
R,27
Query:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND ("content" ILIKE '%import %' OR "content" ILIKE '%from % import %')
    LIMIT 100;
Answer:
Too long, hard cut:
content
"# -*- coding: utf-8 -*-
# Copyright (C) 2015 mulhern <amulhern@redhat.com>

# This library is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by the
# Free Software Foundation; either version 2.1 of the License, or (at your
# option) any later version.

# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
# for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation,
# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA

""""""
    pyudev._ctypeslib
    =================

    Wrappers for libraries.

    .. moduleauthor::  mulhern  <amulhern@redhat.com>
""""""

from . import libc
from . import libudev
"
"# Copyright 2015 Cisco Systems, Inc.
# All rights reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#

from neutronclient.common import extension


class PolicyProfile(extension.NeutronClientExtension):
    resource = 'policy_profile'
    resource_plural = '%ss' % resource
    object_path = '/%s' % resource_plural
    resource_path = '/%s/%%s' % resource_plural
    versions = ['2.0']
    allow_names = True


class PolicyProfileList(extension.ClientExtensionList, PolicyProfile):
    """"""List policy profiles that belong to a given tenant.""""""

    shell_command = 'cisco-policy-profile-list'
    list_columns = ['id', 'name']
    pagination_support = True
    sorting_support = True


class PolicyProfileShow(extension.ClientExtensionShow, PolicyProfile):
    """"""Show information of a given policy profile.""""""

    shell_command = 'cisco-policy-profile-show'
"
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Alex Grigorevskiy
# Licensed under the BSD 3-clause license (see LICENSE.txt)
""""""
Test module for state_space_main.py
""""""

import unittest
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

import GPy.models.state_space_setup as ss_setup
import GPy.models.state_space_main as ssm

def generate_x_points(points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates (sorted) points on the x axis.
    
    Input:
    ---------------------------
        points_num: int
            How many points to generate
        x_interval: tuple (a,b)
            On which interval to generate points
        random: bool
            Regular points or random
    
    Output:
    ---------------------------
        x_points: np.array
            Generated points
    """"""
    
    x_interval = np.asarray( x_interval )

    if random:
        x_points = np.random.rand(points_num) * ( x_interval[1] - x_interval[0] ) + x_interval[0]
        x_points = np.sort( x_points )
    else:
        x_points = np.linspace(x_interval[0], x_interval[1], num=points_num )        

    return x_points

def generate_sine_data(x_points=None, sin_period=2.0, sin_ampl=10.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates sinusoidal data.
    
    Input:
    --------------------------------
    
    x_points: np.array
        Previously generated X points
    sin_period: float
        Sine period    
    sin_ampl: float
        Sine amplitude
    noise_var: float 
        Gaussian noise variance added to the sine function
    plot: bool
        Whether to plot generated data
    
    (if x_points is None, the the following parameters are used to generate
    those. They are the same as in 'generate_x_points' function)        
    
    points_num: int
    
    x_interval: tuple (a,b)
    
    random: bool
    """"""    
    
    sin_function = lambda xx: sin_ampl * np.sin( 2*np.pi/sin_period * xx )
    
    if x_points is None:
        x_points = generate_x_points(points_num, x_interval, random)

    y_points = sin_function( x_points ) + np.random.randn( len(x_points) ) * np.sqrt(noise_var)

    if plot:
        pass
    
    return x_points, y_points
    
def generate_linear_data(x_points=None, tangent=2.0, add_term=1.0, noise_var=2.0,
                        plot = False, points_num=100, x_interval = (0, 20), random=True):
    """"""
    Function generates linear data.
    
    Input:
    -------
Query:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.R' AND "content" ILIKE '%require(%'
    LIMIT 100;
Answer:
Too long, hard cut:
content
"setwd(normalizePath(dirname(R.utils::commandArgs(asValues=TRUE)$""f"")))
source(""../../../scripts/h2o-r-test-setup.R"")
### This tests observation weights in glm ######




test_weights_by_row_duplication <- function() {
  
  require(testthat)
  
  #create data
  print(""create synthetic data with a numeric outcome"")
  set.seed(45541)
  n <- 100  #Number of training observations (also nrow(test) = n)
  p <- 20  #Number of features
  x <- matrix(rnorm(n*p), n, p)
  y <- rnorm(n)
  
  # Training data with weights
  # draw some random weights ~ Poisson, add 'x1' weight col and y to df, hdf
  set.seed(1234)
  x1 <- rpois(n, rep(2, n)) + 1  #Random integer-valued (>=1) weights
  df <- data.frame(x, x1, y)  #design matrix with weight and outcome cols
  hdf <- as.h2o(df, destination_frame = ""hdf"")  #for h2o
  
  # Training data (weights == 1.0 with repeated rows instead of weights)
  rep_idxs <- unlist(sapply(1:n, function(i) rep(i, df$x1[i])))
  rdf <- df[rep_idxs,]  #repeat rows
  rdf$x1 <- 1  #set weights back to 1.0
  rhdf <- as.h2o(rdf, destination_frame = ""rhdf"")  #for h2o
  
  ## for glmnet
  #df <- as.matrix(df)
  #rdf <- as.matrix(rdf)
  
  # Test data
  set.seed(2641)
  newx <- matrix(rnorm(n*p), n, p)
  newy <- rnorm(n)
  
  x1 <- rep(1, n)
  valid1 <- data.frame(newx, x1, y = newy)
  val1 <- as.h2o(valid1, destination_frame = ""val1"")
  valid1 <- as.matrix(valid1)
  
  print(""build models with weights vs repeated rows with h2o and lambda!=0"")
  hh1 <- h2o.gbm(x = 1:20, y = ""y"", 
                 training_frame = hdf, 
                 validation_frame = val1, 
                 ntrees = 50, 
                 weights_column = ""x1"")
  hh2 <- h2o.gbm(x = 1:20, y = ""y"", 
                 training_frame = rhdf, 
                 validation_frame = val1,
                 ntrees = 50, 
                 weights_column = ""x1"")
  
  print(""compare results"")
  expect_equal(hh1@model$training_metrics@metrics$MSE, 
               hh2@model$training_metrics@metrics$MSE,
               tolerance = 1e-6)
  expect_equal(hh1@model$training_metrics@metrics$r2, 
               hh2@model$training_metrics@metrics$r2,
               tolerance = 1e-6)

  expect_equal(hh1@model$validation_metrics@metrics$MSE,
               hh2@model$validation_metrics@metrics$MSE,
               tolerance = 1e-6)
  expect_equal(hh1@model$validation_metrics@metrics$r2,
               hh2@model$validation_metrics@metrics$r2,
               tolerance = 1e-6)
  
    
  #predictions
  print(""compare predictions"")
  ph1 <- as.data.frame(h2o.predict(object = hh1, newdata = val1))
  ph2 <- as.data.frame(h2o.predict(object = hh2, newdata = val1))
  mse1 <- mean((ph1$predict - newy)^2)
  mse2 <- mean((ph2$predict - newy)^2)
  #expect_equal(mse1, mse2)  #1.49 - 1.46 == 0.0291
  
  
  
}


doTest(""GBM weight Test: GBM w/ weights test by row duplication"", test_weights_by_row_duplication)
"
"## This script checks whether the reads in each splitted file belong to the same barcode
## and whether the file name contains the corresponding sample id name.
## Note, this script is a memory hog. 
## It was used to check the idemp output for one of our miseq runs.
##source(""http://bioconductor.org/biocLite.R"")
##biocLite(""ShortRead"")
require(ShortRead)

#### Files original and decoded ####
barcodeFile=""barcode_sample.txt""
I1File=""~/projects/141104_M03249_0008_000000000-ABY6R/Data/Intensities/BaseCalls/Undetermined_S0_L001_I1_001.fastq.gz""
R1File=""~/projects/141104_M03249_0008_000000000-ABY6R/Data/Intensities/BaseCalls/Undetermined_S0_L001_R1_001.fastq.gz"" 
R2File=""~/projects/141104_M03249_0008_000000000-ABY6R/Data/Intensities/BaseCalls/Undetermined_S0_L001_R2_001.fastq.gz""
decodedFile=list.files(""./"", pattern=""*.fastq.gz$"")

#### Read in barcode table, sequence names and barcodes ####
firstLine=readLines(""barcode_sample.txt"",1)
barcodeTable=read.table(barcodeFile, header=grepl(""arcode"", firstLine))
### Read in seqquence names and barcodes ###
barcodeReads=readFastq(I1File)
I1Names=unname(sapply(as.character(id(barcodeReads)), function(x) (strsplit(x,"" "")[[1]][1] ) ) )
I1Barcodes=as.character(sread(barcodeReads))

#### Loop through decoded files ####
for( i in 1:length(decodedFile) ) {
  cat(i, "" of "", length(decodedFile), ""\n"")
  cat(decodedFile[i],""\n"")
  decodedReads=readFastq(decodedFile[i])
  seqNames=unname(sapply(as.character(id(decodedReads)), function(x) (strsplit(x,"" "")[[1]][1] ) ) )
  seqBarcodes=as.character(sread(decodedReads))
  
  idx=match(seqNames, I1Names)
  #table(I1Barcodes[idx])
  #sort(table(I1Barcodes[idx]), decreasing=T)
  bctable=sort(table(I1Barcodes[idx]), decreasing=T)
  if ( length(bctable)> 1000 ) {
    message(length(bctable), "" barcodes found out of "", length(seqNames), "" reads."") 
  }
  if ( length( grep(names(bctable)[1], barcodeTable[,1]) )==0 ) {
    message(""most frequent barcode "",names(bctable)[1], "" not matched."") 
    next
  }
  if ( length(bctable)> 1000 ) n
Query:
SELECT "content"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py' AND "content" ILIKE '%import pandas%' AND "content" ILIKE '%import numpy%'
    LIMIT 100;
Answer:
Too long, hard cut:
content
"import os
import time
import cPickle
import datetime
import logging
import flask
import werkzeug
import optparse
import tornado.wsgi
import tornado.httpserver
import numpy as np
import pandas as pd
from PIL import Image as PILImage
import cStringIO as StringIO
import urllib
import caffe
import exifutil

REPO_DIRNAME = os.path.abspath(os.path.dirname(__file__) + '/../..')
UPLOAD_FOLDER = '/tmp/caffe_demos_uploads'
ALLOWED_IMAGE_EXTENSIONS = set(['png', 'bmp', 'jpg', 'jpe', 'jpeg', 'gif'])

# Obtain the flask app object
app = flask.Flask(__name__)


@app.route('/')
def index():
    return flask.render_template('index.html', has_result=False)


@app.route('/classify_url', methods=['GET'])
def classify_url():
    imageurl = flask.request.args.get('imageurl', '')
    try:
        string_buffer = StringIO.StringIO(
            urllib.urlopen(imageurl).read())
        image = caffe.io.load_image(string_buffer)

    except Exception as err:
        # For any exception we encounter in reading the image, we will just
        # not continue.
        logging.info('URL Image open error: %s', err)
        return flask.render_template(
            'index.html', has_result=True,
            result=(False, 'Cannot open image from URL.')
        )

    logging.info('Image: %s', imageurl)
    result = app.clf.classify_image(image)
    return flask.render_template(
        'index.html', has_result=True, result=result, imagesrc=imageurl)


@app.route('/classify_upload', methods=['POST'])
def classify_upload():
    try:
        # We will save the file to disk for possible data collection.
        imagefile = flask.request.files['imagefile']
        filename_ = str(datetime.datetime.now()).replace(' ', '_') + \
            werkzeug.secure_filename(imagefile.filename)
        filename = os.path.join(UPLOAD_FOLDER, filename_)
        imagefile.save(filename)
        logging.info('Saving to %s.', filename)
        image = exifutil.open_oriented_im(filename)

    except Exception as err:
        logging.info('Uploaded image open error: %s', err)
        return flask.render_template(
            'index.html', has_result=True,
            result=(False, 'Cannot open uploaded image.')
        )

    result = app.clf.classify_image(image)
    return flask.render_template(
        'index.html', has_result=True, result=result,
        imagesrc=embed_image_html(image)
    )


def embed_image_html(image):
    """"""Creates an image embedded in HTML base64 format.""""""
    image_pil = PILImage.fromarray((255 * image).astype('uint8'))
    image_pil = image_pil.resize((256, 256))
    string_buf = StringIO.StringIO()
    image_pil.save(string_buf, format='png')
    data = string_buf.getvalue().encode('base64').replace('\n', '')
    return 'data:image/png;base64,' + data


def allowed_file(filename):
    return (
        '.' in filename and
        filename.rsplit('.', 1)[1] in ALLOWED_IMAGE_EXTENSIONS
    )


class ImagenetClassifier(object):
    default_args = {
        'model_def_file': (
            '{}/models/bvlc_reference_caffenet/deploy.prototxt'.format(REPO_DIRNAME)),
        'pretrained_model_file': (
            '{}/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'.format(REPO_DIRNAME)),
        'mean_file': (
            '{}/python/caffe/imagenet/ilsvrc_2012_mean.npy'.format(REPO_DIRNAME)),
        'class_labels_file': (
            '{}/data/ilsvrc12/synset_words.txt'.format(REPO_DIRNAME)),
        'bet_file': (
            '{}/data/ilsvrc12/imagenet.bet.pickle'.format(REPO_DIRNAME)),
    }
    for key, val in default_args.iteritems():
        if not os.path.exists(val):
            raise Exception(
                ""File for {} is missing. Should be at: {}"".format(key, val))
    default_args['image_dim'] = 227
    default_args['raw_scale'] = 255.
    default_args['gpu_mode'] = False

    def __init__(self, model_def_file, pretrained_model_file, mean_file,
                 raw_scale, class_labels_file, bet_file, image_dim, gpu_mode):
        logging.info('Loading net and associated files...')
        self.net = caffe.Classifier(
            model_def_file, pretrained_model_file,
            image_dims=(image_dim, image_dim), raw_scale=raw_scale,
            mean=np.load(mean_file), channel_swap=(2, 1, 0), gpu=gpu_mode
        )

        with open(class_labels_file) as f:
            labels_df = pd.DataFrame([
                {
                    'synset_id': l.strip().split(' ')[0],
                    'name': ' '.join(l.strip().split(' ')[1:]).split(',')[0]
                }
                for l in f.readlines()
            ])
        self.labels = labels_df.sort('synset_id')['name'].values

        self.bet = cPickle.load(open(bet_file))
        # A bias to prefer children nodes in single-chain paths
        # I am setting the value to 0.1 as a quick, simple model.
        # We could use better psychological models here...
        self.bet['infogain'] -= np.array(self.bet['preferences']) * 0.1

    def 
Query:
SELECT SPLIT_PART("content", '\n', 1) AS "first_line"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.py'
    LIMIT 100;
Answer:
first_line
# -*- coding: utf-8 -*-
"# Copyright 2015 Cisco Systems, Inc."
# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
"#  Copyright (c) 2009-2010, Cloud Matrix Pty. Ltd."
###############################################################################
""""""""
# -*- coding:utf-8 -*-
#!/usr/bin/env python
from password_policies.tests.forms import *
"#-----------------------------------------------------------------"
import os
# Copyright 2010-2016 Luc Saffre
"from urllib import request, parse"
# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
"from mendeley.models.groups import Group, GroupMember"
import metadata_parser
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#!/usr/bin/python
from uibasetest import *
""""""""
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright (c) 2016 Cloudbase Solutions Srl
# vim: set encoding=utf-8
#coding: utf8
from unittest import TestCase
#!/usr/bin/env python
# -*- coding: utf-8 -*-
try:
"from django.conf.urls import patterns, url"
# code by n3ko1 2015 - @n3ko101
#!/usr/bin/python3
#!/usr/bin/env python
import os
from editorconfig_plugin.gedit2 import *
#===============================================================================
#!/usr/bin/env python
import os
#!/usr/bin/python
from sklearn_pmml.convert import IntegerCategoricalFeature
import random
""""""""
#!/usr/bin/env python
class Job(object):
# -*- coding: UTF-8 -*-
# -*- coding: utf-8 -*-
a = r'''this is some
#!/usr/bin/env python
from pyqode.core.api import TextHelper
from meinheld import server
import gevent
#!/usr/bin/env python
""
from django.shortcuts import Http404
#
#!/usr/bin/python
# -*- coding: utf-8 -*-
# Copyright 2011 OpenStack Foundation
__author__ = 'cpaulson'
"""""""Test asyncio support"""""""
# This file is part of Tryton.  The COPYRIGHT file at the top level of
#
""""""""
import datetime
# (C) Copyright 2015 Hewlett Packard Enterprise Development Company LP
#!/usr/bin/env python
# Copyright (c) The PyAMF Project.
#!/usr/bin/env python
# Copyright (C) 2016 ycmd contributors
#!/usr/bin/env python
"# Copyright 2013 Eucalyptus Systems, Inc."
""""""""
# GemRB - Infinity Engine Emulator
# Copyright (C) 2009 Daniel Carvalho <idnael@gmail.com>
# https://www.bountysource.com/issues/4335201-ssl-broken-for-python-2-7-9
import unittest
from __future__ import division
from net.grinder.script.Grinder import grinder
import Adafruit_BBIO.GPIO as GPIO
"# Copyright 2011-2012 Eucalyptus Systems, Inc."
# Copyright 2010 United States Government as represented by the
# -*- coding: iso-8859-1 -*-
""""""""
def add_hostname_segment(powerline):
'''
import os
import datetime
import pytest
#!/usr/bin/env python
""""""""
# -*- coding: utf-8 -*-
#
#!/usr/bin/env python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
import sys
""
Query:
SELECT "sample_path", "size"
    FROM GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS
    WHERE "sample_path" ILIKE '%.R'
    LIMIT 100;
Answer:
sample_path,size
R/series.R,2440
tests/testthat/test-normalizuj.R,881
books/Gelman_BDA2_ARM/doc/Book_Codes/Ch.25/25.0_Missing data in R and Bugs.R,556
R/newLonLat.R,1596
checkDecodedFiles.R,2616
src/R/model/multicontext_model_genData.R,10515
test/impact_plot_test.R,2587
tests/src/test/R/mget.R,263
R/getCensusApi.R,2612
inst/ShinyStan/ui_files/model_code.R,818
src/test/scripts/applications/cspline/CsplineDS.R,1899
src/library/base/R/lazyload.R,4387
packages/utils/src/main/R/prompt.R,16242
lib/perl/Genome/Model/Tools/EdgeR/FilterCountsFile.pm.R,1153
examples/undocumented/r_modular/kernel_poly_modular.R,584
_ignore/benchmarkingNewEnvs.R,1866
books/Gelman_BDA2_ARM/doc/arm2/chicks/chickens.R,2694
shiny/trabalho/global.R,34
r_modules/analysisPackages/PLSR/inst/unitTests/test_PLSR.R,32005
h2o-docs/src/booklets/v2_2015/source/R_Vignette_code_examples/r_import_file.R,707
h2o-r/tests/testdir_algos/gbm/runit_GBM_weights_gaussian.R,2886
JASP-Engine/JASP/R/ttestbayesianonesample.R,103789
src/library/utils/R/zip.R,4110
src/extra/testr/filtered-test-suite/isloaded/tc_isloaded_1.R,202
src/extra/testr/filtered-test-suite/tabulate/tc_tabulate_3.R,176
src/extra/testr/filtered-test-suite/gettext/tc_gettext_5.R,222
R/genCov_trackViz.R,1934
End Exploring Related Columns
Task: Please help me retrieve the top 5 most frequently used module names from Python and R scripts.

Please answer only one complete SQL in snowflake dialect in ```sql``` format.
Usage example: ```sql
SELECT "COLUMN_NAME" FROM DATABASE.SCHEMA.TABLE WHERE ... ``` (Adjust "DATABASE", "SCHEMA", and "TABLE" to match actual names, ensure all column names are enclosed in double quotations)
Follow the answer format like: To retrieve the top 5 most frequently used module names from Python and R scripts, we analyze the script files in the `SAMPLE_CONTENTS` table. The result is:

```csv
Module_Name,Usage_Count
module1:str,count1:int
module2:str,count2:int
module3:str,count3:int
module4:str,count4:int
module5:str,count5:int
(Attention: answer in five rows)
```

This table lists the module names and how frequently they are used in the scripts, with the most frequently used modules at the top..
Here are some useful tips for answering:
When performing a UNION operation on many tables, ensure that all table names are explicitly listed. Union first and then add condition and selection. e.g. SELECT "col1", "col2" FROM (TABLE1 UNION ALL TABLE2) WHERE ...; Don't write sqls as (SELECT col1, col2 FROM TABLE1 WHERE ...) UNION ALL (SELECT col1, col2 FROM TABLE2 WHERE ...); Don't use ['-- Include all', '-- Omit', '-- Continue', '-- Union all', '-- ...', '-- List all', '-- Replace this', '-- Each table', '-- Add other'] to omit any table. Table names here: ({database name: {schema name: {table name}}}): 
{'GITHUB_REPOS': {'GITHUB_REPOS': ['LANGUAGES', 'LICENSES', 'SAMPLE_COMMITS', 'SAMPLE_CONTENTS', 'SAMPLE_FILES', 'SAMPLE_REPOS']}}

For string-matching scenarios, if the string is decided, don't use fuzzy query, and avoid using REGEXP. e.g. Get the object's title contains the word "book"
However, if the string is not decided, you may use fuzzy query and ignore upper or lower case. e.g. Get articles that mention "education".
When using ORDER BY xxx DESC, add NULLS LAST to exclude null records: ORDER BY xxx DESC NULLS LAST.
When using ORDER BY, if there are duplicate values in the primary sort column, sort by an additional column as a secondary criterion.Keep all decimals to four decimal places.
Be careful of information in nested columns. e.g. When it comes to completed purchase, `hits.eCommerceAction.action_type` Indicates the type of ecommerce action and '6' represents completed purchases.
Be careful one country may have different country_name and country_region in different columns in a database.
Don't be misled by examples. For instance, a question related to Android development on StackOverflow might include tags like 'android-layout,' 'android-activity,' or 'android-intent.' However, you should not limit your analysis to just these three tags; instead, consider all tags related to Android: "tags" LIKE '%android%'.

2025-01-26 02:55:03 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com/openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-01-26 02:55:03 - root - INFO - ```sql
WITH python_modules AS (
    SELECT
        LOWER(
            CASE
                WHEN REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1)
                WHEN REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1)
                ELSE NULL
            END
        ) AS "Module_Name"
    FROM (
        SELECT "value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.py'
    )
    WHERE "line" ILIKE 'import %' OR "line" ILIKE 'from % import %'
), r_modules AS (
    SELECT LOWER(REGEXP_SUBSTR("line", 'library\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT "value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
             LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%library(%'
    UNION ALL
    SELECT LOWER(REGEXP_SUBSTR("line", 'require\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT "value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%require(%'
)
SELECT "Module_Name", COUNT(*) AS "Usage_Count"
FROM (
    SELECT "Module_Name" FROM python_modules
    UNION ALL
    SELECT "Module_Name" FROM r_modules
)
WHERE "Module_Name" IS NOT NULL
GROUP BY "Module_Name"
ORDER BY "Usage_Count" DESC
LIMIT 5;
```
2025-01-26 02:55:03 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:55:03 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:55:03 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:55:04 - snowflake.connector.connection - INFO - closed
2025-01-26 02:55:04 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:55:04 - root - INFO - itercount: 1
2025-01-26 02:55:04 - root - INFO - 000904 (42000): 01b9f5ef-0004-8343-0001-11c300faa536: SQL compilation error: error line 13 at position 15
invalid identifier '"value"'
2025-01-26 02:55:04 - root - INFO - Input sql:
WITH python_modules AS (
    SELECT
        LOWER(
            CASE
                WHEN REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1)
                WHEN REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1)
                ELSE NULL
            END
        ) AS "Module_Name"
    FROM (
        SELECT "value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.py'
    )
    WHERE "line" ILIKE 'import %' OR "line" ILIKE 'from % import %'
), r_modules AS (
    SELECT LOWER(REGEXP_SUBSTR("line", 'library\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT "value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
             LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%library(%'
    UNION ALL
    SELECT LOWER(REGEXP_SUBSTR("line", 'require\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT "value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%require(%'
)
SELECT "Module_Name", COUNT(*) AS "Usage_Count"
FROM (
    SELECT "Module_Name" FROM python_modules
    UNION ALL
    SELECT "Module_Name" FROM r_modules
)
WHERE "Module_Name" IS NOT NULL
GROUP BY "Module_Name"
ORDER BY "Usage_Count" DESC
LIMIT 5;
The error information is:
000904 (42000): 01b9f5ef-0004-8343-0001-11c300faa536: SQL compilation error: error line 13 at position 15
invalid identifier '"value"'
Please correct it and output only 1 complete SQL query.When using ORDER BY xxx DESC, add NULLS LAST to exclude null records: ORDER BY xxx DESC NULLS LAST.

2025-01-26 02:55:42 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com/openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-01-26 02:55:42 - root - INFO - ```sql
WITH python_modules AS (
    SELECT
        LOWER(
            CASE
                WHEN REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1)
                WHEN REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1)
                ELSE NULL
            END
        ) AS "Module_Name"
    FROM (
        SELECT t."value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.py'
    )
    WHERE "line" ILIKE 'import %' OR "line" ILIKE 'from % import %'
), r_modules AS (
    SELECT LOWER(REGEXP_SUBSTR("line", 'library\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t."value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
             LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%library(%'
    UNION ALL
    SELECT LOWER(REGEXP_SUBSTR("line", 'require\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t."value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%require(%'
)
SELECT "Module_Name", COUNT(*) AS "Usage_Count"
FROM (
    SELECT "Module_Name" FROM python_modules
    UNION ALL
    SELECT "Module_Name" FROM r_modules
)
WHERE "Module_Name" IS NOT NULL
GROUP BY "Module_Name"
ORDER BY "Usage_Count" DESC NULLS LAST
LIMIT 5;
```
2025-01-26 02:55:42 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:55:42 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:55:42 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:55:43 - snowflake.connector.connection - INFO - closed
2025-01-26 02:55:43 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:55:43 - root - INFO - itercount: 2
2025-01-26 02:55:43 - root - INFO - 000904 (42000): 01b9f5ef-0004-7d15-0001-11c300fa9646: SQL compilation error: error line 13 at position 15
invalid identifier 'T."value"'
2025-01-26 02:55:43 - root - INFO - Input sql:
WITH python_modules AS (
    SELECT
        LOWER(
            CASE
                WHEN REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1)
                WHEN REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1)
                ELSE NULL
            END
        ) AS "Module_Name"
    FROM (
        SELECT t."value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.py'
    )
    WHERE "line" ILIKE 'import %' OR "line" ILIKE 'from % import %'
), r_modules AS (
    SELECT LOWER(REGEXP_SUBSTR("line", 'library\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t."value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
             LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%library(%'
    UNION ALL
    SELECT LOWER(REGEXP_SUBSTR("line", 'require\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t."value" AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%require(%'
)
SELECT "Module_Name", COUNT(*) AS "Usage_Count"
FROM (
    SELECT "Module_Name" FROM python_modules
    UNION ALL
    SELECT "Module_Name" FROM r_modules
)
WHERE "Module_Name" IS NOT NULL
GROUP BY "Module_Name"
ORDER BY "Usage_Count" DESC NULLS LAST
LIMIT 5;
The error information is:
000904 (42000): 01b9f5ef-0004-7d15-0001-11c300fa9646: SQL compilation error: error line 13 at position 15
invalid identifier 'T."value"'
Please correct it and output only 1 complete SQL query.
2025-01-26 02:56:11 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com/openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-01-26 02:56:11 - root - INFO - ```sql
WITH python_modules AS (
    SELECT
        LOWER(
            CASE
                WHEN REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1)
                WHEN REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1)
                ELSE NULL
            END
        ) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.py'
    )
    WHERE "line" ILIKE 'import %' OR "line" ILIKE 'from % import %'
), r_modules AS (
    SELECT LOWER(REGEXP_SUBSTR("line", 'library\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
             LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%library(%'
    UNION ALL
    SELECT LOWER(REGEXP_SUBSTR("line", 'require\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%require(%'
)
SELECT "Module_Name", COUNT(*) AS "Usage_Count"
FROM (
    SELECT "Module_Name" FROM python_modules
    UNION ALL
    SELECT "Module_Name" FROM r_modules
)
WHERE "Module_Name" IS NOT NULL
GROUP BY "Module_Name"
ORDER BY "Usage_Count" DESC NULLS LAST
LIMIT 5;
```
2025-01-26 02:56:11 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:56:11 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:56:11 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:56:13 - snowflake.connector.cursor - INFO - Number of results in first chunk: 5
2025-01-26 02:56:13 - snowflake.connector.connection - INFO - closed
2025-01-26 02:56:13 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:56:13 - root - INFO - itercount: 3
2025-01-26 02:56:13 - root - INFO - 0
2025-01-26 02:56:13 - root - INFO - results: 
Module_Name,Usage_Count
__future__,24
os,16
unittest,9
numpy,9
sys,7


2025-01-26 02:56:13 - root - INFO - Please check the answer again by reviewing Please help me retrieve the top 5 most frequently used module names from Python and R scripts., reviewing Relevant Tables and Columns and Possible Conditions and then give the final SQL query. Don't output other queries. If you think the answer is right, just output the current SQL.
Keep all decimals to four decimal places.
The answer format should be like: To retrieve the top 5 most frequently used module names from Python and R scripts, we analyze the script files in the `SAMPLE_CONTENTS` table. The result is:

```csv
Module_Name,Usage_Count
module1:str,count1:int
module2:str,count2:int
module3:str,count3:int
module4:str,count4:int
module5:str,count5:int
(Attention: answer in five rows)
```

This table lists the module names and how frequently they are used in the scripts, with the most frequently used modules at the top. The answer should match the number of rows, the column name of the format and the filled values in the format (e.g. filled year or month). Don't output extra rows or nested rows!
Current snswer: 
Module_Name,Usage_Count
__future__,24
os,16
unittest,9
numpy,9
sys,7
Current sql:
WITH python_modules AS (
    SELECT
        LOWER(
            CASE
                WHEN REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1)
                WHEN REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1)
                ELSE NULL
            END
        ) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.py'
    )
    WHERE "line" ILIKE 'import %' OR "line" ILIKE 'from % import %'
), r_modules AS (
    SELECT LOWER(REGEXP_SUBSTR("line", 'library\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
             LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%library(%'
    UNION ALL
    SELECT LOWER(REGEXP_SUBSTR("line", 'require\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%require(%'
)
SELECT "Module_Name", COUNT(*) AS "Usage_Count"
FROM (
    SELECT "Module_Name" FROM python_modules
    UNION ALL
    SELECT "Module_Name" FROM r_modules
)
WHERE "Module_Name" IS NOT NULL
GROUP BY "Module_Name"
ORDER BY "Usage_Count" DESC NULLS LAST
LIMIT 5;
2025-01-26 02:56:35 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com/openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-01-26 02:56:35 - root - INFO - ```sql
WITH python_modules AS (
    SELECT
        LOWER(
            CASE
                WHEN REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*import\\s+(\\w+)', 1, 1, 'e', 1)
                WHEN REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1) IS NOT NULL THEN
                    REGEXP_SUBSTR("line", '^\\s*from\\s+(\\w+)\\s+import\\s+', 1, 1, 'e', 1)
                ELSE NULL
            END
        ) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.py'
    )
    WHERE "line" ILIKE 'import %' OR "line" ILIKE 'from % import %'
), r_modules AS (
    SELECT LOWER(REGEXP_SUBSTR("line", 'library\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
             LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%library(%'
    UNION ALL
    SELECT LOWER(REGEXP_SUBSTR("line", 'require\\(([^)]+)\\)', 1, 1, 'e', 1)) AS "Module_Name"
    FROM (
        SELECT t.VALUE AS "line"
        FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS",
            LATERAL FLATTEN(INPUT => SPLIT("content", '\\n')) AS t
        WHERE "sample_path" ILIKE '%.R'
    )
    WHERE "line" ILIKE '%require(%'
)
SELECT "Module_Name", COUNT(*) AS "Usage_Count"
FROM (
    SELECT "Module_Name" FROM python_modules
    UNION ALL
    SELECT "Module_Name" FROM r_modules
)
WHERE "Module_Name" IS NOT NULL
GROUP BY "Module_Name"
ORDER BY "Usage_Count" DESC NULLS LAST
LIMIT 5;
```
2025-01-26 02:56:35 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: Linux-6.1.62-x86_64-with-glibc2.31
2025-01-26 02:56:35 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-01-26 02:56:35 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-26 02:56:36 - snowflake.connector.cursor - INFO - Number of results in first chunk: 5
2025-01-26 02:56:36 - snowflake.connector.connection - INFO - closed
2025-01-26 02:56:36 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-01-26 02:56:36 - root - INFO - itercount: 4
2025-01-26 02:56:36 - root - INFO - 0
2025-01-26 02:56:37 - root - INFO - Total iteration counts: 4
