2025-02-12 18:32:28 - openai._base_client - INFO - Retrying request to /chat/completions in 0.498704 seconds
2025-02-12 18:33:30 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:33:30 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:30 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:30 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:32 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:32 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:32 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:32 - root - INFO - SQL:
SELECT DISTINCT "sample_repo_name"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   LIMIT 100;
Results:
sample_repo_name
pelya/commandergenius
cloudera/impala-kudu
khasang/SmartForecast
urjaman/flashrom
velo/flexmojos
SnappyDataInc/snappy-store
XyrusWorx/apophysis7x
drdaeman/accel-ppp
tokee/lucene
webscalesql/webscalesql-5.6
CONNECT-Solution/CONNECT
DoSomething/voting-app
apache/sqoop
AbiWord/abiword
meta-debian/meta-debian
Cerberuss/GofPatterns
cloudmatrix/esky
Mygod/Skylark
JHUAPL/AccumuloGraph
vmesel/GeoMath
mapbender/mapbender
sfmskywalker/Orchard
ovh/overthebox-openwrt
Caltech-IPAC/firefly
Kunena/Kunena-Forum
nickkolok/chas-ege
apache/uima-uimaj
apache/sis
bombmanual/bombmanual.github.io
pplante/droidtowers
Nexus-Mods/Nexus-Mod-Manager
jmaih/RISE_toolbox
headwirecom/aem-solr-search
glmcdona/strings2
anycmd/anycmd
linuxdeepin/deepin-wm
mempo/mempo-kernel
apache/qpid-java
ImmobilienScout24/yum-repo-server
gorescript/gorescript
oehf/ipf
findsorguk/findsorguk
garyKeorkunian/squants
Sitecore/Habitat
StefanoFiumara/Harry-Potter-Unity
gr8pefish/IronBackpacks
iridium-browser/iridium-browser-ubuntu
sam408130/Ionic-Demos
Glimpse/Glimpse.Prototype
coinkite/cloudfire
b3dgs/lionengine
Incubaid/arakoon
aspnetboilerplate/aspnetboilerplate
jaquadro/StorageDrawers
Job-Yang/YTZImageComparison
awslabs/aws-sdk-cpp
ghxiao/drew
aasensio/pySIR
epiSurg/EpiSurg
googlei18n/language-resources
crossbario/crossbarexamples
ezScrum/ezScrum
fxos-components/bridge
LibreOffice/core
KDE/krita
mdaniel/virtualbox-org-svn-vbox-trunk
hroptatyr/dateutils
espadrine/opera
digama0/mmj2
nathansttt/hog2
google/binexport
biocaml/biocaml
tatsuhiro-t/aria2
albertz/openlierox
Open-Transport/synthese
danielnaber/openthesaurus
scrollback/io.scrollback.neighborhoods
project-store/theme
sileht/check_mk
umbraco/Umbraco-CMS
nigelsmall/py2neo
Esteemed-Innovation/Flaxbeards-Steam-Power
TheTechnobear/EigenD
sonata-project/sandbox-build
koala-framework/koala-framework
ligaDATA/Kamanja
hiloteam/Hilo
oivva/boxy
ChildrenOfUr/coUclient
timduru/tf300t-katkernel
ChildrenOfUr/coUserver
draios/sysdig
bosonic/bosonic
Ulauncher/Ulauncher
DynamoRIO/drk
google/ktsan
apache/tomcat-native
erasaur/binary
jdahlstrom/vaadin.react
pfirmstone/river-internet

2025-02-12 18:33:32 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:32 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:32 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:33 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:33 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:34 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:34 - root - INFO - SQL:
SELECT DISTINCT "sample_path"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   LIMIT 100;
Results:
Too long, hard cut:
sample_path
common/thrift/CatalogService.thrift
socketcan_interface/CMakeLists.txt
bin/php7_linux1/bin/mbedtls_dh_client
src/pocketmine/block/Sugarcane.php
Install/Help/commands/3dmaths/SCALE VECTOR2.htm
src/cinder/app/linux/WindowImplLinuxEgl.cpp
libjava/javax/naming/spi/NamingManager.java
lionengine-network/src/main/java/com/b3dgs/lionengine/network/Networker.java
top_down_classifier/src/top_down_classifier/volume_visualizer.h
networking_cisco/neutronclient/policyprofile.py
third-party/org.svnkit/org/tmatesoft/svn/core/internal/wc2/ng/SvnNgRepositoryAccess.class
share/gamedir/levels/ctf_duel2/sprites/flag_y.bmp
aws-cpp-sdk-route53/include/aws/route53/model/CreateTrafficPolicyInstanceRequest.h
backend/colorAdmin/form_editable.html
src/BCR/BCRexternalBWT.cpp
util/robodoc/Source/robodoc.c
myblockchain-test/suite/rpl/r/rpl_loaddata_s.result
myblockchain-test/suite/ndb_rpl/r/ndb_rpl_mixed_tables.result
resources/assets/storagedrawers/textures/blocks/indicator/void_icon.png
GPy/testing/state_space_main_tests.py
tooling/support/provisioning-model/pom.xml
src/java/org/apache/cassandra/db/commitlog/ReplayPosition.java
chrome/browser/signin/about_signin_internals.cc
core/sis-metadata/src/test/java/org/apache/sis/metadata/iso/DefaultMetadataTest.java
src/include/platform.h
lib/padding/pad_variable.m
clients/java/src/main/java/com/senseidb/search/client/req/SenseiClientRequest.java
sal/qa/rtl/strings/test_oustring_compare.cxx
source/stylesheets/modules/_sortable.scss
bin/Skylark.dll.config
pos_position/cv483_16378.txt
src/main/webapp/fonts/DigitalDream/DIGITALDREAMNARROW-webfont.ttf
checks/decru_fans
grails-app/controllers/TagController.groovy
src/libc/stdio/FreeBSD/clrerr.c
CommonProjects/AMDTBaseTools/Include/gtStringTokenizer.h
libs/SDL2_ttf-2.0.14/debian/copyright
lionengine-core/src/main/java/com/b3dgs/lionengine/drawable/Image.java
src/main/resources/templates/layout/app.jade
spec/models/i18n_spec.rb
dbaccess/source/ui/misc/datasourceconnector.cxx
SystemEx/Windows/Forms/IpcHelper.cs
Assets/Scripts/HarryPotterUnity/Cards/Quidditch/Spells/QuickThinking.cs
authmodules/TYPO3/privacyidea/Resources/Private/Language/locallang.xlf
assets/src/scss/components/_logo.scss
Assets/Graphics/Big.psd
Product/Production/Services/PatientDiscoveryCore/src/main/java/gov/hhs/fha/nhinc/patientdiscovery/model/builder/impl/PatientSearchResultsModelBuilderImpl.java
third_party/skia/src/gpu/effects/GrConfigConversionEffect.cpp
deps/icu4c/source/i18n/hebrwcal.cpp
mapfishapp/src/main/java/org/georchestra/mapfishapp/ws/upload/FeatureGeoFileReader.java
uimaj-core/src/main/java/org/apache/uima/collection/CasConsumerDescription.java
whois-endtoend/src/test/java/net/ripe/db/whois/changedphase3/util/Scenario.java
JGTL/JGTL_API/latex/class_j_g_t_l_1_1_hex_tree_branch.tex
resources/CAVP/Vectors/OpenSSL/testvectors.SuSE/testvectors/sha/req/SHA256Monte.req
test/ddiff.052.clit
common/java/core/net/i2p/client/naming/ExecNamingService.java
third_party/skia/src/gpu/gl/GrGLProgram.cpp
pack.cmd
spec/test_app/spec-opal/active_record/update_associations_spec.rb
classes/time_series/@ts/acosh.m
html/partials/compare/os_table.html.haml
app/src/main/res/drawable-xxxhdpi/ic_headphones_grey600_48dp.png
app/src/main/res/drawable/key8.png
src/libs/css/daterangepicker-bs3.css
util/misc/cdna_fasta_file_to_transcript_gtf.pl
docs/html/T_AForge_Video_Ximea_XimeaCamera.htm
chromium/src/third_party/WebKit/Source/modules/webaudio/OfflineAudioDestinationNode.h
Helpers/INRIAEval/data-USA/annotations/set06/V017.vbb
include/bot-logic/behaviour_drive_neuralnet.h
src/Scriban.Tests/TestFiles/100-expressions/150-range-expression.txt
application/var/generation/Magento/AdminNotification/Controller/Adminhtml/Notification/Remove/Interceptor.php
test/VisualStudio.Test/VisualStudio.Test.csproj
subjectivity/objective/default/file4850
conda_manager/__init__.py
Vendor Firmware/Kinetis SDK v.1.3.0 API Reference Manual/fsl__clock__MKV40F15_8h.html
xxl-job-admin/src/main/java/com/xxl/job/admin/core/jobbean/impl/DemoConcurrentJobBean.java
dev.watchr.rb
.settings/org.eclipse.core.resources.prefs
virtual_memory.h
ArcFormats/BlackCyc/ArcGPK.cs
src/main/java/io/mycat/manager/response/ShowSQLSumUser.java
tapestry-core/src/test/java/org/apache/tapestry5/ContentTypeTest.java
vio/vio.c
Modules/BetterCms.Module.Root/Commands/Tag/SaveTag/SaveTagCommand.cs
lib/entities/plants/peatbog.dart
src/filesystem/ZWorkerPool.h
third-party/org.carrot2.api/javadoc/org/carrot2/text/preprocessing/CaseNormalizerDescriptor.Keys.html
core/lib/dr_config.h
ME3Explorer/Resources/property_database_64x64.png
module/plugins/crypter/UploadableChFolder.py
build.xml
content/browser/indexed_db/indexed_db_quota_client.cc
core/sis-referencing/src/main/java/org/apache/sis/referencing/datum/DefaultPrimeMeridian.java
streamingUpdate/seq1.c
grammars/unosln.cson
plugins/BackendTheme/src/Template/Element/settings.ctp
FAQ-USER
commonjs/google-map/map.js
tapestry-core/src/test/java/org/apache/tapestry5/internal/services/RequestPathOptimizer

2025-02-12 18:33:34 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:34 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:34 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:35 - snowflake.connector.cursor - INFO - Number of results in first chunk: 27
2025-02-12 18:33:36 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:37 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:37 - root - INFO - SQL:
SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md'
   LIMIT 100;
Results:
Too long, hard cut:
content
"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][django-browserid], a.k.a. Mozilla Pe

2025-02-12 18:33:37 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:37 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:37 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:38 - snowflake.connector.cursor - INFO - Number of results in first chunk: 27
2025-02-12 18:33:39 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:40 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:40 - root - INFO - SQL:
SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE
   LIMIT 100;
Results:
Too long, hard cut:
content
"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][django-browserid], a.k.a. Mozilla Pe

2025-02-12 18:33:40 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:40 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:40 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:41 - snowflake.connector.cursor - INFO - Number of results in first chunk: 27
2025-02-12 18:33:44 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:44 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:44 - root - INFO - SQL:
SELECT "sample_repo_name", "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE
   LIMIT 100;
Results:
Too long, hard cut:
sample_repo_name,content
mozilla/oneanddone,"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][

2025-02-12 18:33:44 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:44 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:44 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:45 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:45 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:45 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:45 - root - INFO - SQL:
SELECT "repo_name", "language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES"
   LIMIT 100;
Results:
repo_name,language
konrad/READemption,[]
Duobe/TheFirstOne,[]
andyyardley/SecureO,[]
PGower/Timetabler2SQL,[]
brykmoore/SeniorProject,[]
mpusz/SimpleWorkarounds,[]
lily06280425/lian-,[]
seanarooni/gitignore,[]
mashurex/arduino-tuts,[]
Natashka89/ironpython_training2,[]
Chookahead/Locally-Created-Repo,[]
twiess/hello-world,[]
jasonzissman/Algorithms,[]
pl85s/programming-for_testers,[]
maicki/GDUpload,[]
cyclejs/base,[]
renwei360/-,[]
pedazo/ogo,[]
jsheng258/helloworld,[]
web1o1/pixi.js,[]
birthcat/HelloWorld,[]
webner/nginx-proxy,[]
s3r4ph/PySplice,[]
makerspacelt/car-usb-charger,[]
hioxxo/radiojavandownloader,[]
alanmcna/heat_templates,[]
dbhys/com.dbhys,[]
Ivshti/awesome-hacking-spots,[]
du5t/char-custom,[]
slimchrisp/bootstrap_cms,[]
skeeet/iOSAppReverseEngineering,[]
ajsondev/fullcalendar,[]
zen-np/np-log,[]
kragen/zxing,[]
Davidmeng78/PPRE,[]
SebastienGaspar/Gecko,[]
maquanyi/crew,[]
marcelobarretto/docker-tomcat-mysql,[]
delgadom/lptutorial,[]
zcrutherford/zhangchao,[]
sampanelaid/panelteam,[]
NodeTutorials/express.js-intro,[]
hubertod/MarketWatcher,[]
GameDevBlizzardThread/game,[]
RagnarDanneskjold/bitbot,[]
deependragit/testing,[]
kennethormandy/default,[]
renqiaoyang/www,[]
pjcnunes/ADS2017,[]
drewhammond/idea-gulp,[]
basilajith/python,[]
pedro/active_merchant,[]
baiyanghese/angular.js,[]
kemalacar/mediaplayer_plugin,[]
ridesoftech/videoconf,[]
airate/docker-base,[]
Galves96/CP,[]
ibanezz/GitDemo,[]
vpayno/md-api-perl,[]
AnujaK/chrome-dropbox-oauth,[]
tcalmant/nao-iotdays-2015,[]
adyates/steamalytics,[]
Remnaut/DungeonCrawler,[]
FireFlyDreamWorks/aladino,[]
active-interest/reverse-proxy-comment-ip-fix,[]
pataquets/docker-supervisor,[]
Sameer-Shukla/FirstRepo,[]
gloryministry/.com,[]
iicray/Rails-102,[]
mrblabs/vitwitter.net,[]
mardann/randomNumGeneratorNonReacuring,[]
PaperHat/programmer-training,[]
eahrold/Chainables,[]
substruct/mohawk,[]
Chromatophore/MDS,[]
dazzyd/firefox-searchplugins,[]
lutaf/auto-complete,[]
dayler/nuevatel.common,[]
nwgat/nodejs-rtorrent-installer,[]
collabx/LegalComponents,[]
4everdunn/phonefix,[]
eos-org/autoload,[]
devendradhanal/T,[]
metavida/Multi-Firefox-Launcher,[]
yjchou/polar,[]
andreaslindeboom/padlock,[]
mewiteor/algorithm,[]
refactorthis/acute.js,[]
inshideru/datasciencecoursera,[]
sysb-io/sysbio-gallery,[]
manutddidaka/Moments-in-Space,[]
mako-taco/react-components,[]
ajaycode/docker-cheat-sheet,[]
icyflame/install-from-source-tmux-2-0,[]
hcp4715/AnalyzingExpData,[]
nishant-jain-94/QuizRT,[]
therebelrobot/hublog,[]
cheaboar/my,[]
zarathustra1/Tom-Shelling,[]
bobalazek/open-model,[]

2025-02-12 18:33:45 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:45 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:45 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:47 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:47 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:47 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:47 - root - INFO - SQL:
SELECT DISTINCT c."sample_repo_name", l."language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c
   JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
     ON c."sample_repo_name" = l."repo_name"
   WHERE c."sample_path" = 'README.md' AND c."binary" = FALSE
   LIMIT 100;
Results:
Too long, hard cut:
sample_repo_name,language
OfficeDev/Product-List-Code-Sample,"[
  {
    ""bytes"": 113,
    ""name"": ""ASP""
  },
  {
    ""bytes"": 114173,
    ""name"": ""C#""
  },
  {
    ""bytes"": 685,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 735,
    ""name"": ""Gherkin""
  },
  {
    ""bytes"": 5125,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 15651,
    ""name"": ""JavaScript""
  }
]"
OscarES/Differential-Algebra-Tracker,"[
  {
    ""bytes"": 126345,
    ""name"": ""Python""
  }
]"
kluivers/jbw-builders,"[
  {
    ""bytes"": 3702,
    ""name"": ""Objective-C""
  },
  {
    ""bytes"": 651,
    ""name"": ""Ruby""
  }
]"
polomoshnov/jQuery-UI-Resizable-Snap-extension,"[
  {
    ""bytes"": 5130,
    ""name"": ""JavaScript""
  }
]"
himanshu-soni/image-intent-handler,"[
  {
    ""bytes"": 14053,
    ""name"": ""Java""
  }
]"
paul999/433.92-Raspberry-Pi,"[
  {
    ""bytes"": 283987,
    ""name"": ""C""
  },
  {
    ""bytes"": 2930,
    ""name"": ""C++""
  }
]"
mmerian/phpcrawl,"[
  {
    ""bytes"": 746,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 2711,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 307285,
    ""name"": ""PHP""
  }
]"
adafruit/Adafruit-Trinket-Gemma-Bootloader,"[
  {
    ""bytes"": 13210,
    ""name"": ""Assembly""
  },
  {
    ""bytes"": 105486,
    ""name"": ""C""
  },
  {
    ""bytes"": 6507,
    ""name"": ""C++""
  },
  {
    ""bytes"": 4870,
    ""name"": ""Objective-C""
  }
]"
otoolep/gosf-rqlite,[]
jconst/JCDialPad,"[
  {
    ""bytes"": 27797,
    ""name"": ""Objective-C""
  },
  {
    ""bytes"": 1001,
    ""name"": ""Ruby""
  }
]"
sskyy/redux-task,"[
  {
    ""bytes"": 30357,
    ""name"": ""JavaScript""
  }
]"
Moq/moq,"[
  {
    ""bytes"": 120765,
    ""name"": ""C#""
  }
]"
CESNET/owncloud-theme,"[
  {
    ""bytes"": 881,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 12158,
    ""name"": ""PHP""
  }
]"
VeliovGroup/Meteor-logger,"[
  {
    ""bytes"": 18154,
    ""name"": ""JavaScript""
  }
]"
jsonld-java/jsonld-java-tools,"[
  {
    ""bytes"": 28759,
    ""name"": ""Java""
  },
  {
    ""bytes"": 553,
    ""name"": ""Shell""
  }
]"
wahern/cqueues,"[
  {
    ""bytes"": 683720,
    ""name"": ""C""
  },
  {
    ""bytes"": 92480,
    ""name"": ""Lua""
  },
  {
    ""bytes"": 4096,
    ""name"": ""M4""
  },
  {
    ""bytes"": 18317,
    ""name"": ""Makefile""
  },
  {
    ""bytes"": 65362,
    ""name"": ""Shell""
  }
]"
analog-nico/passport-pinterest,"[
  {
    ""bytes"": 10193,
    ""name"": ""JavaScript""
  }
]"
Hexworks/hexameter,[]
johnpneumann/portable-maya-prefs,"[
  {
    ""bytes"": 51064,
    ""name"": ""Shell""
  }
]"
kittens/lerna,"[
  {
    ""bytes"": 33925,
    ""name"": ""JavaScript""
  }
]"
ha/doozerd,"[
  {
    ""bytes"": 1453,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 162957,
    ""name"": ""Go""
  },
  {
    ""bytes"": 3693,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 5340,
    ""name"": ""Shell""
  }
]"
keithwhor/cmnd,"[
  {
    ""bytes"": 5766,
    ""name"": ""JavaScript""
  }
]"
delight-im/OpenSoccer,"[
  {
    ""bytes"": 724,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 63,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 9754,
    ""name"": ""Java""
  },
  {
    ""bytes"": 596,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 1121630,
    ""name"": ""PHP""
  }
]"
mozilla/oneanddone,[]
ravl1084/TJ2PDF,"[
  {
    ""bytes"": 9094,
    ""name"": ""Java""
  }
]"
JuliaDB/MySQL.jl,"[
  {
    ""bytes"": 219575,
    ""name"": ""Julia""
  }
]"
shenxgan/xblog,"[
  {
    ""bytes"": 6051,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 9991,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 14695,
    ""name"": ""Python""
  }
]"
Swader/diffbot-php-client,"[
  {
    ""bytes"": 258473,
    ""name"": ""PHP""
  }
]"
rluders/phaser-skeleton,"[
  {
    ""bytes"": 655,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 861,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 1471,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 396,
    ""name"": ""TypeScript""
  }
]"
hosom/bro-file-extraction,"[
  {
    ""bytes"": 7496,
    ""name"": ""Bro""
  }
]"
winunet/Hui,"[
  {
    ""bytes"": 227987,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 2142885,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 354049,
    ""name"": ""JavaScript""
  }
]"
LI-COR/eddypro-engine,"[
  {
    ""bytes"": 303,
    ""name"": ""Batchfile""
  },
  {
    ""bytes"": 1448,
    ""name"": ""C++""
  },
  {
    ""bytes"": 2896251,
    ""name"": ""Fortran""
  },
  {
    ""bytes"": 20475,
    ""name"": ""Makefile""
  },
  {
    ""bytes"": 2320,
    ""name"": ""Pascal""
  },
  {
    ""bytes"": 107,
    ""name"": ""SourcePawn""
  }
]"
blond/hash-set,"[
  {
    ""bytes"": 12343,
    ""name"": ""JavaScript""
  }
]"
rogpeppe/showdeps,"[
  {
    ""bytes"": 10282,
    ""name"": ""Go""
  }
]"
qt-pods/qt-pods,"[
  {
    ""bytes"": 58043,
    ""name"": ""C++""
  },
  {
    ""bytes"": 9639,
    ""name"": ""QMake""
  }
]"
JSSolutions/meteor-google-prediction,"[
  {
    ""bytes"": 3755,
    ""name"": ""JavaScript""
  }
]"
johnham

2025-02-12 18:33:47 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:47 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:47 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:48 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:48 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:48 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:49 - root - INFO - SQL:
SELECT l."repo_name", lang.VALUE::STRING AS "language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
   LATERAL FLATTEN(input => l."language") lang
   LIMIT 100;
Results:
Too long, hard cut:
repo_name,language
yyuu/antismoker,"{""bytes"":24665,""name"":""Ruby""}"
yyuu/antismoker,"{""bytes"":164,""name"":""Shell""}"
itakurara/gem_mamezo,"{""bytes"":1994,""name"":""Ruby""}"
itakurara/gem_mamezo,"{""bytes"":115,""name"":""Shell""}"
klriutsa/e_stat,"{""bytes"":3585,""name"":""Ruby""}"
klriutsa/e_stat,"{""bytes"":131,""name"":""Shell""}"
rmcfadzean/jekyll-codepen,"{""bytes"":5232,""name"":""Ruby""}"
rmcfadzean/jekyll-codepen,"{""bytes"":420,""name"":""Shell""}"
kitlangton/pessimist,"{""bytes"":2329,""name"":""Ruby""}"
kitlangton/pessimist,"{""bytes"":115,""name"":""Shell""}"
bjjb/ordu,"{""bytes"":1715,""name"":""Ruby""}"
bjjb/ordu,"{""bytes"":131,""name"":""Shell""}"
sajjadROR/extra_attributes_for_all_migration,"{""bytes"":2578,""name"":""Ruby""}"
sajjadROR/extra_attributes_for_all_migration,"{""bytes"":115,""name"":""Shell""}"
space-pirates-llc/quill-builder,"{""bytes"":14983,""name"":""Ruby""}"
space-pirates-llc/quill-builder,"{""bytes"":131,""name"":""Shell""}"
jt-platterz/slack_messenger,"{""bytes"":7726,""name"":""Ruby""}"
jt-platterz/slack_messenger,"{""bytes"":131,""name"":""Shell""}"
aquinofb/checkout,"{""bytes"":13565,""name"":""Ruby""}"
aquinofb/checkout,"{""bytes"":131,""name"":""Shell""}"
esender/ffaker,"{""bytes"":301045,""name"":""Ruby""}"
esender/ffaker,"{""bytes"":60,""name"":""Shell""}"
harshniketseta/marvels,"{""bytes"":2172,""name"":""Ruby""}"
harshniketseta/marvels,"{""bytes"":115,""name"":""Shell""}"
catalin-enache/ntk_dockerfile,"{""bytes"":192,""name"":""Ruby""}"
catalin-enache/ntk_dockerfile,"{""bytes"":182,""name"":""Shell""}"
chef/knife-linode,"{""bytes"":40951,""name"":""Ruby""}"
chef/knife-linode,"{""bytes"":455,""name"":""Shell""}"
qilab-/vagrant-cdh4.5,"{""bytes"":662,""name"":""Ruby""}"
qilab-/vagrant-cdh4.5,"{""bytes"":1229,""name"":""Shell""}"
carney520/crawler,"{""bytes"":53286,""name"":""Ruby""}"
carney520/crawler,"{""bytes"":115,""name"":""Shell""}"
alu0100789355/prct09,"{""bytes"":21138,""name"":""Ruby""}"
alu0100789355/prct09,"{""bytes"":115,""name"":""Shell""}"
ConPaaS-team/conpaas-docker-images,"{""bytes"":412,""name"":""Ruby""}"
ConPaaS-team/conpaas-docker-images,"{""bytes"":5403,""name"":""Shell""}"
dreamingechoes/bootstrap_sb_admin_base_v2,"{""bytes"":1858,""name"":""Ruby""}"
dreamingechoes/bootstrap_sb_admin_base_v2,"{""bytes"":115,""name"":""Shell""}"
wickles/homebrew-cask,"{""bytes"":2140657,""name"":""Ruby""}"
wickles/homebrew-cask,"{""bytes"":56584,""name"":""Shell""}"
pressable/chef-hipchat-cli,"{""bytes"":5169,""name"":""Ruby""}"
pressable/chef-hipchat-cli,"{""bytes"":2128,""name"":""Shell""}"
gnawhleinad/youtube,"{""bytes"":29,""name"":""Ruby""}"
gnawhleinad/youtube,"{""bytes"":1171,""name"":""Shell""}"
se3000/ruby-eth,"{""bytes"":69565,""name"":""Ruby""}"
se3000/ruby-eth,"{""bytes"":131,""name"":""Shell""}"
jayceeb/remote_syslog2-cookbook,"{""bytes"":3392,""name"":""Ruby""}"
jayceeb/remote_syslog2-cookbook,"{""bytes"":2109,""name"":""Shell""}"
cosmo0920/ansible-playbook-for-keter-deploy,"{""bytes"":3250,""name"":""Ruby""}"
cosmo0920/ansible-playbook-for-keter-deploy,"{""bytes"":316,""name"":""Shell""}"
egjiri/database_syncer,"{""bytes"":3929,""name"":""Ruby""}"
egjiri/database_syncer,"{""bytes"":115,""name"":""Shell""}"
can-explore/geojson_model,"{""bytes"":8272,""name"":""Ruby""}"
can-explore/geojson_model,"{""bytes"":115,""name"":""Shell""}"
yast/yast-storage-ng,"{""bytes"":5753311,""name"":""Ruby""}"
yast/yast-storage-ng,"{""bytes"":2203,""name"":""Shell""}"
alu0100611281/LPP_32_prct09,"{""bytes"":10513,""name"":""Ruby""}"
alu0100611281/LPP_32_prct09,"{""bytes"":115,""name"":""Shell""}"
obsidian-btc/http-commands,"{""bytes"":22977,""name"":""Ruby""}"
obsidian-btc/http-commands,"{""bytes"":2912,""name"":""Shell""}"
guttertec/vagrant-template,"{""bytes"":124,""name"":""Ruby""}"
guttertec/vagrant-template,"{""bytes"":0,""name"":""Shell""}"
altV/interleave,"{""bytes"":2176,""name"":""Ruby""}"
altV/interleave,"{""bytes"":131,""name"":""Shell""}"
phoet/memo-it,"{""bytes"":9556,""name"":""Ruby""}"
phoet/memo-it,"{""bytes"":131,""name"":""Shell""}"
dimko/carrierwave-jpegtran,"{""bytes"":3917,""name"":""Ruby""}"
dimko/carrierwave-jpegtran,"{""bytes"":66,""name"":""Shell""}"
kuldeepaggarwal/arel_extension,"{""bytes"":6601,""name"":""Ruby""}"
kuldeepaggarwal/arel_extension,"{""bytes"":115,""name"":""Shell""}"
nalabjp/mysql_import,"{""bytes"":21440,""name"":""Ruby""}"
nalabjp/mysql_import,"{""bytes"":290,""name"":""Shell""}"
marcojonker/test,"{""bytes"":156103,""name"":""Ruby""}"
marcojonker/test,"{""bytes"":1517,""name"":""Shell""}"
akuzko/parascope,"{""bytes"":24482,""name"":""Ruby""}"
akuzko/parascope,"{""bytes"":131,""name"":""Shell""}"
DivineDominion/zettel-outline-rendering,"{""bytes"":20436,""name"":""Ruby""}"
DivineDominion/zettel-outline-rendering,"{""bytes"":131,""name"":""Shell""}"
cyphactor/octopusci,"{""bytes"":84848,""name"":""Ruby""}"
cyphactor/octopusci,"{""bytes"":915,""name"":""Shell""}"
bogdan14x/d3raw,"{""bytes"":11054,""name"":""Ruby""}

2025-02-12 18:33:49 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:49 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:49 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:50 - snowflake.connector.cursor - INFO - Number of results in first chunk: 27
2025-02-12 18:33:51 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:51 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:51 - root - INFO - SQL:
SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE AND "content" IS NOT NULL
   LIMIT 100;
Results:
Too long, hard cut:
content
"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][django-browserid], a.k.a. Mozilla Pe

2025-02-12 18:33:51 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:51 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:51 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:53 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:53 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:53 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:53 - root - INFO - SQL:
SELECT c."sample_repo_name", line.VALUE::STRING AS "line"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md' AND c."binary" = FALSE AND c."content" IS NOT NULL
    LIMIT 100;
Results:
Too long, hard cut:
sample_repo_name,line
velveteer/mithril-boilerplate,## Mithril Boilerplate
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,This is a quick starter template coupled with NodeJS build tools for projects that want to use Leo Horie's
velveteer/mithril-boilerplate,[Mithril](http://lhorie.github.io/mithril/index.html) framework.
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,Features include:
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,+ Gulpfile and modular tasks via [gulp-starter](https://github.com/greypants/gulp-starter)
velveteer/mithril-boilerplate,+ Bower support -- wire dependencies with [wiredep](https://github.com/taptapship/wiredep)
velveteer/mithril-boilerplate,+ Browserify for CommonJS modules (Mithril is installed from NPM)
velveteer/mithril-boilerplate,+ JSHint and JSCS linting
velveteer/mithril-boilerplate,+ LESS support (easily swapped with your preproc of choice)
velveteer/mithril-boilerplate,+ Connect server with LiveReload
velveteer/mithril-boilerplate,+ Proxy middleware for local/external API calls and mocks using [connect-prism](https://github.com/seglo/connect-prism)
velveteer/mithril-boilerplate,+ Connect middleware for HTML5 pushState fallback (for pathname routes)
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,### Requirements
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,+ NodeJS and NPM
velveteer/mithril-boilerplate,+ Bower (optional)
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,### Install and use
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,`npm install`
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,`gulp watch`
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,Now you should see the example Mithril app at [http://localhost:9000](http://localhost:9000)
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,# Gulp Tasks
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,- Run `gulp watch` to get local development started.
velveteer/mithril-boilerplate,- Run `gulp build` to build a distribution.
velveteer/mithril-boilerplate,- Run `gulp wiredep` to add new bower dependencies to your index.html.
velveteer/mithril-boilerplate,
atom/node-ctags,# Ctags Node module [![Build Status](https://travis-ci.org/atom/node-ctags.png)](https://travis-ci.org/atom/node-ctags)
atom/node-ctags,
atom/node-ctags,Read all about ctags [here](http://ctags.sourceforge.net/).
atom/node-ctags,
atom/node-ctags,## Installing
atom/node-ctags,
atom/node-ctags,```sh
atom/node-ctags,npm install ctags
atom/node-ctags,```
atom/node-ctags,
atom/node-ctags,## Building
atom/node-ctags,  * Clone the repository
atom/node-ctags,  * Run `npm install`
atom/node-ctags,  * Run `grunt` to compile the native and CoffeeScript code
atom/node-ctags,  * Run `grunt test` to run the specs
atom/node-ctags,
atom/node-ctags,## Documentation
atom/node-ctags,
atom/node-ctags,"### findTags(tagsFilePath, tag, [options], callback)"
atom/node-ctags,
atom/node-ctags,Get all tags matching the tag specified from the tags file at the path.
atom/node-ctags,
atom/node-ctags,* `tagsFilePath` - The string path to the tags file.
atom/node-ctags,
atom/node-ctags,* `tag` - The string name of the tag to search for.
atom/node-ctags,
atom/node-ctags,* `options` - An optional options object containing the following keys:
atom/node-ctags,
atom/node-ctags,"  * `caseInsensitive` - `true` to include tags that match case insensitively,"
atom/node-ctags,    (default: `false`)
atom/node-ctags,  * `partialMatch` - `true` to include tags that partially match the given tag
atom/node-ctags,    (default: `false`)
atom/node-ctags,
atom/node-ctags,* `callback` - The function to call when complete with an error as the first
atom/node-ctags,             argument and an array containing objects that have `name` and
atom/node-ctags,             `file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,             specified contains tag patterns.
atom/node-ctags,
atom/node-ctags,#### Example
atom/node-ctags,
atom/node-ctags,```coffeescript
atom/node-ctags,ctags = require 'ctags'
atom/node-ctags,
atom/node-ctags,"ctags.findTags('/Users/me/repos/node/tags', 'exists', (error, tags=[]) ->"
atom/node-ctags,  for tag in tags
atom/node-ctags,"    console.log(""#{tag.name} is in #{tag.file}"")"
atom/node-ctags,```
atom/node-ctags,
atom/node-ctags,"### createReadStream(tagsFilePath, [options])"
atom/node-ctags,
atom/node-ctags,Create a read stream to a tags file.
atom/node-ctags,
atom/node-ctags,The stream returned will emit `data` events with arrays of tag objects
atom/node-ctags,that have `name` and `file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,specified contains tag patterns.
atom/node-ctags,
atom/node-ctags,An `error` event will be emitted if the tag file cannot be read.
atom/node-ctags,
atom/node-ctags,An `end` event will be emitted when all the tags have been read.
atom/node-ctags,
atom/node-c

2025-02-12 18:33:53 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:53 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:53 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:55 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:55 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:56 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:56 - root - INFO - SQL:
SELECT c."sample_repo_name", TRIM(line.VALUE::STRING) AS "line"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.VALUE::STRING) != ''
      AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
      AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    LIMIT 100;
Results:
Too long, hard cut:
sample_repo_name,line
velveteer/mithril-boilerplate,This is a quick starter template coupled with NodeJS build tools for projects that want to use Leo Horie's
velveteer/mithril-boilerplate,[Mithril](http://lhorie.github.io/mithril/index.html) framework.
velveteer/mithril-boilerplate,Features include:
velveteer/mithril-boilerplate,+ Gulpfile and modular tasks via [gulp-starter](https://github.com/greypants/gulp-starter)
velveteer/mithril-boilerplate,+ Bower support -- wire dependencies with [wiredep](https://github.com/taptapship/wiredep)
velveteer/mithril-boilerplate,+ Browserify for CommonJS modules (Mithril is installed from NPM)
velveteer/mithril-boilerplate,+ JSHint and JSCS linting
velveteer/mithril-boilerplate,+ LESS support (easily swapped with your preproc of choice)
velveteer/mithril-boilerplate,+ Connect server with LiveReload
velveteer/mithril-boilerplate,+ Proxy middleware for local/external API calls and mocks using [connect-prism](https://github.com/seglo/connect-prism)
velveteer/mithril-boilerplate,+ Connect middleware for HTML5 pushState fallback (for pathname routes)
velveteer/mithril-boilerplate,+ NodeJS and NPM
velveteer/mithril-boilerplate,+ Bower (optional)
velveteer/mithril-boilerplate,`npm install`
velveteer/mithril-boilerplate,`gulp watch`
velveteer/mithril-boilerplate,Now you should see the example Mithril app at [http://localhost:9000](http://localhost:9000)
velveteer/mithril-boilerplate,- Run `gulp watch` to get local development started.
velveteer/mithril-boilerplate,- Run `gulp build` to build a distribution.
velveteer/mithril-boilerplate,- Run `gulp wiredep` to add new bower dependencies to your index.html.
atom/node-ctags,Read all about ctags [here](http://ctags.sourceforge.net/).
atom/node-ctags,```sh
atom/node-ctags,npm install ctags
atom/node-ctags,```
atom/node-ctags,* Clone the repository
atom/node-ctags,* Run `npm install`
atom/node-ctags,* Run `grunt` to compile the native and CoffeeScript code
atom/node-ctags,* Run `grunt test` to run the specs
atom/node-ctags,Get all tags matching the tag specified from the tags file at the path.
atom/node-ctags,* `tagsFilePath` - The string path to the tags file.
atom/node-ctags,* `tag` - The string name of the tag to search for.
atom/node-ctags,* `options` - An optional options object containing the following keys:
atom/node-ctags,"* `caseInsensitive` - `true` to include tags that match case insensitively,"
atom/node-ctags,(default: `false`)
atom/node-ctags,* `partialMatch` - `true` to include tags that partially match the given tag
atom/node-ctags,(default: `false`)
atom/node-ctags,* `callback` - The function to call when complete with an error as the first
atom/node-ctags,argument and an array containing objects that have `name` and
atom/node-ctags,`file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,specified contains tag patterns.
atom/node-ctags,```coffeescript
atom/node-ctags,ctags = require 'ctags'
atom/node-ctags,"ctags.findTags('/Users/me/repos/node/tags', 'exists', (error, tags=[]) ->"
atom/node-ctags,for tag in tags
atom/node-ctags,"console.log(""#{tag.name} is in #{tag.file}"")"
atom/node-ctags,```
atom/node-ctags,Create a read stream to a tags file.
atom/node-ctags,The stream returned will emit `data` events with arrays of tag objects
atom/node-ctags,that have `name` and `file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,specified contains tag patterns.
atom/node-ctags,An `error` event will be emitted if the tag file cannot be read.
atom/node-ctags,An `end` event will be emitted when all the tags have been read.
atom/node-ctags,* `tagsFilePath` - The string path to the tags file.
atom/node-ctags,* `options` - An optional object containing the following keys.
atom/node-ctags,* `chunkSize` - The number of tags to read at a time (default: `100`).
atom/node-ctags,Returns a stream.
atom/node-ctags,```coffeescript
atom/node-ctags,ctags = require 'ctags'
atom/node-ctags,stream = ctags.createReadStream('/Users/me/repos/node/tags')
atom/node-ctags,"stream.on 'data', (tags) ->"
atom/node-ctags,for tag in tags
atom/node-ctags,"console.log(""#{tag.name} is in #{tag.file} with pattern: #{tag.pattern}"")"
atom/node-ctags,```
bh107/bohrium,Welcome!
bh107/bohrium,========
bh107/bohrium,
bh107/bohrium,[![Build Status](https://travis-ci.org/bh107/bohrium.svg?branch=master)](https://travis-ci.org/bh107/bohrium)
bh107/bohrium,
bh107/bohrium,"Bohrium provides a runtime environment for efficiently executing vectorized applications using your favorourite programming languange Python/NumPy, C#, F# on Linux, Windows and MacOSX."
bh107/bohrium,
bh107/bohrium,"Forget handcrafting CUDA/OpenCL to utilize your GPU, forget threading, mutexes and locks to utilize your multi-core CPU and forget about MPI to program your cluster just Bohrium!"
bh107/bohrium,
bh107/bohrium,Features
bh107/bohrium,--------
bh107/bohrium,|           | Architecture Support                             ||| Frontends     

2025-02-12 18:33:56 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:56 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:56 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:33:57 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:33:57 - snowflake.connector.connection - INFO - closed
2025-02-12 18:33:58 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:33:58 - root - INFO - SQL:
SELECT TRIM(line.VALUE::STRING) AS "line", COUNT(*) AS "occurrence"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.VALUE::STRING) != ''
      AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
      AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    GROUP BY "line"
    ORDER BY "occurrence" DESC
    LIMIT 100;
Results:
line,occurrence
```,410
},133
,68
```javascript,42
```php,37
{,34
});,33
```bash,31
}),26
```js,26
};,24
```sh,23
```scala,18
*/,18
-------------,15
<?php,13
*,12
);,12
/**,12
package com.massivedatascience.clusterer,11
?>,10
```ruby,10
```java,10
```html,10
<hr>,10
============,9
</tr>,9
<tr>,9
========,9
License,8
Image dimensions: 333 x 500,8
$diffbot = new Diffbot('my_token');,8
Author: s_molinari,7
<br />,7
return {,7
"},",7
</a>,7
"ops: BregmanPointOps,",7
``` bash,7
-------,7
* @param ops distance function,7
```,7
```shell,6
```gdscript,6
-----------------,6
<br>,6
public:,6
...,6
==================,6
</td>,6
```rust,6
object KMeans {,6
"<td width=""50%"">",6
Author: swader,6
end,6
---,6
```c++,6
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the,5
```julia,5
=======,5
sb*n*/,5
"console.log(""Service is reporting MUTE=["" +",5
----------,5
* @return  k-means model,5
.build();,5
".identifyAs(""oauth"")",5
but WITHOUT ANY WARRANTY; without even the implied warranty of,5
Example:,5
-----,5
),5
Consultant consultant = Consultant.builder(),5
--------,5
------------,5
"""]"");",5
end,4
var cache = new SuperCache({ttl: 60});,4
```properties,4
```lisp,4
"InstanceId: 0,",4
SB_MODULE(/*a description should go here*/),4
],4
*****,4
==========,4
* @param seed random number seed,4
</p>,4
Installation,4
var Component = require('brindille-component');,4
MainObject(),4
"k: Int,",4
"pointOps: BregmanPointOps,",4
```objc,4
</dependency>,4
"<p align=""center"">",4
Examples:,4
Usage,4
* *extract function*,4
.then( function( response ) {,4
"upnpService.action('GetMute', {",4
``` java,4
<dependency>,4

2025-02-12 18:33:58 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:33:58 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:33:58 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:34:01 - snowflake.connector.connection - INFO - closed
2025-02-12 18:34:01 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:34:55 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:34:55 - root - INFO - The error occurs because the `LATERAL FLATTEN` cannot be used directly after a `JOIN` clause in that manner. In Snowflake SQL, when flattening a variant or array column after a `JOIN`, you should use the `TABLE(FLATTEN(...))` syntax and include it properly in the `FROM` clause or as part of the join.

Here's the corrected SQL query:

```sql
SELECT line_repo."line", ARRAY_AGG(DISTINCT lang."value"::STRING) AS "languages"
FROM (
  SELECT c."sample_repo_name", TRIM(line."value"::STRING) AS "line"
  FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
       TABLE(FLATTEN(input => SPLIT(c."content", '\n'))) line
  WHERE c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line."value"::STRING) != ''
    AND NOT TRIM(line."value"::STRING) LIKE '#%'
    AND NOT TRIM(line."value"::STRING) LIKE '//%'
) line_repo
JOIN (
  SELECT l."repo_name", lang."value"::STRING AS "language"
  FROM "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
       TABLE(FLATTEN(input => l."language")) lang
) l_lang
  ON line_repo."sample_repo_name" = l_lang."repo_name"
GROUP BY line_repo."line"
LIMIT 100;
```

**Explanation:**

- **Adjusting the `LANGUAGES` Table Flattening:**
  - We create a subquery `l_lang` that selects the `repo_name` and flattens the `language` column using `TABLE(FLATTEN(...))`.
  - The `lang."value"` column contains the individual programming languages used in each repository.

- **Joining the Subqueries:**
  - We join the `line_repo` subquery with the `l_lang` subquery on the repository name using `ON line_repo."sample_repo_name" = l_lang."repo_name"`.

- **Aggregating the Languages:**
  - We use `ARRAY_AGG(DISTINCT l_lang."language")` to collect all unique languages associated with each line.

- **Why the Original Error Occurred:**
  - In the original query, `LATERAL FLATTEN` was incorrectly placed directly after the `JOIN` clause, which is not syntactically correct in Snowflake.
  - The `LATERAL` keyword should be used within the `FROM` clause or inside a subquery, not immediately after `JOIN`.

**Additional Notes:**

- **Using `TABLE(FLATTEN(...))`:**
  - In Snowflake, when you need to flatten a variant or array column, you should use `TABLE(FLATTEN(...))` within the `FROM` clause.
  - This function turns the nested data into a lateral view that can be joined or queried directly.

- **Handling the Lines from `README.md`:**
  - We split the content of each `README.md` file into individual lines using `SPLIT(c."content", '\n')`.
  - We flatten this array of lines so that each line becomes a separate row.
  - We filter out empty lines and lines that start with `#` or `//` to exclude comments and empty lines.

- **Collecting and Aggregating Results:**
  - The final result will be a list of non-empty, non-commented lines from `README.md` files.
  - For each line, we have an occurrence count (due to the `GROUP BY`) and a list of programming languages used in the repositories containing that line.

**Sample Output Format:**

```csv
line,languages
line1:str,"[language1:str, language2:str, ...]"
line2:str,"[language3:str, language4:str, ...]"
...
```

*Note*: The `languages` column contains a comma-separated list of programming languages used in repositories where the line appears.

By restructuring the query to correctly flatten the `language` column within a subquery and adjusting the placement of `TABLE(FLATTEN(...))`, we resolve the syntax error and ensure the query runs successfully.
2025-02-12 18:34:55 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:34:55 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:34:55 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:34:56 - snowflake.connector.connection - INFO - closed
2025-02-12 18:34:56 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:35:49 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:35:49 - root - INFO - The error you're encountering is due to incorrect referencing of the `VALUE` column from the `FLATTEN` function and the placement of `LATERAL FLATTEN` in the query. Let's address these issues one at a time.

### **Issue 1: Incorrect Reference to the `VALUE` Column**

In Snowflake, the `FLATTEN` function produces output columns with uppercase names by default (`SEQ`, `KEY`, `PATH`, `INDEX`, `VALUE`). If you reference these columns with double quotes and lowercase letters (e.g., `line."value"`), Snowflake looks for a column named exactly `value`, which does not exist. This results in an "invalid identifier" error.

**Solution:**

- **Use unquoted lowercase identifiers**: Snowflake treats unquoted identifiers as uppercase, so referencing `line.value` will correctly map to the `VALUE` column.
- **Use double quotes with uppercase identifiers**: If you prefer to use double quotes, ensure the casing matches exactly, e.g., `line."VALUE"`.

### **Issue 2: Incorrect Placement of `LATERAL FLATTEN` After `JOIN`

In Snowflake, you cannot place `LATERAL FLATTEN` directly after a `JOIN` clause without including it properly in the `FROM` clause. To use `FLATTEN` after a `JOIN`, you need to incorporate it into a subquery or adjust the `FROM` clause to include it correctly.

**Solution:**

- Flatten the `language` column within a subquery and join the result.
- Ensure that `LATERAL FLATTEN` is placed correctly in the `FROM` clause.

### **Corrected SQL Query**

Here's the corrected query addressing both issues:

```sql
SELECT
  line_repo."line",
  ARRAY_AGG(DISTINCT l_flattened."language" ORDER BY l_flattened."language") AS "languages"
FROM
  (
    SELECT
      c."sample_repo_name",
      TRIM(line.value::STRING) AS "line"
    FROM
      "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
      LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE
      c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.value::STRING) != ''
      AND NOT TRIM(line.value::STRING) LIKE '#%'
      AND NOT TRIM(line.value::STRING) LIKE '//%'
  ) line_repo
  JOIN (
    SELECT
      l."repo_name",
      lang.value::STRING AS "language"
    FROM
      "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
      LATERAL FLATTEN(input => l."language") lang
  ) l_flattened ON line_repo."sample_repo_name" = l_flattened."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  COUNT(*) DESC
LIMIT 100;
```

### **Explanation:**

1. **Referencing the `VALUE` Column Correctly:**

   - **Inner Subquery (`line_repo`):**
     - Replaced `line.VALUE::STRING` with `line.value::STRING`.
     - This ensures that Snowflake interprets `value` correctly as the `VALUE` column from the `FLATTEN` output.

   - **Flattening the `language` Column:**
     - Created a subquery `l_flattened` to flatten the `language` column.
     - Used `lang.value::STRING` to extract individual languages.

2. **Proper Placement of `LATERAL FLATTEN`:**

   - In both subqueries, `LATERAL FLATTEN` is included alongside the table in the `FROM` clause.
   - This ensures that the flattening occurs correctly and the output columns are available for selection.

3. **Collecting and Ordering Languages:**

   - Used `ARRAY_AGG(DISTINCT l_flattened."language" ORDER BY l_flattened."language")` to collect and sort the languages alphabetically.
   - This matches the requirement to have a comma-separated list of programming languages sorted alphabetically.

4. **Ordering the Results by Frequency:**

   - Included `ORDER BY COUNT(*) DESC` to sort the results by the frequency of each line's occurrence in descending order.

### **Sample Output Format:**

```csv
Line,Occurrence,Languages
line1:str,count1:int,"language1_1:str,language1_2:str,..."
line2:str,count2:int,"language2_1:str,language2_2:str,..."
...
```

**Note**: The `Languages` column contains a comma-separated list of programming languages used in repositories where the line appears.

### **Final Notes:**

- **Case Sensitivity in Snowflake:**

  - **Unquoted Identifiers:** Treated as uppercase and are case-insensitive when referenced. For example, `line.value` refers to the `VALUE` column.
  - **Double-Quoted Identifiers:** Treated as case-sensitive. Using `line."value"` looks for a column named exactly `value`, which does not exist in this context.

- **Avoiding Errors:**

  - Ensure that all references to columns from `FLATTEN` are either unquoted or correctly cased if quoted.
  - Place `LATERAL FLATTEN` correctly within the `FROM` clause or subqueries, not directly after `JOIN`.

### **Brief Explanation of the Task Solution:**

The query retrieves all non-empty, non-commented lines from `README.md` files across GitHub repositories. It excludes lines starting with `#` or `//` and counts how often each unique line appears. For each line, it aggregates a list of programming languages used in repositories containing that line, sorts them alphabetically, and orders the results by the frequency of occurrence in descending order.

By correcting the references to the `VALUE` columns and adjusting the placement of `LATERAL FLATTEN`, the query should now execute without errors and produce the desired results in CSV format.
2025-02-12 18:35:49 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:35:49 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:35:49 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:35:50 - snowflake.connector.connection - INFO - closed
2025-02-12 18:35:51 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:36:21 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:36:21 - root - INFO - The error you're encountering is due to incorrect placement and use of the `LATERAL FLATTEN` function after the `JOIN` clause. In Snowflake SQL, you cannot use `LATERAL FLATTEN` directly after a `JOIN` without incorporating it properly into the `FROM` clause.

### **Understanding the Error**

The error messages you received are:

```
SQL compilation error:
syntax error line 3 at position 44 unexpected 'ORDER'.
syntax error line 3 at position 32 unexpected '.'.
```

This indicates that there's a syntax issue near line 3 of your SQL query, specifically around the `LATERAL FLATTEN` usage after the `JOIN`.

### **Problematic Part of the Query**

The problematic part is:

```sql
JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
  ON line_repo."sample_repo_name" = l."repo_name"
LATERAL FLATTEN(input => l."language") lang
```

Placing `LATERAL FLATTEN` directly after a `JOIN` like this is not syntactically correct. In Snowflake, `LATERAL FLATTEN` should be included within the `FROM` clause, either as a comma-separated table or using `JOIN LATERAL`.

### **Solution**

To fix the syntax error, you need to adjust how you're flattening the `language` column from the `LANGUAGES` table. Here's how you can modify your query:

1. **Flatten the `language` column within a subquery (`l_flattened`).**
2. **Join the flattened language subquery with `line_repo`.**
3. **Ensure all column references are correct, especially when dealing with the `FLATTEN` function's output columns.**

### **Corrected SQL Query**

```sql
SELECT
  line_repo."line",
  ARRAY_AGG(DISTINCT l_flat."language" ORDER BY l_flat."language") AS "languages"
FROM
  (
    SELECT
      c."sample_repo_name",
      TRIM(line.value::STRING) AS "line"
    FROM
      "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
      LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE
      c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.value::STRING) != ''
      AND NOT TRIM(line.value::STRING) LIKE '#%'
      AND NOT TRIM(line.value::STRING) LIKE '//%'
  ) line_repo
  JOIN (
    SELECT
      l."repo_name",
      lang.value::STRING AS "language"
    FROM
      "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
      LATERAL FLATTEN(input => l."language") lang
  ) l_flat ON line_repo."sample_repo_name" = l_flat."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  COUNT(*) DESC
LIMIT 100;
```

### **Explanation**

**1. Inner Subquery (`line_repo`):**

- **Splitting Content into Lines:** We split the content of each `README.md` file into individual lines using `SPLIT(c."content", '\n')`.
- **Flattening the Lines:** We flatten this array so each line becomes a separate row.
- **Filtering Lines:**
  - Exclude empty lines: `TRIM(line.value::STRING) != ''`
  - Exclude lines starting with `#` or `//`: `NOT TRIM(line.value::STRING) LIKE '#%'` and `NOT TRIM(line.value::STRING) LIKE '//%'`

**2. Flattening the `language` Column in Subquery (`l_flat`):**

- **Flattening Languages:** We create a subquery `l_flat` where we flatten the `language` column using `LATERAL FLATTEN`.
- **Extracting Languages as Strings:** `lang.value::STRING AS "language"`

**3. Joining the Subqueries:**

- **Joining on Repository Name:** We join `line_repo` with `l_flat` on `sample_repo_name` and `repo_name`.

**4. Aggregating Results:**

- **Grouping by Lines:** `GROUP BY line_repo."line"`
- **Aggregating Languages:** We use `ARRAY_AGG(DISTINCT l_flat."language" ORDER BY l_flat."language")` to create a sorted list of unique languages for each line.

**5. Ordering the Results:**

- **By Frequency:** `ORDER BY COUNT(*) DESC` to order lines by their frequency in descending order.

### **Sample Output Format**

```csv
Line,Languages
"This is a sample line","JavaScript,Python"
"Another line from README","C++,Java"
...
```

- **Line:** The non-empty, non-commented lines from `README.md` files.
- **Languages:** A comma-separated list of programming languages used in repositories containing that line, sorted alphabetically.

### **Additional Notes**

- **Avoiding Syntax Errors:**

  - **Placement of `LATERAL FLATTEN`:** Ensure that `LATERAL FLATTEN` is used within the `FROM` clause or within a subquery, and not directly after a `JOIN`.
  
  - **Correct Column References:** When referencing columns from the `FLATTEN` function, use `value` (unquoted) or `"VALUE"` (quoted in uppercase) to match Snowflake's handling of unquoted identifiers.

- **Case Sensitivity in Snowflake:**

  - **Unquoted Identifiers:** Treated as uppercase by default.
  
  - **Quoted Identifiers:** Case-sensitive and must match the exact column names.

- **Using `ARRAY_AGG` Function:**

  - **Ordering Within `ARRAY_AGG`:** You can sort the aggregated array by specifying `ORDER BY` within `ARRAY_AGG`, like `ARRAY_AGG(DISTINCT l_flat."language" ORDER BY l_flat."language")`.

### **Summary**

The error was due to improper usage of `LATERAL FLATTEN` after the `JOIN` clause and incorrect column references. By restructuring the query to flatten the `language` column within a subquery and correctly joining it, the syntax errors are resolved. The corrected query retrieves the desired information: unique lines from `README.md` files along with the programming languages used in repositories containing those lines, sorted and aggregated as per the requirements.

---

**Note:** Ensure you have the necessary permissions and that the data conforms to any applicable usage policies when running queries on actual datasets.
2025-02-12 18:36:21 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:36:21 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:36:21 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:36:22 - snowflake.connector.connection - INFO - closed
2025-02-12 18:36:23 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:36:23 - root - INFO - SQL:
JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
  ON line_repo."sample_repo_name" = l."repo_name"
LATERAL FLATTEN(input => l."language") lang
Results:
001003 (42000): 01ba593c-0004-9c22-0001-11c301106856: SQL compilation error:
syntax error line 1 at position 0 unexpected 'JOIN'.
2025-02-12 18:36:23 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:36:23 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:36:23 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:36:24 - snowflake.connector.connection - INFO - closed
2025-02-12 18:36:24 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:37:01 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:37:01 - root - INFO - The error you're encountering is due to the incorrect placement of `LATERAL FLATTEN` after the `JOIN` clause. In Snowflake SQL, `LATERAL FLATTEN` cannot be used directly after a `JOIN` without including it properly within the `FROM` clause. To resolve this, we need to flatten the `language` column within a subquery and then join the result back to our main query.

Here's the corrected SQL query:

```sql
SELECT
  line_repo."line",
  COUNT(*) AS "occurrence",
  ARRAY_AGG(DISTINCT languages."language" ORDER BY languages."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) line_repo
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) languages
  ON line_repo."sample_repo_name" = languages."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  "occurrence" DESC
LIMIT 100;
```

**Explanation:**

1. **Flatten the `language` Column in a Subquery (`languages`):**

   - We create a subquery named `languages` where we flatten the `language` column from the `LANGUAGES` table.
   - Within this subquery, we select `l."repo_name"` and `lang.VALUE::STRING AS "language"`.
   - The `LATERAL FLATTEN` function is used within the `FROM` clause of this subquery, which is the correct placement in Snowflake SQL.

2. **Main Subquery to Extract Lines (`line_repo`):**

   - We extract the lines from `README.md` files in the `SAMPLE_CONTENTS` table.
   - Split the contents of each file into lines using `SPLIT(c."content", '\n')` and flatten the result.
   - We trim each line and filter out empty lines and those starting with `#` or `//`.

3. **Joining the Subqueries:**

   - We join `line_repo` and `languages` on the repository name (`line_repo."sample_repo_name" = languages."repo_name"`).
   - This associates each line with the programming languages used in the corresponding repository.

4. **Aggregating Results:**

   - Use `COUNT(*) AS "occurrence"` to calculate how often each unique line appears across all repositories.
   - Use `ARRAY_AGG(DISTINCT languages."language" ORDER BY languages."language") AS "languages"` to get a comma-separated list of programming languages, sorted alphabetically.

5. **Grouping and Ordering:**

   - Group the results by `line_repo."line"` to aggregate data per unique line.
   - Order the results by `"occurrence"` in descending order to list lines by frequency.

**Why This Fix Works:**

- **Proper Placement of `LATERAL FLATTEN`:** By moving the `LATERAL FLATTEN` into the subquery `languages`, we adhere to Snowflake's syntax rules, since `LATERAL FLATTEN` cannot appear directly after a `JOIN`.
  
- **Avoiding Syntax Errors:** This adjustment eliminates the syntax error you encountered and allows the query to execute successfully.

**Sample Output Format:**

The query will output results in the following format:

```csv
line,occurrence,languages
"This is a sample line",5,"[JavaScript, Python]"
"Another example line",3,"[C++, Java, Python]"
...
```

- **line:** The non-empty, non-commented lines from `README.md` files.
- **occurrence:** The number of times each line appears across all repositories.
- **languages:** A list of programming languages used in repositories containing that line, sorted alphabetically.

**Brief Explanation:**

This query retrieves all non-empty, non-commented lines from `README.md` files in GitHub repositories. It excludes lines that are comments or empty. For each unique line, it calculates how often it appears across repositories. It then aggregates a list of programming languages used in repositories containing that line, sorting the languages alphabetically. Finally, it orders the results by the frequency of each line in descending order.

**Final Notes:**

- Ensure that all table and column names are correctly referenced and enclosed in double quotations as needed.
- The usage of `LATERAL FLATTEN` is carefully structured within subqueries to comply with Snowflake's syntax requirements.
- Remember to replace `LIMIT 100` with an appropriate value based on your data size and needs.

By applying these changes, your query should now execute without errors and produce the desired result.
2025-02-12 18:37:01 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:37:01 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:37:01 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:37:02 - snowflake.connector.connection - INFO - closed
2025-02-12 18:37:02 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:37:50 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:37:50 - root - INFO - The error you're encountering is due to the incorrect placement of the `LATERAL FLATTEN` function after the `JOIN` clause. In Snowflake SQL, `LATERAL FLATTEN` cannot be used directly after a `JOIN` without properly incorporating it into the `FROM` clause. This results in a syntax error.

### **Understanding the Error**

The error messages indicate:

```
SQL compilation error:
syntax error line 4 at position 42 unexpected 'ORDER'.
syntax error line 4 at position 30 unexpected '.'.
```

This suggests that there's a syntax issue near line 4 of the query, specifically around the usage of `LATERAL FLATTEN` after the `JOIN`.

### **Issue in Your Query**

The problematic part of your query is:

```sql
JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
  ON line_repo."sample_repo_name" = l."repo_name"
LATERAL FLATTEN(input => l."language") lang
```

In Snowflake, you cannot have `LATERAL FLATTEN` directly following a `JOIN` clause like this. The `FLATTEN` function should be used within the `FROM` clause, not directly after a `JOIN`.

### **Solution**

To fix the error, we need to:

1. **Flatten the `language` column within a subquery or CTE (Common Table Expression).**

2. **Adjust the main query to join with the flattened subquery.**

### **Corrected SQL Query**

Here's the corrected query with explanations:

```sql
SELECT
  line_repo."line",
  COUNT(*) AS "occurrence",
  ARRAY_AGG(DISTINCT lang_flattened."language" ORDER BY lang_flattened."language") AS "languages"
FROM (
  -- Subquery to extract non-empty, non-commented lines from README.md files
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) line_repo
JOIN (
  -- Subquery to flatten the language column from LANGUAGES table
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flattened
  ON line_repo."sample_repo_name" = lang_flattened."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  "occurrence" DESC
LIMIT 100;
```

### **Explanation**

1. **Flattening the `language` Column:**

   - We create a subquery (`lang_flattened`) where we flatten the `language` column from the `LANGUAGES` table.
   - This subquery selects the `repo_name` and each individual `language`.

   ```sql
   SELECT
     l."repo_name",
     lang.VALUE::STRING AS "language"
   FROM
     "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
     LATERAL FLATTEN(input => l."language") lang
   ```

2. **Joining the Subqueries:**

   - We join the `line_repo` subquery (which contains the lines from `README.md` files) with the `lang_flattened` subquery on `sample_repo_name` and `repo_name`.

   ```sql
   JOIN lang_flattened
     ON line_repo."sample_repo_name" = lang_flattened."repo_name"
   ```

3. **Aggregating the Results:**

   - **Counting Occurrences:**
     
     ```sql
     COUNT(*) AS "occurrence"
     ```

   - **Aggregating Languages:**

     - We use `ARRAY_AGG(DISTINCT lang_flattened."language" ORDER BY lang_flattened."language")` to collect a sorted list of unique programming languages associated with each line.

   - **Grouping and Ordering:**

     - We group by `line_repo."line"` to aggregate data for each unique line.
     - We order the results by `"occurrence"` in descending order.

4. **Why This Fix Works:**

   - By moving the `LATERAL FLATTEN` into a subquery, we ensure it is correctly used within the `FROM` clause.
   - This structure complies with Snowflake's syntax requirements, resolving the syntax error.

### **Sample Output Format**

The query will output results in the following CSV format:

```csv
line,occurrence,languages
"Example line from README",10,"[C++,Java,Python]"
"Another line",8,"[JavaScript,TypeScript]"
...
```

- **line**: Non-empty, non-commented lines from `README.md` files.
- **occurrence**: The number of times each unique line appears across all repositories.
- **languages**: A comma-separated list of programming languages used in repositories containing that line, sorted alphabetically.

### **Additional Notes**

- **Proper Use of `LATERAL FLATTEN`:**

  - `LATERAL FLATTEN` should be included in the `FROM` clause alongside the table it operates on.
  - Placing it within a subquery avoids syntax issues and makes the query more readable.

- **Column Aliasing:**

  - In the `lang_flattened` subquery, we alias `lang.VALUE::STRING` as `"language"` for clarity.

- **Ensuring Correct References:**

  - Use the correct table aliases (e.g., `lang_flattened`) when referencing columns in the main query.

- **Ordering the Aggregated Languages:**

  - The `ORDER BY` within `ARRAY_AGG` ensures the list of languages is sorted alphabetically.

- **Testing the Query:**

  - Before running the query on the full dataset, consider testing it on a smaller subset to ensure it works as expected.

### **Final Thoughts**

By restructuring your query to correctly use `LATERAL FLATTEN` within a subquery, you eliminate the syntax error and align with Snowflake's SQL syntax requirements. This adjusted query should execute successfully and provide the desired results.

If you encounter any further issues, please double-check:

- All table names and column names are correctly referenced and enclosed in double quotes where necessary.
- All parentheses, commas, and SQL syntax are correctly placed.
- The data types and structures in your tables match the query's expectations.

---

**Remember:** When working with complex queries, breaking them down into smaller, manageable subqueries can help organize your logic and make debugging easier.
2025-02-12 18:37:50 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:37:50 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:37:50 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:37:51 - snowflake.connector.connection - INFO - closed
2025-02-12 18:37:52 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:38:42 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:38:42 - root - INFO - The error you're encountering:

```
SQL compilation error:
syntax error line 1 at position 0 unexpected 'JOIN'.
```

indicates that the SQL parser is seeing `JOIN` at the very beginning of the statement, which it doesn't expect. This suggests that there might be a missing or misplaced clause before the `JOIN`.

In your query, the issue arises because you're using `LATERAL FLATTEN` directly after the `JOIN` clause without incorporating it properly into the `FROM` clause or wrapping it in a subquery. In Snowflake SQL, `LATERAL FLATTEN` cannot be used directly after a `JOIN` like that.

### **Corrected SQL Query**

Here's the corrected query that addresses the syntax error:

```sql
SELECT
  line_repo."line",
  COUNT(*) AS "occurrence",
  ARRAY_AGG(DISTINCT lang_flat."language" ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) line_repo
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON line_repo."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  "occurrence" DESC
LIMIT 100;
```

### **Explanation**

**1. Flattening the `language` Column in a Subquery (`lang_flat`):**

- We create a subquery `lang_flat` that selects `repo_name` and flattens the `language` array into individual rows.
- This subquery looks like:

  ```sql
  (
    SELECT
      l."repo_name",
      lang.VALUE::STRING AS "language"
    FROM
      "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
      LATERAL FLATTEN(input => l."language") lang
  ) lang_flat
  ```

- By doing this, we avoid placing `LATERAL FLATTEN` directly after a `JOIN`, which is not allowed in Snowflake SQL.

**2. Joining the Flattened Languages with Lines:**

- We join the `line_repo` subquery (which contains the lines from `README.md` files) with the `lang_flat` subquery on the repository name:

  ```sql
  JOIN lang_flat
    ON line_repo."sample_repo_name" = lang_flat."repo_name"
  ```

**3. Aggregating the Results:**

- We group the results by `line_repo."line"` and count the occurrences of each line.
- We use `ARRAY_AGG` to collect all unique languages associated with each line and sort them alphabetically:

  ```sql
  ARRAY_AGG(DISTINCT lang_flat."language" ORDER BY lang_flat."language") AS "languages"
  ```

**4. Ordering the Results:**

- The results are ordered by the frequency of occurrence in descending order:

  ```sql
  ORDER BY
    "occurrence" DESC
  ```

### **Why the Original Error Occurred**

- **Invalid Placement of `LATERAL FLATTEN`:** In your original query, you placed `LATERAL FLATTEN` directly after the `JOIN` clause, which is syntactically incorrect in Snowflake SQL.

  ```sql
  JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
    ON line_repo."sample_repo_name" = l."repo_name"
  LATERAL FLATTEN(input => l."language") lang
  ```

- This leads to the parser expecting a table or subquery after the `JOIN`, but instead, it encounters `LATERAL FLATTEN`, resulting in a syntax error.

### **Key Points**

- **Use `LATERAL FLATTEN` Within the `FROM` Clause:** When flattening data, ensure that `LATERAL FLATTEN` is used within the `FROM` clause, ideally inside a subquery if you're joining tables.

- **Avoid Chaining `LATERAL FLATTEN` Directly After `JOIN`:** Snowflake SQL does not support placing `LATERAL FLATTEN` directly after a `JOIN` without wrapping it appropriately.

- **Subquery Approach:** By moving the flattening logic into subqueries, we can join the results without syntax errors.

### **Sample Output Format**

The query will produce results in the following format:

```csv
line,occurrence,languages
"This is a sample line",5,"[JavaScript,Python]"
"Another useful line",3,"[Java,Scala]"
...
```

- **line:** The unique non-empty, non-commented lines from `README.md` files.
- **occurrence:** The number of times each line appears across all repositories.
- **languages:** A sorted list of programming languages used in repositories containing that line.

### **Additional Notes**

- **Case Sensitivity:** Be mindful of the case sensitivity in Snowflake. Columns produced by `FLATTEN` are in uppercase (e.g., `VALUE`). Reference them accordingly.

- **Usage of `ARRAY_AGG` and `ORDER BY`:** The `ARRAY_AGG` function collects all unique languages, and the `ORDER BY` within it ensures the languages are sorted alphabetically.

- **Testing the Query:** Before running the query on the entire dataset, consider testing with a smaller subset to ensure it works as expected.

### **Conclusion**

By restructuring your query to include the `LATERAL FLATTEN` within a subquery, you align with Snowflake's syntax rules, and the query should execute without errors. This approach ensures that you can retrieve the required data: the unique lines from `README.md` files, their occurrences across repositories, and the programming languages used in those repositories.

---

**Tip:** Always ensure that your SQL queries have the correct syntax, especially when working with functions like `LATERAL FLATTEN`. Placing them correctly within the query structure is crucial for successful execution.
2025-02-12 18:38:42 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:38:42 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:38:42 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:38:43 - snowflake.connector.connection - INFO - closed
2025-02-12 18:38:43 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:38:43 - root - INFO - SQL:
SELECT
  line_repo."line",
  COUNT(*) AS "occurrence",
  ARRAY_AGG(DISTINCT lang_flat."language" ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) line_repo
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON line_repo."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  "occurrence" DESC
LIMIT 100;
Results:
001003 (42000): 01ba593e-0004-9c22-0001-11c301106e6e: SQL compilation error:
syntax error line 4 at position 42 unexpected 'ORDER'.
syntax error line 4 at position 30 unexpected '.'.
2025-02-12 18:38:43 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:38:43 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:38:43 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:38:45 - snowflake.connector.connection - INFO - closed
2025-02-12 18:38:45 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:39:22 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:39:22 - root - INFO - The error you're encountering is due to two main issues in your SQL query:

1. **Incorrect Use of `ORDER BY` Inside `ARRAY_AGG`**
2. **Improper Placement of `LATERAL FLATTEN` After a `JOIN`**

---

### **Issue 1: Incorrect Use of `ORDER BY` Inside `ARRAY_AGG`**

When using `ARRAY_AGG` in Snowflake SQL, if you want to sort the aggregated array, you need to use the `WITHIN GROUP (ORDER BY ...)` clause. The syntax is as follows:

```sql
ARRAY_AGG(DISTINCT expression) WITHIN GROUP (ORDER BY expression)
```

**Your Query:**

```sql
ARRAY_AGG(DISTINCT lang.VALUE::STRING ORDER BY lang.VALUE::STRING) AS "languages"
```

**Problem:**

- Placing `ORDER BY` directly inside `ARRAY_AGG` without `WITHIN GROUP` is incorrect and causes a syntax error.

**Solution:**

- Use the `WITHIN GROUP` clause to specify the ordering.

**Corrected Syntax:**

```sql
ARRAY_AGG(DISTINCT lang.VALUE::STRING) WITHIN GROUP (ORDER BY lang.VALUE::STRING) AS "languages"
```

---

### **Issue 2: Improper Placement of `LATERAL FLATTEN` After a `JOIN`**

In Snowflake SQL, you cannot use `LATERAL FLATTEN` directly after a `JOIN` clause without properly incorporating it into the `FROM` clause. To flatten the `language` column after a `JOIN`, you need to adjust the query to include `LATERAL FLATTEN` correctly.

**Your Query:**

```sql
JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
  ON line_repo."sample_repo_name" = l."repo_name"
LATERAL FLATTEN(input => l."language") lang
```

**Problem:**

- `LATERAL FLATTEN` is placed incorrectly after the `JOIN`, leading to a syntax error.
- Snowflake expects table expressions in the `FROM` clause or after `JOIN` operators, not directly after a `JOIN` without `ON` or `USING`.

**Solution:**

- Use a subquery to flatten the `language` column and then join it.
- Alternatively, use `JOIN LATERAL` to properly join and flatten the `language` column.

---

### **Corrected SQL Query**

Here is the corrected query that addresses both issues:

```sql
SELECT
  line_repo."line",
  ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  -- Extract non-empty, non-commented lines from README.md files
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'  -- Exclude lines starting with '#'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'  -- Exclude lines starting with '//'
) line_repo
JOIN (
  -- Flatten the 'language' column from the 'LANGUAGES' table
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON line_repo."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  line_repo."line"
LIMIT 100;
```

---

### **Explanation of Changes**

1. **Fixed the `ARRAY_AGG` Syntax:**

   - Replaced `ARRAY_AGG(DISTINCT lang.VALUE::STRING ORDER BY lang.VALUE::STRING)` with `ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language")`.
   - Used `WITHIN GROUP (ORDER BY ...)` to correctly specify the ordering within `ARRAY_AGG`.

2. **Adjusted the Placement of `LATERAL FLATTEN`:**

   - Wrapped the flattening of the `language` column in a subquery `lang_flat`:

     ```sql
     (
       SELECT
         l."repo_name",
         lang.VALUE::STRING AS "language"
       FROM
         "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
         LATERAL FLATTEN(input => l."language") lang
     ) lang_flat
     ```

   - This subquery selects each repository name along with its individual programming languages.
   - Joined `line_repo` with `lang_flat` on the repository name.

3. **Referenced the Correct Aliases:**

   - Used `lang_flat."language"` when selecting and ordering the languages.
   - Ensured all table aliases are correctly used throughout the query.

---

### **Sample Output Format**

The query will produce results in the following format:

```csv
line,languages
"First non-commented line from README.md","[C++, Java, Python]"
"Another line from README.md","[JavaScript, TypeScript]"
...
```

- **line**: Non-empty, non-commented lines extracted from `README.md` files.
- **languages**: A sorted array of unique programming languages used in repositories containing that line.

---

### **Additional Notes**

- **Understanding `LATERAL FLATTEN`:**

  - `LATERAL FLATTEN` is used to expand arrays or variants into a set of rows.
  - When used in the `FROM` clause alongside a table, it provides access to the expanded rows.

- **Why Use a Subquery (`lang_flat`):**

  - By placing the flattening operation in a subquery, you can correctly join it with other tables or subqueries.
  - It avoids syntax errors caused by improper placement of `LATERAL FLATTEN`.

- **Ordering Inside `ARRAY_AGG`:**

  - The `WITHIN GROUP (ORDER BY ...)` clause sorts the elements within the aggregated array.
  - This ensures the languages are listed in alphabetical order as required.

---

### **Testing the Query**

- Before running the query on the full dataset, you can test it by limiting the input data (e.g., using `LIMIT` on inner queries) to ensure it works correctly.
- Verify that the results meet your expectations and that the languages are correctly associated with the lines.

---

### **Summary**

By addressing the syntax errors related to the use of `ARRAY_AGG` and the placement of `LATERAL FLATTEN`, the corrected query should now execute successfully and provide the desired results.

- **Corrected the `ARRAY_AGG` function** to use `WITHIN GROUP (ORDER BY ...)`.
- **Adjusted the placement of `LATERAL FLATTEN`** by incorporating it within a subquery.
- **Ensured proper aliasing and references** throughout the query.

---

### **Helpful Tips**

- **Always check function syntax** when encountering errors related to unexpected tokens or syntax.
- **Use subqueries or `JOIN LATERAL`** when flattening arrays after joins.
- **Review documentation** for specific SQL dialects (e.g., Snowflake) to ensure correct usage of functions and clauses.

---

I hope this helps you resolve the errors and achieve the desired results in your SQL query. Let me know if you have any further questions or need additional assistance!
2025-02-12 18:39:22 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:39:22 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:39:22 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:39:23 - snowflake.connector.connection - INFO - closed
2025-02-12 18:39:23 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:40:08 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:40:08 - root - INFO - The error you're encountering:

```
SQL compilation error:
syntax error line 1 at position 0 unexpected 'ARRAY_AGG'.
```

indicates that there's a syntax error at the very beginning of your query, specifically with the use of `ARRAY_AGG` in your `SELECT` statement. The SQL parser was not expecting `ARRAY_AGG` in the way it's written.

---

### **Issue: Incorrect Syntax in `ARRAY_AGG` Function**

In Snowflake SQL, when you want to sort the elements within an `ARRAY_AGG` function, you need to use the `WITHIN GROUP` clause. The correct syntax is:

```sql
ARRAY_AGG(DISTINCT expression) WITHIN GROUP (ORDER BY expression)
```

In your query, you have:

```sql
ARRAY_AGG(DISTINCT lang.VALUE::STRING ORDER BY lang.VALUE::STRING) AS "languages"
```

This syntax is incorrect because the `ORDER BY` clause is placed directly inside `ARRAY_AGG` without the `WITHIN GROUP` clause, leading to a syntax error.

---

### **Solution: Correct the Syntax of `ARRAY_AGG`**

You should adjust your `ARRAY_AGG` function to include the `WITHIN GROUP (ORDER BY ...)` clause. Here's the corrected syntax:

```sql
ARRAY_AGG(DISTINCT lang.VALUE::STRING) WITHIN GROUP (ORDER BY lang.VALUE::STRING) AS "languages"
```

---

### **Additional Issue: Placement of `LATERAL FLATTEN` after `JOIN`**

In Snowflake SQL, you cannot use `LATERAL FLATTEN` directly after a `JOIN` clause without properly incorporating it into the `FROM` clause or using a subquery. To flatten the `language` column, you should wrap it in a subquery and then join it.

---

### **Corrected SQL Query**

Here is the corrected query that addresses both issues:

```sql
SELECT
  line_repo."line",
  ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  -- Extract non-empty, non-commented lines from README.md files
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'    -- Exclude lines starting with '#'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'   -- Exclude lines starting with '//'
) line_repo
JOIN (
  -- Flatten the 'language' column from the 'LANGUAGES' table
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON line_repo."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  line_repo."line"
LIMIT 100;
```

---

### **Explanation of Changes**

1. **Corrected `ARRAY_AGG` Syntax:**

   - Replaced:

     ```sql
     ARRAY_AGG(DISTINCT lang.VALUE::STRING ORDER BY lang.VALUE::STRING) AS "languages"
     ```

     with:

     ```sql
     ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
     ```

   - This uses the correct `ARRAY_AGG` syntax with the `WITHIN GROUP (ORDER BY ...)` clause to sort the aggregated array.

2. **Used Subquery to Flatten `language` Column:**

   - Created a subquery `lang_flat` to flatten the `language` array from the `LANGUAGES` table:

     ```sql
     (
       SELECT
         l."repo_name",
         lang.VALUE::STRING AS "language"
       FROM
         "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
         LATERAL FLATTEN(input => l."language") lang
     ) lang_flat
     ```

   - This avoids syntax errors by properly placing `LATERAL FLATTEN` within the `FROM` clause of a subquery.

3. **Adjusted References:**

   - Replaced `lang.VALUE::STRING` with `lang_flat."language"` throughout the query to match the alias used in the subquery.

4. **Ensured Correct Placement of `LATERAL FLATTEN`:**

   - Ensured `LATERAL FLATTEN` is used within the `FROM` clause and not directly after a `JOIN`.

---

### **Sample Output Format**

The query will produce results in the following format:

```csv
line,languages
"Installation instructions","[C++, Java, Python]"
"Usage","[JavaScript, TypeScript]"
...
```

- **line**: Non-empty, non-commented lines extracted from `README.md` files.
- **languages**: An array of unique programming languages, sorted alphabetically, used in repositories containing that line.

---

### **Additional Notes**

- **Understanding `WITHIN GROUP (ORDER BY ...)`:**

  - The `WITHIN GROUP` clause allows you to specify the order of elements within the aggregated array.
  - This is necessary when you want to sort the array elements.

- **Proper Use of `LATERAL FLATTEN`:**

  - `LATERAL FLATTEN` should be used within the `FROM` clause, either directly or within a subquery.
  - Avoid placing `LATERAL FLATTEN` directly after a `JOIN` without incorporating it properly.

- **Column References and Aliases:**

  - Ensure that all column references use the correct alias, especially after flattening.
  - In this case, we use `lang_flat."language"` in the `SELECT` and `ARRAY_AGG` clauses.

- **Potential Case Sensitivity:**

  - Be mindful of case sensitivity when referencing columns.
  - Columns produced by `FLATTEN` are in uppercase (e.g., `VALUE`), so using unquoted lowercase identifiers may lead to errors.

---

### **Testing the Query**

- **Sample Run:**

  - Before running the query on the full dataset, you can test it on a smaller subset or with `LIMIT` clauses to ensure it works as expected.

---

### **Conclusion**

By correcting the syntax of the `ARRAY_AGG` function and properly handling the `LATERAL FLATTEN` operations within subqueries, the query should now execute successfully and produce the desired results: a list of unique, non-commented lines from `README.md` files, along with the programming languages used in repositories containing those lines, sorted alphabetically.

---

**Let me know if you have any questions or need further assistance!**
2025-02-12 18:40:08 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:40:08 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:40:08 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:40:09 - snowflake.connector.connection - INFO - closed
2025-02-12 18:40:09 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:40:50 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:40:50 - root - INFO - The error you're encountering:

```
SQL compilation error:
syntax error line 1 at position 0 unexpected 'ARRAY_AGG'.
```

indicates that there's a syntax issue with the use of the `ARRAY_AGG` function in your `SELECT` statement. Specifically, the SQL parser is not expecting `ARRAY_AGG` in the way it's written in your query.

---

### **Issue: Incorrect Syntax in `ARRAY_AGG` Function**

In Snowflake SQL, when you want to sort the elements within an `ARRAY_AGG` function, you need to use the `WITHIN GROUP` clause. The correct syntax is:

```sql
ARRAY_AGG(DISTINCT <expression>) WITHIN GROUP (ORDER BY <expression>)
```

In your query, you have:

```sql
ARRAY_AGG(DISTINCT lang.VALUE::STRING ORDER BY lang.VALUE::STRING) AS "languages"
```

This syntax is incorrect because the `ORDER BY` clause is placed directly inside `ARRAY_AGG` without using the `WITHIN GROUP` clause, causing a syntax error.

---

### **Solution: Correct the Syntax of `ARRAY_AGG`**

To fix the error, you need to adjust the `ARRAY_AGG` function to include the `WITHIN GROUP` clause. Here's the corrected syntax:

```sql
ARRAY_AGG(DISTINCT lang.VALUE::STRING) WITHIN GROUP (ORDER BY lang.VALUE::STRING) AS "languages"
```

---

### **Additional Issue: Placement of `LATERAL FLATTEN` after `JOIN`**

In your query, you have:

```sql
JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
  ON line_repo."sample_repo_name" = l."repo_name"
LATERAL FLATTEN(input => l."language") lang
```

In Snowflake, you cannot use `LATERAL FLATTEN` directly after a `JOIN` clause without properly incorporating it into the `FROM` clause or wrapping it in a subquery. This usage leads to a syntax error.

---

### **Rewriting the Query**

Here's the corrected query that addresses both issues:

```sql
SELECT
  line_repo."line",
  ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  -- Extract non-empty, non-commented lines from README.md files
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'    -- Exclude lines starting with '#'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'   -- Exclude lines starting with '//'
) line_repo
JOIN (
  -- Flatten the 'language' column from the 'LANGUAGES' table
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON line_repo."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  line_repo."line"
LIMIT 100;
```

---

### **Explanation of Changes**

1. **Corrected `ARRAY_AGG` Syntax:**

   - Replaced:

     ```sql
     ARRAY_AGG(DISTINCT lang.VALUE::STRING ORDER BY lang.VALUE::STRING) AS "languages"
     ```

     with:

     ```sql
     ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
     ```

   - This uses the correct `ARRAY_AGG` syntax with the `WITHIN GROUP (ORDER BY ...)` clause to sort the aggregated array.

2. **Used Subquery to Flatten `language` Column:**

   - Created a subquery `lang_flat` to flatten the `language` array from the `LANGUAGES` table:

     ```sql
     (
       SELECT
         l."repo_name",
         lang.VALUE::STRING AS "language"
       FROM
         "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
         LATERAL FLATTEN(input => l."language") lang
     ) lang_flat
     ```

   - This avoids syntax errors by properly placing `LATERAL FLATTEN` within the `FROM` clause of a subquery.

3. **Adjusted References:**

   - Replaced `lang.VALUE::STRING` with `lang_flat."language"` throughout the query to match the alias used in the subquery.

4. **Ensured Correct Placement of `LATERAL FLATTEN`:**

   - Ensured `LATERAL FLATTEN` is used within the `FROM` clause and not directly after a `JOIN`.

---

### **Sample Output Format**

The query will produce results in the following format:

```csv
line,languages
"This is a sample line","[C++, Java, Python]"
"Another line from README","[JavaScript, TypeScript]"
...
```

- **line**: Non-empty, non-commented lines extracted from `README.md` files.
- **languages**: An array of unique programming languages, sorted alphabetically, used in repositories containing that line.

---

### **Additional Notes**

- **Understanding `WITHIN GROUP (ORDER BY ...)`:**

  - The `WITHIN GROUP` clause allows you to specify the order of elements within the aggregated array.
  - This is necessary when you want to sort the array elements in `ARRAY_AGG`.

- **Proper Use of `LATERAL FLATTEN`:**

  - `LATERAL FLATTEN` should be used within the `FROM` clause, either directly or within a subquery.
  - Avoid placing `LATERAL FLATTEN` directly after a `JOIN` without incorporating it properly.

- **Column References and Aliases:**

  - Ensure that all column references use the correct alias, especially after flattening.
  - In this case, we use `lang_flat."language"` in the `SELECT` and `ARRAY_AGG` clauses.

- **Avoiding Case Sensitivity Issues:**

  - Be consistent with column naming and casing.
  - Snowflake is case-sensitive when identifiers are enclosed in double quotes. Make sure that the casing matches exactly.

---

### **Summary**

By correcting the syntax of the `ARRAY_AGG` function and properly handling the `LATERAL FLATTEN` operations within subqueries, the query should now execute successfully and produce the desired results:

- **Extract non-empty, non-commented lines from `README.md` files.**
- **Calculate how often each unique line appears across all repositories.**
- **Return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically.**
- **Order the results by the frequency of occurrence in descending order or by the line text, as specified.**

---

### **Testing the Query**

Before running the query on the full dataset, consider testing it on a smaller subset to ensure it works as expected:

- **Add `LIMIT` clauses to inner queries if needed.**
- **Verify that the results meet your expectations.**

---

### **Let me know if you have any questions or need further assistance!**

---

**Note:** Always ensure that you have the necessary permissions and that your queries comply with any data usage policies applicable to the dataset you're working with.
2025-02-12 18:40:50 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:40:50 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:40:50 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:40:51 - snowflake.connector.connection - INFO - closed
2025-02-12 18:40:51 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:40:51 - root - INFO - SQL:
ARRAY_AGG(DISTINCT <expression>) WITHIN GROUP (ORDER BY <expression>)
Results:
001003 (42000): 01ba5940-0004-9c12-0001-11c30110908e: SQL compilation error:
syntax error line 1 at position 0 unexpected 'ARRAY_AGG'.
2025-02-12 18:40:51 - root - INFO - itercount: 0
2025-02-12 18:40:51 - root - INFO - Database Name: GITHUB_REPOS
Schema Name: GITHUB_REPOS
,0
table_name,SAMPLE_FILES
description,
DDL,"create or replace TABLE SAMPLE_FILES (
	""repo_name"" VARCHAR(16777216),
	""ref"" VARCHAR(16777216),
	""path"" VARCHAR(16777216),
	""mode"" NUMBER(38,0),
	""id"" VARCHAR(16777216),
	""symlink_target"" VARCHAR(16777216)
);"

Database Name: GITHUB_REPOS
Schema Name: GITHUB_REPOS
,1
table_name,LANGUAGES
description,
DDL,"create or replace TABLE LANGUAGES (
	""repo_name"" VARCHAR(16777216),
	""language"" VARIANT
);"

Database Name: GITHUB_REPOS
Schema Name: GITHUB_REPOS
,2
table_name,LICENSES
description,
DDL,"create or replace TABLE LICENSES (
	""repo_name"" VARCHAR(16777216),
	""license"" VARCHAR(16777216)
);"

Database Name: GITHUB_REPOS
Schema Name: GITHUB_REPOS
,3
table_name,SAMPLE_COMMITS
description,
DDL,"create or replace TABLE SAMPLE_COMMITS (
	""commit"" VARCHAR(16777216),
	""tree"" VARCHAR(16777216),
	""parent"" VARIANT,
	""author"" VARIANT,
	""committer"" VARIANT,
	""subject"" VARCHAR(16777216),
	""message"" VARCHAR(16777216),
	""trailer"" VARIANT,
	""difference"" VARIANT,
	""difference_truncated"" BOOLEAN,
	""repo_name"" VARCHAR(16777216),
	""encoding"" VARCHAR(16777216)
);"

Database Name: GITHUB_REPOS
Schema Name: GITHUB_REPOS
,4
table_name,SAMPLE_CONTENTS
description,
DDL,"create or replace TABLE SAMPLE_CONTENTS (
	""id"" VARCHAR(16777216),
	""size"" NUMBER(38,0),
	""content"" VARCHAR(16777216),
	""binary"" BOOLEAN,
	""copies"" NUMBER(38,0),
	""sample_repo_name"" VARCHAR(16777216),
	""sample_ref"" VARCHAR(16777216),
	""sample_path"" VARCHAR(16777216),
	""sample_mode"" NUMBER(38,0),
	""sample_symlink_target"" VARCHAR(16777216)
);"

Database Name: GITHUB_REPOS
Schema Name: GITHUB_REPOS
,5
table_name,SAMPLE_REPOS
description,
DDL,"create or replace TABLE SAMPLE_REPOS (
	""repo_name"" VARCHAR(16777216),
	""watch_count"" NUMBER(38,0)
);"

External knowledge that might be helpful: 
None
The table structure information is ({database name: {schema name: [table name]}}): 
{'GITHUB_REPOS': {'GITHUB_REPOS': ['SAMPLE_FILES', 'LANGUAGES', 'LICENSES', 'SAMPLE_COMMITS', 'SAMPLE_CONTENTS', 'SAMPLE_REPOS']}}
Begin Exploring Related Columns
**Relevant Columns and Potential Usage:**

1. **SAMPLE_CONTENTS**
   - `"content"`: Contains the content of files; needed to extract lines from `README.md` files.
   - `"sample_repo_name"`: The repository name; used to link with the `LANGUAGES` table.
   - `"sample_path"`: The path of the file; used to identify `README.md` files.
   - `"binary"`: Indicates if the file is binary; used to exclude binary files.

2. **LANGUAGES**
   - `"repo_name"`: The repository name; used to join with the `SAMPLE_CONTENTS` table.
   - `"language"`: A `VARIANT` type containing the programming languages used in the repository; needed to list languages.

**Conditions that May Be Used:**

- `SAMPLE_CONTENTS."sample_path" = 'README.md'` or `LIKE '%/README.md'`: To select `README.md` files.
- `SAMPLE_CONTENTS."binary" = FALSE`: To exclude binary files.
- Exclude lines that are empty or start with `#` or `//`: To filter out comments and empty lines.
- Use `TRIM` and `LIKE` for string matching and filtering.

---

**SQL Queries:**

1. **Retrieve distinct repository names from `SAMPLE_CONTENTS`:**

   ```sql
   SELECT DISTINCT "sample_repo_name"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   LIMIT 100;
   ```

2. **List all file paths from `SAMPLE_CONTENTS`:**

   ```sql
   SELECT DISTINCT "sample_path"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   LIMIT 100;
   ```

3. **Select contents of all `README.md` files:**

   ```sql
   SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md'
   LIMIT 100;
   ```

4. **Select contents of `README.md` files, excluding binary files:**

   ```sql
   SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE
   LIMIT 100;
   ```

5. **Retrieve repository names and contents of `README.md` files:**

   ```sql
   SELECT "sample_repo_name", "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE
   LIMIT 100;
   ```

6. **List programming languages used in repositories from `LANGUAGES`:**

   ```sql
   SELECT "repo_name", "language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES"
   LIMIT 100;
   ```

7. **Join repositories with `README.md` files to their programming languages:**

   ```sql
   SELECT DISTINCT c."sample_repo_name", l."language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c
   JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
     ON c."sample_repo_name" = l."repo_name"
   WHERE c."sample_path" = 'README.md' AND c."binary" = FALSE
   LIMIT 100;
   ```

8. **Extract individual programming languages from the `language` VARIANT column:**

   ```sql
   SELECT l."repo_name", lang.VALUE::STRING AS "language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
   LATERAL FLATTEN(input => l."language") lang
   LIMIT 100;
   ```

9. **Select non-null contents of `README.md` files:**

   ```sql
   SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE AND "content" IS NOT NULL
   LIMIT 100;
   ```

10. **Extract individual lines from `README.md` file contents:**

    ```sql
    SELECT c."sample_repo_name", line.VALUE::STRING AS "line"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md' AND c."binary" = FALSE AND c."content" IS NOT NULL
    LIMIT 100;
    ```

11. **Filter out empty lines and comments from extracted lines:**

    ```sql
    SELECT c."sample_repo_name", TRIM(line.VALUE::STRING) AS "line"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.VALUE::STRING) != ''
      AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
      AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    LIMIT 100;
    ```

12. **Count occurrences of each unique line across all repositories:**

    ```sql
    SELECT TRIM(line.VALUE::STRING) AS "line", COUNT(*) AS "occurrence"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.VALUE::STRING) != ''
      AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
      AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    GROUP BY "line"
    ORDER BY "occurrence" DESC
    LIMIT 100;
    ```

13. **Retrieve programming languages for repositories containing each line:**

    ```sql
    SELECT line_repo."line", ARRAY_AGG(DISTINCT lang.VALUE::STRING) AS "languages"
    FROM (
      SELECT c."sample_repo_name", TRIM(line.VALUE::STRING) AS "line"
      FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
      LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
      WHERE c."sample_path" = 'README.md'
        AND c."binary" = FALSE
        AND c."content" IS NOT NULL
        AND TRIM(line.VALUE::STRING) != ''
        AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
        AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    ) line_repo
    JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
      ON line_repo."sample_repo_name" = l."repo_name"
    LATERAL FLATTEN(input => l."language") lang
    GROUP BY line_repo."line"
    LIMIT 100;
    ```

14. **List lines along with their occurrence counts and associated languages, ordered by frequency:**

    ```sql
    SELECT line_repo."line", COUNT(*) AS "occurrence", ARRAY_AGG(DISTINCT lang.VALUE::STRING) AS "languages"
    FROM (
      SELECT c."sample_repo_name", TRIM(line.VALUE::STRING) AS "line"
      FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
      LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
      WHERE c."sample_path" = 'README.md'
        AND c."binary" = FALSE
        AND c."content" IS NOT NULL
        AND TRIM(line.VALUE::STRING) != ''
        AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
        AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    ) line_repo
    JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
      ON line_repo."sample_repo_name" = l."repo_name"
    LATERAL FLATTEN(input => l."language") lang
    GROUP BY line_repo."line"
    ORDER BY "occurrence" DESC
    LIMIT 100;
    ```

15. **Extract and list unique lines with associated languages sorted alphabetically:**

    ```sql
    SELECT line_repo."line", ARRAY_AGG(DISTINCT lang.VALUE::STRING ORDER BY lang.VALUE::STRING) AS "languages"
    FROM (
      SELECT c."sample_repo_name", TRIM(line.VALUE::STRING) AS "line"
      FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
      LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
      WHERE c."sample_path" = 'README.md'
        AND c."binary" = FALSE
        AND c."content" IS NOT NULL
        AND TRIM(line.VALUE::STRING) != ''
        AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
        AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    ) line_repo
    JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
      ON line_repo."sample_repo_name" = l."repo_name"
    LATERAL FLATTEN(input => l."language") lang
    GROUP BY line_repo."line"
    ORDER BY line_repo."line"
    LIMIT 100;
    ```

---

These queries progressively explore the data and build towards understanding how to retrieve and process the necessary information to address the task. They start from simple data retrieval and advance to more complex data manipulation, including joins, aggregations, and filtering based on specific conditions.Query:
SELECT DISTINCT "sample_repo_name"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   LIMIT 100;
Answer:
sample_repo_name
pelya/commandergenius
cloudera/impala-kudu
khasang/SmartForecast
urjaman/flashrom
velo/flexmojos
SnappyDataInc/snappy-store
XyrusWorx/apophysis7x
drdaeman/accel-ppp
tokee/lucene
webscalesql/webscalesql-5.6
CONNECT-Solution/CONNECT
DoSomething/voting-app
apache/sqoop
AbiWord/abiword
meta-debian/meta-debian
Cerberuss/GofPatterns
cloudmatrix/esky
Mygod/Skylark
JHUAPL/AccumuloGraph
vmesel/GeoMath
mapbender/mapbender
sfmskywalker/Orchard
ovh/overthebox-openwrt
Caltech-IPAC/firefly
Kunena/Kunena-Forum
nickkolok/chas-ege
apache/uima-uimaj
apache/sis
bombmanual/bombmanual.github.io
pplante/droidtowers
Nexus-Mods/Nexus-Mod-Manager
jmaih/RISE_toolbox
headwirecom/aem-solr-search
glmcdona/strings2
anycmd/anycmd
linuxdeepin/deepin-wm
mempo/mempo-kernel
apache/qpid-java
ImmobilienScout24/yum-repo-server
gorescript/gorescript
oehf/ipf
findsorguk/findsorguk
garyKeorkunian/squants
Sitecore/Habitat
StefanoFiumara/Harry-Potter-Unity
gr8pefish/IronBackpacks
iridium-browser/iridium-browser-ubuntu
sam408130/Ionic-Demos
Glimpse/Glimpse.Prototype
coinkite/cloudfire
b3dgs/lionengine
Incubaid/arakoon
aspnetboilerplate/aspnetboilerplate
jaquadro/StorageDrawers
Job-Yang/YTZImageComparison
awslabs/aws-sdk-cpp
ghxiao/drew
aasensio/pySIR
epiSurg/EpiSurg
googlei18n/language-resources
crossbario/crossbarexamples
ezScrum/ezScrum
fxos-components/bridge
LibreOffice/core
KDE/krita
mdaniel/virtualbox-org-svn-vbox-trunk
hroptatyr/dateutils
espadrine/opera
digama0/mmj2
nathansttt/hog2
google/binexport
biocaml/biocaml
tatsuhiro-t/aria2
albertz/openlierox
Open-Transport/synthese
danielnaber/openthesaurus
scrollback/io.scrollback.neighborhoods
project-store/theme
sileht/check_mk
umbraco/Umbraco-CMS
nigelsmall/py2neo
Esteemed-Innovation/Flaxbeards-Steam-Power
TheTechnobear/EigenD
sonata-project/sandbox-build
koala-framework/koala-framework
ligaDATA/Kamanja
hiloteam/Hilo
oivva/boxy
ChildrenOfUr/coUclient
timduru/tf300t-katkernel
ChildrenOfUr/coUserver
draios/sysdig
bosonic/bosonic
Ulauncher/Ulauncher
DynamoRIO/drk
google/ktsan
apache/tomcat-native
erasaur/binary
jdahlstrom/vaadin.react
pfirmstone/river-internet
Query:
SELECT DISTINCT "sample_path"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   LIMIT 100;
Answer:
Too long, hard cut:
sample_path
common/thrift/CatalogService.thrift
socketcan_interface/CMakeLists.txt
bin/php7_linux1/bin/mbedtls_dh_client
src/pocketmine/block/Sugarcane.php
Install/Help/commands/3dmaths/SCALE VECTOR2.htm
src/cinder/app/linux/WindowImplLinuxEgl.cpp
libjava/javax/naming/spi/NamingManager.java
lionengine-network/src/main/java/com/b3dgs/lionengine/network/Networker.java
top_down_classifier/src/top_down_classifier/volume_visualizer.h
networking_cisco/neutronclient/policyprofile.py
third-party/org.svnkit/org/tmatesoft/svn/core/internal/wc2/ng/SvnNgRepositoryAccess.class
share/gamedir/levels/ctf_duel2/sprites/flag_y.bmp
aws-cpp-sdk-route53/include/aws/route53/model/CreateTrafficPolicyInstanceRequest.h
backend/colorAdmin/form_editable.html
src/BCR/BCRexternalBWT.cpp
util/robodoc/Source/robodoc.c
myblockchain-test/suite/rpl/r/rpl_loaddata_s.result
myblockchain-test/suite/ndb_rpl/r/ndb_rpl_mixed_tables.result
resources/assets/storagedrawers/textures/blocks/indicator/void_icon.png
GPy/testing/state_space_main_tests.py
tooling/support/provisioning-model/pom.xml
src/java/org/apache/cassandra/db/commitlog/ReplayPosition.java
chrome/browser/signin/about_signin_internals.cc
core/sis-metadata/src/test/java/org/apache/sis/metadata/iso/DefaultMetadataTest.java
src/include/platform.h
lib/padding/pad_variable.m
clients/java/src/main/java/com/senseidb/search/client/req/SenseiClientRequest.java
sal/qa/rtl/strings/test_oustring_compare.cxx
source/stylesheets/modules/_sortable.scss
bin/Skylark.dll.config
pos_position/cv483_16378.txt
src/main/webapp/fonts/DigitalDream/DIGITALDREAMNARROW-webfont.ttf
checks/decru_fans
grails-app/controllers/TagController.groovy
src/libc/stdio/FreeBSD/clrerr.c
CommonProjects/AMDTBaseTools/Include/gtStringTokenizer.h
libs/SDL2_ttf-2.0.14/debian/copyright
lionengine-core/src/main/java/com/b3dgs/lionengine/drawable/Image.java
src/main/resources/templates/layout/app.jade
spec/models/i18n_spec.rb
dbaccess/source/ui/misc/datasourceconnector.cxx
SystemEx/Windows/Forms/IpcHelper.cs
Assets/Scripts/HarryPotterUnity/Cards/Quidditch/Spells/QuickThinking.cs
authmodules/TYPO3/privacyidea/Resources/Private/Language/locallang.xlf
assets/src/scss/components/_logo.scss
Assets/Graphics/Big.psd
Product/Production/Services/PatientDiscoveryCore/src/main/java/gov/hhs/fha/nhinc/patientdiscovery/model/builder/impl/PatientSearchResultsModelBuilderImpl.java
third_party/skia/src/gpu/effects/GrConfigConversionEffect.cpp
deps/icu4c/source/i18n/hebrwcal.cpp
mapfishapp/src/main/java/org/georchestra/mapfishapp/ws/upload/FeatureGeoFileReader.java
uimaj-core/src/main/java/org/apache/uima/collection/CasConsumerDescription.java
whois-endtoend/src/test/java/net/ripe/db/whois/changedphase3/util/Scenario.java
JGTL/JGTL_API/latex/class_j_g_t_l_1_1_hex_tree_branch.tex
resources/CAVP/Vectors/OpenSSL/testvectors.SuSE/testvectors/sha/req/SHA256Monte.req
test/ddiff.052.clit
common/java/core/net/i2p/client/naming/ExecNamingService.java
third_party/skia/src/gpu/gl/GrGLProgram.cpp
pack.cmd
spec/test_app/spec-opal/active_record/update_associations_spec.rb
classes/time_series/@ts/acosh.m
html/partials/compare/os_table.html.haml
app/src/main/res/drawable-xxxhdpi/ic_headphones_grey600_48dp.png
app/src/main/res/drawable/key8.png
src/libs/css/daterangepicker-bs3.css
util/misc/cdna_fasta_file_to_transcript_gtf.pl
docs/html/T_AForge_Video_Ximea_XimeaCamera.htm
chromium/src/third_party/WebKit/Source/modules/webaudio/OfflineAudioDestinationNode.h
Helpers/INRIAEval/data-USA/annotations/set06/V017.vbb
include/bot-logic/behaviour_drive_neuralnet.h
src/Scriban.Tests/TestFiles/100-expressions/150-range-expression.txt
application/var/generation/Magento/AdminNotification/Controller/Adminhtml/Notification/Remove/Interceptor.php
test/VisualStudio.Test/VisualStudio.Test.csproj
subjectivity/objective/default/file4850
conda_manager/__init__.py
Vendor Firmware/Kinetis SDK v.1.3.0 API Reference Manual/fsl__clock__MKV40F15_8h.html
xxl-job-admin/src/main/java/com/xxl/job/admin/core/jobbean/impl/DemoConcurrentJobBean.java
dev.watchr.rb
.settings/org.eclipse.core.resources.prefs
virtual_memory.h
ArcFormats/BlackCyc/ArcGPK.cs
src/main/java/io/mycat/manager/response/ShowSQLSumUser.java
tapestry-core/src/test/java/org/apache/tapestry5/ContentTypeTest.java
vio/vio.c
Modules/BetterCms.Module.Root/Commands/Tag/SaveTag/SaveTagCommand.cs
lib/entities/plants/peatbog.dart
src/filesystem/ZWorkerPool.h
third-party/org.carrot2.api/javadoc/org/carrot2/text/preprocessing/CaseNormalizerDescriptor.Keys.html
core/lib/dr_config.h
ME3Explorer/Resources/property_database_64x64.png
module/plugins/crypter/UploadableChFolder.py
build.xml
content/browser/indexed_db/indexed_db_quota_client.cc
core/sis-referencing/src/main/java/org/apache/sis/referencing/datum/DefaultPrimeMeridian.java
streamingUpdate/seq1.c
grammars/unosln.cson
plugins/BackendTheme/src/Template/Element/settings.ctp
FAQ-USER
commonjs/google-map/map.js
tapestry-core/src/test/java/org/apache/tapestry5/internal/services/RequestPathOptimizer
Query:
SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md'
   LIMIT 100;
Answer:
Too long, hard cut:
content
"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][django-browserid], a.k.a. Mozilla Pe
Query:
SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE
   LIMIT 100;
Answer:
Too long, hard cut:
content
"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][django-browserid], a.k.a. Mozilla Pe
Query:
SELECT "sample_repo_name", "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE
   LIMIT 100;
Answer:
Too long, hard cut:
sample_repo_name,content
mozilla/oneanddone,"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][
Query:
SELECT "repo_name", "language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES"
   LIMIT 100;
Answer:
repo_name,language
konrad/READemption,[]
Duobe/TheFirstOne,[]
andyyardley/SecureO,[]
PGower/Timetabler2SQL,[]
brykmoore/SeniorProject,[]
mpusz/SimpleWorkarounds,[]
lily06280425/lian-,[]
seanarooni/gitignore,[]
mashurex/arduino-tuts,[]
Natashka89/ironpython_training2,[]
Chookahead/Locally-Created-Repo,[]
twiess/hello-world,[]
jasonzissman/Algorithms,[]
pl85s/programming-for_testers,[]
maicki/GDUpload,[]
cyclejs/base,[]
renwei360/-,[]
pedazo/ogo,[]
jsheng258/helloworld,[]
web1o1/pixi.js,[]
birthcat/HelloWorld,[]
webner/nginx-proxy,[]
s3r4ph/PySplice,[]
makerspacelt/car-usb-charger,[]
hioxxo/radiojavandownloader,[]
alanmcna/heat_templates,[]
dbhys/com.dbhys,[]
Ivshti/awesome-hacking-spots,[]
du5t/char-custom,[]
slimchrisp/bootstrap_cms,[]
skeeet/iOSAppReverseEngineering,[]
ajsondev/fullcalendar,[]
zen-np/np-log,[]
kragen/zxing,[]
Davidmeng78/PPRE,[]
SebastienGaspar/Gecko,[]
maquanyi/crew,[]
marcelobarretto/docker-tomcat-mysql,[]
delgadom/lptutorial,[]
zcrutherford/zhangchao,[]
sampanelaid/panelteam,[]
NodeTutorials/express.js-intro,[]
hubertod/MarketWatcher,[]
GameDevBlizzardThread/game,[]
RagnarDanneskjold/bitbot,[]
deependragit/testing,[]
kennethormandy/default,[]
renqiaoyang/www,[]
pjcnunes/ADS2017,[]
drewhammond/idea-gulp,[]
basilajith/python,[]
pedro/active_merchant,[]
baiyanghese/angular.js,[]
kemalacar/mediaplayer_plugin,[]
ridesoftech/videoconf,[]
airate/docker-base,[]
Galves96/CP,[]
ibanezz/GitDemo,[]
vpayno/md-api-perl,[]
AnujaK/chrome-dropbox-oauth,[]
tcalmant/nao-iotdays-2015,[]
adyates/steamalytics,[]
Remnaut/DungeonCrawler,[]
FireFlyDreamWorks/aladino,[]
active-interest/reverse-proxy-comment-ip-fix,[]
pataquets/docker-supervisor,[]
Sameer-Shukla/FirstRepo,[]
gloryministry/.com,[]
iicray/Rails-102,[]
mrblabs/vitwitter.net,[]
mardann/randomNumGeneratorNonReacuring,[]
PaperHat/programmer-training,[]
eahrold/Chainables,[]
substruct/mohawk,[]
Chromatophore/MDS,[]
dazzyd/firefox-searchplugins,[]
lutaf/auto-complete,[]
dayler/nuevatel.common,[]
nwgat/nodejs-rtorrent-installer,[]
collabx/LegalComponents,[]
4everdunn/phonefix,[]
eos-org/autoload,[]
devendradhanal/T,[]
metavida/Multi-Firefox-Launcher,[]
yjchou/polar,[]
andreaslindeboom/padlock,[]
mewiteor/algorithm,[]
refactorthis/acute.js,[]
inshideru/datasciencecoursera,[]
sysb-io/sysbio-gallery,[]
manutddidaka/Moments-in-Space,[]
mako-taco/react-components,[]
ajaycode/docker-cheat-sheet,[]
icyflame/install-from-source-tmux-2-0,[]
hcp4715/AnalyzingExpData,[]
nishant-jain-94/QuizRT,[]
therebelrobot/hublog,[]
cheaboar/my,[]
zarathustra1/Tom-Shelling,[]
bobalazek/open-model,[]
Query:
SELECT DISTINCT c."sample_repo_name", l."language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c
   JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
     ON c."sample_repo_name" = l."repo_name"
   WHERE c."sample_path" = 'README.md' AND c."binary" = FALSE
   LIMIT 100;
Answer:
Too long, hard cut:
sample_repo_name,language
OfficeDev/Product-List-Code-Sample,"[
  {
    ""bytes"": 113,
    ""name"": ""ASP""
  },
  {
    ""bytes"": 114173,
    ""name"": ""C#""
  },
  {
    ""bytes"": 685,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 735,
    ""name"": ""Gherkin""
  },
  {
    ""bytes"": 5125,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 15651,
    ""name"": ""JavaScript""
  }
]"
OscarES/Differential-Algebra-Tracker,"[
  {
    ""bytes"": 126345,
    ""name"": ""Python""
  }
]"
kluivers/jbw-builders,"[
  {
    ""bytes"": 3702,
    ""name"": ""Objective-C""
  },
  {
    ""bytes"": 651,
    ""name"": ""Ruby""
  }
]"
polomoshnov/jQuery-UI-Resizable-Snap-extension,"[
  {
    ""bytes"": 5130,
    ""name"": ""JavaScript""
  }
]"
himanshu-soni/image-intent-handler,"[
  {
    ""bytes"": 14053,
    ""name"": ""Java""
  }
]"
paul999/433.92-Raspberry-Pi,"[
  {
    ""bytes"": 283987,
    ""name"": ""C""
  },
  {
    ""bytes"": 2930,
    ""name"": ""C++""
  }
]"
mmerian/phpcrawl,"[
  {
    ""bytes"": 746,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 2711,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 307285,
    ""name"": ""PHP""
  }
]"
adafruit/Adafruit-Trinket-Gemma-Bootloader,"[
  {
    ""bytes"": 13210,
    ""name"": ""Assembly""
  },
  {
    ""bytes"": 105486,
    ""name"": ""C""
  },
  {
    ""bytes"": 6507,
    ""name"": ""C++""
  },
  {
    ""bytes"": 4870,
    ""name"": ""Objective-C""
  }
]"
otoolep/gosf-rqlite,[]
jconst/JCDialPad,"[
  {
    ""bytes"": 27797,
    ""name"": ""Objective-C""
  },
  {
    ""bytes"": 1001,
    ""name"": ""Ruby""
  }
]"
sskyy/redux-task,"[
  {
    ""bytes"": 30357,
    ""name"": ""JavaScript""
  }
]"
Moq/moq,"[
  {
    ""bytes"": 120765,
    ""name"": ""C#""
  }
]"
CESNET/owncloud-theme,"[
  {
    ""bytes"": 881,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 12158,
    ""name"": ""PHP""
  }
]"
VeliovGroup/Meteor-logger,"[
  {
    ""bytes"": 18154,
    ""name"": ""JavaScript""
  }
]"
jsonld-java/jsonld-java-tools,"[
  {
    ""bytes"": 28759,
    ""name"": ""Java""
  },
  {
    ""bytes"": 553,
    ""name"": ""Shell""
  }
]"
wahern/cqueues,"[
  {
    ""bytes"": 683720,
    ""name"": ""C""
  },
  {
    ""bytes"": 92480,
    ""name"": ""Lua""
  },
  {
    ""bytes"": 4096,
    ""name"": ""M4""
  },
  {
    ""bytes"": 18317,
    ""name"": ""Makefile""
  },
  {
    ""bytes"": 65362,
    ""name"": ""Shell""
  }
]"
analog-nico/passport-pinterest,"[
  {
    ""bytes"": 10193,
    ""name"": ""JavaScript""
  }
]"
Hexworks/hexameter,[]
johnpneumann/portable-maya-prefs,"[
  {
    ""bytes"": 51064,
    ""name"": ""Shell""
  }
]"
kittens/lerna,"[
  {
    ""bytes"": 33925,
    ""name"": ""JavaScript""
  }
]"
ha/doozerd,"[
  {
    ""bytes"": 1453,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 162957,
    ""name"": ""Go""
  },
  {
    ""bytes"": 3693,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 5340,
    ""name"": ""Shell""
  }
]"
keithwhor/cmnd,"[
  {
    ""bytes"": 5766,
    ""name"": ""JavaScript""
  }
]"
delight-im/OpenSoccer,"[
  {
    ""bytes"": 724,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 63,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 9754,
    ""name"": ""Java""
  },
  {
    ""bytes"": 596,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 1121630,
    ""name"": ""PHP""
  }
]"
mozilla/oneanddone,[]
ravl1084/TJ2PDF,"[
  {
    ""bytes"": 9094,
    ""name"": ""Java""
  }
]"
JuliaDB/MySQL.jl,"[
  {
    ""bytes"": 219575,
    ""name"": ""Julia""
  }
]"
shenxgan/xblog,"[
  {
    ""bytes"": 6051,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 9991,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 14695,
    ""name"": ""Python""
  }
]"
Swader/diffbot-php-client,"[
  {
    ""bytes"": 258473,
    ""name"": ""PHP""
  }
]"
rluders/phaser-skeleton,"[
  {
    ""bytes"": 655,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 861,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 1471,
    ""name"": ""JavaScript""
  },
  {
    ""bytes"": 396,
    ""name"": ""TypeScript""
  }
]"
hosom/bro-file-extraction,"[
  {
    ""bytes"": 7496,
    ""name"": ""Bro""
  }
]"
winunet/Hui,"[
  {
    ""bytes"": 227987,
    ""name"": ""CSS""
  },
  {
    ""bytes"": 2142885,
    ""name"": ""HTML""
  },
  {
    ""bytes"": 354049,
    ""name"": ""JavaScript""
  }
]"
LI-COR/eddypro-engine,"[
  {
    ""bytes"": 303,
    ""name"": ""Batchfile""
  },
  {
    ""bytes"": 1448,
    ""name"": ""C++""
  },
  {
    ""bytes"": 2896251,
    ""name"": ""Fortran""
  },
  {
    ""bytes"": 20475,
    ""name"": ""Makefile""
  },
  {
    ""bytes"": 2320,
    ""name"": ""Pascal""
  },
  {
    ""bytes"": 107,
    ""name"": ""SourcePawn""
  }
]"
blond/hash-set,"[
  {
    ""bytes"": 12343,
    ""name"": ""JavaScript""
  }
]"
rogpeppe/showdeps,"[
  {
    ""bytes"": 10282,
    ""name"": ""Go""
  }
]"
qt-pods/qt-pods,"[
  {
    ""bytes"": 58043,
    ""name"": ""C++""
  },
  {
    ""bytes"": 9639,
    ""name"": ""QMake""
  }
]"
JSSolutions/meteor-google-prediction,"[
  {
    ""bytes"": 3755,
    ""name"": ""JavaScript""
  }
]"
johnham
Query:
SELECT l."repo_name", lang.VALUE::STRING AS "language"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
   LATERAL FLATTEN(input => l."language") lang
   LIMIT 100;
Answer:
Too long, hard cut:
repo_name,language
yyuu/antismoker,"{""bytes"":24665,""name"":""Ruby""}"
yyuu/antismoker,"{""bytes"":164,""name"":""Shell""}"
itakurara/gem_mamezo,"{""bytes"":1994,""name"":""Ruby""}"
itakurara/gem_mamezo,"{""bytes"":115,""name"":""Shell""}"
klriutsa/e_stat,"{""bytes"":3585,""name"":""Ruby""}"
klriutsa/e_stat,"{""bytes"":131,""name"":""Shell""}"
rmcfadzean/jekyll-codepen,"{""bytes"":5232,""name"":""Ruby""}"
rmcfadzean/jekyll-codepen,"{""bytes"":420,""name"":""Shell""}"
kitlangton/pessimist,"{""bytes"":2329,""name"":""Ruby""}"
kitlangton/pessimist,"{""bytes"":115,""name"":""Shell""}"
bjjb/ordu,"{""bytes"":1715,""name"":""Ruby""}"
bjjb/ordu,"{""bytes"":131,""name"":""Shell""}"
sajjadROR/extra_attributes_for_all_migration,"{""bytes"":2578,""name"":""Ruby""}"
sajjadROR/extra_attributes_for_all_migration,"{""bytes"":115,""name"":""Shell""}"
space-pirates-llc/quill-builder,"{""bytes"":14983,""name"":""Ruby""}"
space-pirates-llc/quill-builder,"{""bytes"":131,""name"":""Shell""}"
jt-platterz/slack_messenger,"{""bytes"":7726,""name"":""Ruby""}"
jt-platterz/slack_messenger,"{""bytes"":131,""name"":""Shell""}"
aquinofb/checkout,"{""bytes"":13565,""name"":""Ruby""}"
aquinofb/checkout,"{""bytes"":131,""name"":""Shell""}"
esender/ffaker,"{""bytes"":301045,""name"":""Ruby""}"
esender/ffaker,"{""bytes"":60,""name"":""Shell""}"
harshniketseta/marvels,"{""bytes"":2172,""name"":""Ruby""}"
harshniketseta/marvels,"{""bytes"":115,""name"":""Shell""}"
catalin-enache/ntk_dockerfile,"{""bytes"":192,""name"":""Ruby""}"
catalin-enache/ntk_dockerfile,"{""bytes"":182,""name"":""Shell""}"
chef/knife-linode,"{""bytes"":40951,""name"":""Ruby""}"
chef/knife-linode,"{""bytes"":455,""name"":""Shell""}"
qilab-/vagrant-cdh4.5,"{""bytes"":662,""name"":""Ruby""}"
qilab-/vagrant-cdh4.5,"{""bytes"":1229,""name"":""Shell""}"
carney520/crawler,"{""bytes"":53286,""name"":""Ruby""}"
carney520/crawler,"{""bytes"":115,""name"":""Shell""}"
alu0100789355/prct09,"{""bytes"":21138,""name"":""Ruby""}"
alu0100789355/prct09,"{""bytes"":115,""name"":""Shell""}"
ConPaaS-team/conpaas-docker-images,"{""bytes"":412,""name"":""Ruby""}"
ConPaaS-team/conpaas-docker-images,"{""bytes"":5403,""name"":""Shell""}"
dreamingechoes/bootstrap_sb_admin_base_v2,"{""bytes"":1858,""name"":""Ruby""}"
dreamingechoes/bootstrap_sb_admin_base_v2,"{""bytes"":115,""name"":""Shell""}"
wickles/homebrew-cask,"{""bytes"":2140657,""name"":""Ruby""}"
wickles/homebrew-cask,"{""bytes"":56584,""name"":""Shell""}"
pressable/chef-hipchat-cli,"{""bytes"":5169,""name"":""Ruby""}"
pressable/chef-hipchat-cli,"{""bytes"":2128,""name"":""Shell""}"
gnawhleinad/youtube,"{""bytes"":29,""name"":""Ruby""}"
gnawhleinad/youtube,"{""bytes"":1171,""name"":""Shell""}"
se3000/ruby-eth,"{""bytes"":69565,""name"":""Ruby""}"
se3000/ruby-eth,"{""bytes"":131,""name"":""Shell""}"
jayceeb/remote_syslog2-cookbook,"{""bytes"":3392,""name"":""Ruby""}"
jayceeb/remote_syslog2-cookbook,"{""bytes"":2109,""name"":""Shell""}"
cosmo0920/ansible-playbook-for-keter-deploy,"{""bytes"":3250,""name"":""Ruby""}"
cosmo0920/ansible-playbook-for-keter-deploy,"{""bytes"":316,""name"":""Shell""}"
egjiri/database_syncer,"{""bytes"":3929,""name"":""Ruby""}"
egjiri/database_syncer,"{""bytes"":115,""name"":""Shell""}"
can-explore/geojson_model,"{""bytes"":8272,""name"":""Ruby""}"
can-explore/geojson_model,"{""bytes"":115,""name"":""Shell""}"
yast/yast-storage-ng,"{""bytes"":5753311,""name"":""Ruby""}"
yast/yast-storage-ng,"{""bytes"":2203,""name"":""Shell""}"
alu0100611281/LPP_32_prct09,"{""bytes"":10513,""name"":""Ruby""}"
alu0100611281/LPP_32_prct09,"{""bytes"":115,""name"":""Shell""}"
obsidian-btc/http-commands,"{""bytes"":22977,""name"":""Ruby""}"
obsidian-btc/http-commands,"{""bytes"":2912,""name"":""Shell""}"
guttertec/vagrant-template,"{""bytes"":124,""name"":""Ruby""}"
guttertec/vagrant-template,"{""bytes"":0,""name"":""Shell""}"
altV/interleave,"{""bytes"":2176,""name"":""Ruby""}"
altV/interleave,"{""bytes"":131,""name"":""Shell""}"
phoet/memo-it,"{""bytes"":9556,""name"":""Ruby""}"
phoet/memo-it,"{""bytes"":131,""name"":""Shell""}"
dimko/carrierwave-jpegtran,"{""bytes"":3917,""name"":""Ruby""}"
dimko/carrierwave-jpegtran,"{""bytes"":66,""name"":""Shell""}"
kuldeepaggarwal/arel_extension,"{""bytes"":6601,""name"":""Ruby""}"
kuldeepaggarwal/arel_extension,"{""bytes"":115,""name"":""Shell""}"
nalabjp/mysql_import,"{""bytes"":21440,""name"":""Ruby""}"
nalabjp/mysql_import,"{""bytes"":290,""name"":""Shell""}"
marcojonker/test,"{""bytes"":156103,""name"":""Ruby""}"
marcojonker/test,"{""bytes"":1517,""name"":""Shell""}"
akuzko/parascope,"{""bytes"":24482,""name"":""Ruby""}"
akuzko/parascope,"{""bytes"":131,""name"":""Shell""}"
DivineDominion/zettel-outline-rendering,"{""bytes"":20436,""name"":""Ruby""}"
DivineDominion/zettel-outline-rendering,"{""bytes"":131,""name"":""Shell""}"
cyphactor/octopusci,"{""bytes"":84848,""name"":""Ruby""}"
cyphactor/octopusci,"{""bytes"":915,""name"":""Shell""}"
bogdan14x/d3raw,"{""bytes"":11054,""name"":""Ruby""}
Query:
SELECT "content"
   FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS"
   WHERE "sample_path" = 'README.md' AND "binary" = FALSE AND "content" IS NOT NULL
   LIMIT 100;
Answer:
Too long, hard cut:
content
"oneanddone
==========

One and Done is written with [Django][django].

If you're interested in helping us out, please read through the
[project wiki][wiki] and reach out to us!

About the project:
>Contribute to Mozilla - One task at a time, One day at a time.
>
>One and Done gives users a wide variety of ways to contribute to Mozilla. 
>You can pick an easy task that only takes a few minutes - or take on a 
>bigger challenge. This includes working on manual testing, automation, bug 
>verification, mobile testing and more. Tasks are from a variety of Mozilla teams - so you 
>can get involved with Automation, Firefox OS, Desktop Firefox, Mozilla 
>websites, Services, Thunderbird and more.

[django]: http://www.djangoproject.com/
[wiki]: https://wiki.mozilla.org/QA/OneandDone
[persona]: https://developer.mozilla.org/Persona/The_implementor_s_guide/Testing
[django-browserid]: https://github.com/mozilla/django-browserid


Development Setup
-----------------
These instructions assume you have [git][], [python][], and `pip` installed. If
you don't have `pip` installed, you can install it with `easy_install pip`.


1. Start by getting the source:

   ```sh
   $ git clone git@github.com:mozilla/oneanddone.git
   $ cd oneanddone
   ```
   Note you may want to fork and clone the repo as described in the
   [github docs][git-clone] if you are doing active development.

2. Create a virtualenv for One and Done. Skip the first step if you already have
   `virtualenv` installed.

   ```sh
   $ pip install virtualenv
   $ virtualenv venv
   $ source venv/bin/activate
   ```

3. Set up PostgreSQL locally. The [PostgreSQL Installation Documentation][postgres] explains how to do this.
   

4. Create the initial empty database; make sure it's utf8:
   ``` 
   # Log into the postgres console
   # using your username and password
   $ psql -U your_username
   ```
   In the mysql console:
   ```mysql
   CREATE DATABASE oneanddone;
   \q
   ```
   To run all parts of the application, you will eventually need to populate this empty database with some example data, especially Tasks. There are many ways to populate the database. The method you choose may depend on the kind of data you want to add.
      * Use the create/edit features of your local One and Done instance. For example sign in with an administrator account and go to the `/tasks/create/` URL of the app to create Tasks.
      * Use the Django admin section of your local One and Done instance by going to the `/admin` URL -- this also relies on an admin account. You can define Task Teams here, for example.
      * Use an external tool like PgAdmin.
      * Ask another active developer for a dump of their local database.

5. Install the requirements:
   ```sh
   $ ./bin/peep.py install -r requirements.txt
   ```
   _Note_: On OS X (in particular 10.8.5, Xcode 5.1), you may encounter the following error: `clang: error: unknown argument. '-mno-fused-madd'`. Try running peep with the `ARCHFLAGS` environment variable set, as follows: `ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future ./bin/peep.py install -r requirements/requirements.txt` 

6. Establish your local settings by copying `oneanddone/settings/local.py-dist` to
   `oneanddone/settings/local.py`:

   ```sh
   $ cp oneanddone/settings/local.py-dist oneanddone/settings/local.py
   ```
   
   The default settings in this file should work fine for a local dev environment, but the file
   is commented to describe how it can be customized. For example, if you wish to use `memcached` for caching instead of local memory, 
   you can change the `CACHES` section to read:
   ```python
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
           'LOCATION': '127.0.0.1:11211',
           'TIMEOUT': 600,
       }
   }
   ```
   
7. Establish your local environment by copying `.env-dist` to `.env`:
   ```sh
   $ cp .env-dist .env
   ```

   As above, the default settings in this file should work fine for a local dev environment.

8. Initialize your database structure:
   ```sh
   $ python manage.py migrate
   ```

   Once finished, the `migrate` command should produce a message about which models have been migrated, similar to that shown below.

   ```
   Operations to perform:
     Synchronize unmigrated apps: authtoken, rest_framework, cookies, base, session_csrf
     Apply all migrations: tasks, users, sessions, admin, auth, contenttypes
   Synchronizing apps without migrations:
     Creating tables...
       Creating table authtoken_token
     Installing custom SQL...
     Installing indexes...
   Running migrations:
     Applying contenttypes.0001_initial... OK
     Applying auth.0001_initial... OK
     Applying admin.0001_initial... OK
     Applying sessions.0001_initial... OK
     Applying tasks.0001_initial... OK
     Applying users.0001_initial... OK
   ```

Users
-----

One and Done uses [BrowserID][django-browserid], a.k.a. Mozilla Pe
Query:
SELECT c."sample_repo_name", line.VALUE::STRING AS "line"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md' AND c."binary" = FALSE AND c."content" IS NOT NULL
    LIMIT 100;
Answer:
Too long, hard cut:
sample_repo_name,line
velveteer/mithril-boilerplate,## Mithril Boilerplate
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,This is a quick starter template coupled with NodeJS build tools for projects that want to use Leo Horie's
velveteer/mithril-boilerplate,[Mithril](http://lhorie.github.io/mithril/index.html) framework.
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,Features include:
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,+ Gulpfile and modular tasks via [gulp-starter](https://github.com/greypants/gulp-starter)
velveteer/mithril-boilerplate,+ Bower support -- wire dependencies with [wiredep](https://github.com/taptapship/wiredep)
velveteer/mithril-boilerplate,+ Browserify for CommonJS modules (Mithril is installed from NPM)
velveteer/mithril-boilerplate,+ JSHint and JSCS linting
velveteer/mithril-boilerplate,+ LESS support (easily swapped with your preproc of choice)
velveteer/mithril-boilerplate,+ Connect server with LiveReload
velveteer/mithril-boilerplate,+ Proxy middleware for local/external API calls and mocks using [connect-prism](https://github.com/seglo/connect-prism)
velveteer/mithril-boilerplate,+ Connect middleware for HTML5 pushState fallback (for pathname routes)
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,### Requirements
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,+ NodeJS and NPM
velveteer/mithril-boilerplate,+ Bower (optional)
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,### Install and use
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,`npm install`
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,`gulp watch`
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,Now you should see the example Mithril app at [http://localhost:9000](http://localhost:9000)
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,# Gulp Tasks
velveteer/mithril-boilerplate,
velveteer/mithril-boilerplate,- Run `gulp watch` to get local development started.
velveteer/mithril-boilerplate,- Run `gulp build` to build a distribution.
velveteer/mithril-boilerplate,- Run `gulp wiredep` to add new bower dependencies to your index.html.
velveteer/mithril-boilerplate,
atom/node-ctags,# Ctags Node module [![Build Status](https://travis-ci.org/atom/node-ctags.png)](https://travis-ci.org/atom/node-ctags)
atom/node-ctags,
atom/node-ctags,Read all about ctags [here](http://ctags.sourceforge.net/).
atom/node-ctags,
atom/node-ctags,## Installing
atom/node-ctags,
atom/node-ctags,```sh
atom/node-ctags,npm install ctags
atom/node-ctags,```
atom/node-ctags,
atom/node-ctags,## Building
atom/node-ctags,  * Clone the repository
atom/node-ctags,  * Run `npm install`
atom/node-ctags,  * Run `grunt` to compile the native and CoffeeScript code
atom/node-ctags,  * Run `grunt test` to run the specs
atom/node-ctags,
atom/node-ctags,## Documentation
atom/node-ctags,
atom/node-ctags,"### findTags(tagsFilePath, tag, [options], callback)"
atom/node-ctags,
atom/node-ctags,Get all tags matching the tag specified from the tags file at the path.
atom/node-ctags,
atom/node-ctags,* `tagsFilePath` - The string path to the tags file.
atom/node-ctags,
atom/node-ctags,* `tag` - The string name of the tag to search for.
atom/node-ctags,
atom/node-ctags,* `options` - An optional options object containing the following keys:
atom/node-ctags,
atom/node-ctags,"  * `caseInsensitive` - `true` to include tags that match case insensitively,"
atom/node-ctags,    (default: `false`)
atom/node-ctags,  * `partialMatch` - `true` to include tags that partially match the given tag
atom/node-ctags,    (default: `false`)
atom/node-ctags,
atom/node-ctags,* `callback` - The function to call when complete with an error as the first
atom/node-ctags,             argument and an array containing objects that have `name` and
atom/node-ctags,             `file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,             specified contains tag patterns.
atom/node-ctags,
atom/node-ctags,#### Example
atom/node-ctags,
atom/node-ctags,```coffeescript
atom/node-ctags,ctags = require 'ctags'
atom/node-ctags,
atom/node-ctags,"ctags.findTags('/Users/me/repos/node/tags', 'exists', (error, tags=[]) ->"
atom/node-ctags,  for tag in tags
atom/node-ctags,"    console.log(""#{tag.name} is in #{tag.file}"")"
atom/node-ctags,```
atom/node-ctags,
atom/node-ctags,"### createReadStream(tagsFilePath, [options])"
atom/node-ctags,
atom/node-ctags,Create a read stream to a tags file.
atom/node-ctags,
atom/node-ctags,The stream returned will emit `data` events with arrays of tag objects
atom/node-ctags,that have `name` and `file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,specified contains tag patterns.
atom/node-ctags,
atom/node-ctags,An `error` event will be emitted if the tag file cannot be read.
atom/node-ctags,
atom/node-ctags,An `end` event will be emitted when all the tags have been read.
atom/node-ctags,
atom/node-c
Query:
SELECT c."sample_repo_name", TRIM(line.VALUE::STRING) AS "line"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.VALUE::STRING) != ''
      AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
      AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    LIMIT 100;
Answer:
Too long, hard cut:
sample_repo_name,line
velveteer/mithril-boilerplate,This is a quick starter template coupled with NodeJS build tools for projects that want to use Leo Horie's
velveteer/mithril-boilerplate,[Mithril](http://lhorie.github.io/mithril/index.html) framework.
velveteer/mithril-boilerplate,Features include:
velveteer/mithril-boilerplate,+ Gulpfile and modular tasks via [gulp-starter](https://github.com/greypants/gulp-starter)
velveteer/mithril-boilerplate,+ Bower support -- wire dependencies with [wiredep](https://github.com/taptapship/wiredep)
velveteer/mithril-boilerplate,+ Browserify for CommonJS modules (Mithril is installed from NPM)
velveteer/mithril-boilerplate,+ JSHint and JSCS linting
velveteer/mithril-boilerplate,+ LESS support (easily swapped with your preproc of choice)
velveteer/mithril-boilerplate,+ Connect server with LiveReload
velveteer/mithril-boilerplate,+ Proxy middleware for local/external API calls and mocks using [connect-prism](https://github.com/seglo/connect-prism)
velveteer/mithril-boilerplate,+ Connect middleware for HTML5 pushState fallback (for pathname routes)
velveteer/mithril-boilerplate,+ NodeJS and NPM
velveteer/mithril-boilerplate,+ Bower (optional)
velveteer/mithril-boilerplate,`npm install`
velveteer/mithril-boilerplate,`gulp watch`
velveteer/mithril-boilerplate,Now you should see the example Mithril app at [http://localhost:9000](http://localhost:9000)
velveteer/mithril-boilerplate,- Run `gulp watch` to get local development started.
velveteer/mithril-boilerplate,- Run `gulp build` to build a distribution.
velveteer/mithril-boilerplate,- Run `gulp wiredep` to add new bower dependencies to your index.html.
atom/node-ctags,Read all about ctags [here](http://ctags.sourceforge.net/).
atom/node-ctags,```sh
atom/node-ctags,npm install ctags
atom/node-ctags,```
atom/node-ctags,* Clone the repository
atom/node-ctags,* Run `npm install`
atom/node-ctags,* Run `grunt` to compile the native and CoffeeScript code
atom/node-ctags,* Run `grunt test` to run the specs
atom/node-ctags,Get all tags matching the tag specified from the tags file at the path.
atom/node-ctags,* `tagsFilePath` - The string path to the tags file.
atom/node-ctags,* `tag` - The string name of the tag to search for.
atom/node-ctags,* `options` - An optional options object containing the following keys:
atom/node-ctags,"* `caseInsensitive` - `true` to include tags that match case insensitively,"
atom/node-ctags,(default: `false`)
atom/node-ctags,* `partialMatch` - `true` to include tags that partially match the given tag
atom/node-ctags,(default: `false`)
atom/node-ctags,* `callback` - The function to call when complete with an error as the first
atom/node-ctags,argument and an array containing objects that have `name` and
atom/node-ctags,`file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,specified contains tag patterns.
atom/node-ctags,```coffeescript
atom/node-ctags,ctags = require 'ctags'
atom/node-ctags,"ctags.findTags('/Users/me/repos/node/tags', 'exists', (error, tags=[]) ->"
atom/node-ctags,for tag in tags
atom/node-ctags,"console.log(""#{tag.name} is in #{tag.file}"")"
atom/node-ctags,```
atom/node-ctags,Create a read stream to a tags file.
atom/node-ctags,The stream returned will emit `data` events with arrays of tag objects
atom/node-ctags,that have `name` and `file` keys and optionally a `pattern` key if the tag file
atom/node-ctags,specified contains tag patterns.
atom/node-ctags,An `error` event will be emitted if the tag file cannot be read.
atom/node-ctags,An `end` event will be emitted when all the tags have been read.
atom/node-ctags,* `tagsFilePath` - The string path to the tags file.
atom/node-ctags,* `options` - An optional object containing the following keys.
atom/node-ctags,* `chunkSize` - The number of tags to read at a time (default: `100`).
atom/node-ctags,Returns a stream.
atom/node-ctags,```coffeescript
atom/node-ctags,ctags = require 'ctags'
atom/node-ctags,stream = ctags.createReadStream('/Users/me/repos/node/tags')
atom/node-ctags,"stream.on 'data', (tags) ->"
atom/node-ctags,for tag in tags
atom/node-ctags,"console.log(""#{tag.name} is in #{tag.file} with pattern: #{tag.pattern}"")"
atom/node-ctags,```
bh107/bohrium,Welcome!
bh107/bohrium,========
bh107/bohrium,
bh107/bohrium,[![Build Status](https://travis-ci.org/bh107/bohrium.svg?branch=master)](https://travis-ci.org/bh107/bohrium)
bh107/bohrium,
bh107/bohrium,"Bohrium provides a runtime environment for efficiently executing vectorized applications using your favorourite programming languange Python/NumPy, C#, F# on Linux, Windows and MacOSX."
bh107/bohrium,
bh107/bohrium,"Forget handcrafting CUDA/OpenCL to utilize your GPU, forget threading, mutexes and locks to utilize your multi-core CPU and forget about MPI to program your cluster just Bohrium!"
bh107/bohrium,
bh107/bohrium,Features
bh107/bohrium,--------
bh107/bohrium,|           | Architecture Support                             ||| Frontends     
Query:
SELECT TRIM(line.VALUE::STRING) AS "line", COUNT(*) AS "occurrence"
    FROM "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
    WHERE c."sample_path" = 'README.md'
      AND c."binary" = FALSE
      AND c."content" IS NOT NULL
      AND TRIM(line.VALUE::STRING) != ''
      AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
      AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
    GROUP BY "line"
    ORDER BY "occurrence" DESC
    LIMIT 100;
Answer:
line,occurrence
```,410
},133
,68
```javascript,42
```php,37
{,34
});,33
```bash,31
}),26
```js,26
};,24
```sh,23
```scala,18
*/,18
-------------,15
<?php,13
*,12
);,12
/**,12
package com.massivedatascience.clusterer,11
?>,10
```ruby,10
```java,10
```html,10
<hr>,10
============,9
</tr>,9
<tr>,9
========,9
License,8
Image dimensions: 333 x 500,8
$diffbot = new Diffbot('my_token');,8
Author: s_molinari,7
<br />,7
return {,7
"},",7
</a>,7
"ops: BregmanPointOps,",7
``` bash,7
-------,7
* @param ops distance function,7
```,7
```shell,6
```gdscript,6
-----------------,6
<br>,6
public:,6
...,6
==================,6
</td>,6
```rust,6
object KMeans {,6
"<td width=""50%"">",6
Author: swader,6
end,6
---,6
```c++,6
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the,5
```julia,5
=======,5
sb*n*/,5
"console.log(""Service is reporting MUTE=["" +",5
----------,5
* @return  k-means model,5
.build();,5
".identifyAs(""oauth"")",5
but WITHOUT ANY WARRANTY; without even the implied warranty of,5
Example:,5
-----,5
),5
Consultant consultant = Consultant.builder(),5
--------,5
------------,5
"""]"");",5
end,4
var cache = new SuperCache({ttl: 60});,4
```properties,4
```lisp,4
"InstanceId: 0,",4
SB_MODULE(/*a description should go here*/),4
],4
*****,4
==========,4
* @param seed random number seed,4
</p>,4
Installation,4
var Component = require('brindille-component');,4
MainObject(),4
"k: Int,",4
"pointOps: BregmanPointOps,",4
```objc,4
</dependency>,4
"<p align=""center"">",4
Examples:,4
Usage,4
* *extract function*,4
.then( function( response ) {,4
"upnpService.action('GetMute', {",4
``` java,4
<dependency>,4
Query:
JOIN "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l
  ON line_repo."sample_repo_name" = l."repo_name"
LATERAL FLATTEN(input => l."language") lang
Answer:
001003 (42000): 01ba593c-0004-9c22-0001-11c301106856: SQL compilation error:
syntax error line 1 at position 0 unexpected 'JOIN'.Query:
SELECT
  line_repo."line",
  COUNT(*) AS "occurrence",
  ARRAY_AGG(DISTINCT lang_flat."language" ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) line_repo
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON line_repo."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  line_repo."line"
ORDER BY
  "occurrence" DESC
LIMIT 100;
Answer:
001003 (42000): 01ba593e-0004-9c22-0001-11c301106e6e: SQL compilation error:
syntax error line 4 at position 42 unexpected 'ORDER'.
syntax error line 4 at position 30 unexpected '.'.Query:
ARRAY_AGG(DISTINCT <expression>) WITHIN GROUP (ORDER BY <expression>)
Answer:
001003 (42000): 01ba5940-0004-9c12-0001-11c30110908e: SQL compilation error:
syntax error line 1 at position 0 unexpected 'ARRAY_AGG'.End Exploring Related Columns
Task: Retrieve all non-empty, non-commented lines from `README.md` files in GitHub repositories, excluding lines that are comments (either starting with `#` for Markdown or `//` for code comments). For each line, calculate how often each unique line appears across all repositories and return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically, with the results ordered by the frequency of occurrence in descending order.

Please answer only one complete SQL in snowflake dialect in ```sql``` format.
Usage example: ```sql
SELECT "COLUMN_NAME" FROM DATABASE.SCHEMA.TABLE WHERE ... ``` (Adjust "DATABASE", "SCHEMA", and "TABLE" to match actual names, ensure all column names are enclosed in double quotations)
Follow the answer format like: The non-empty, non-commented lines from `README.md` files, their occurrence across repositories, and the programming languages used in those repositories are presented below:

```csv
Line,Occurrence,Languages
line1:str,count1:int,language1_1:str,language1_2:str,...
line2:str,count2:int,language2_1:str,language2_2:str,...
...
```

*Note*: The results are ordered by the frequency of occurrence in descending order..
Here are some useful tips for answering:
When performing a UNION operation on many tables, ensure that all table names are explicitly listed. Union first and then add condition and selection. e.g. SELECT "col1", "col2" FROM (TABLE1 UNION ALL TABLE2) WHERE ...; Don't write sqls as (SELECT col1, col2 FROM TABLE1 WHERE ...) UNION ALL (SELECT col1, col2 FROM TABLE2 WHERE ...); Don't use ['-- Include all', '-- Omit', '-- Continue', '-- Union all', '-- ...', '-- List all', '-- Replace this', '-- Each table', '-- Add other'] to omit any table. Table names here: The table structure information is ({database name: {schema name: [table name]}}): 
{'GITHUB_REPOS': {'GITHUB_REPOS': ['SAMPLE_FILES', 'LANGUAGES', 'LICENSES', 'SAMPLE_COMMITS', 'SAMPLE_CONTENTS', 'SAMPLE_REPOS']}}

For string-matching scenarios, if the string is decided, don't use fuzzy query, and avoid using REGEXP. e.g. Get the object's title contains the word "book"
However, if the string is not decided, you may use fuzzy query and ignore upper or lower case. e.g. Get articles that mention "education".
When using ORDER BY xxx DESC, add NULLS LAST to exclude null records: ORDER BY xxx DESC NULLS LAST.
When using ORDER BY, if there are duplicate values in the primary sort column, sort by an additional column as a secondary criterion.If the task description does not specify the number of decimal places, retain all decimals to four places.
Be careful of information in nested columns. e.g. When it comes to completed purchase, `hits.eCommerceAction.action_type` Indicates the type of ecommerce action and '6' represents completed purchases.
Be careful one country may have different country_name and country_region in different columns in a database.
Don't be misled by examples. For instance, a question related to Android development on StackOverflow might include tags like 'android-layout,' 'android-activity,' or 'android-intent.' However, you should not limit your analysis to just these three tags; instead, consider all tags related to Android: "tags" LIKE '%android%'.

2025-02-12 18:41:38 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:41:38 - root - INFO - ```sql
SELECT
  lr."line",
  COUNT(*) AS "occurrence",
  ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) lr
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE:"name"::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON lr."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  lr."line"
ORDER BY
  "occurrence" DESC NULLS LAST, lr."line"
LIMIT 100;
```
2025-02-12 18:41:38 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:41:38 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:41:38 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:41:39 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:41:39 - snowflake.connector.connection - INFO - closed
2025-02-12 18:41:40 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:41:40 - root - INFO - itercount: 1
2025-02-12 18:41:40 - root - INFO - 0
2025-02-12 18:41:40 - root - INFO - results: 
line,occurrence,languages
```,835,"[
  ""API Blueprint"",
  ""ApacheConf"",
  ""Assembly"",
  ""Awk"",
  ""Batchfile"",
  ""Brainfuck"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CMake"",
  ""CSS"",
  ""CoffeeScript"",
  ""Dockerfile"",
  ""Elixir"",
  ""Emacs Lisp"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Lex"",
  ""Lua"",
  ""M4"",
  ""Makefile"",
  ""NSIS"",
  ""Nix"",
  ""Objective-C"",
  ""PHP"",
  ""Perl"",
  ""Python"",
  ""QML"",
  ""QMake"",
  ""Raku"",
  ""Roff"",
  ""Ruby"",
  ""Rust"",
  ""Scala"",
  ""Shell"",
  ""Swift"",
  ""TypeScript"",
  ""Vim script"",
  ""sed""
]"
},195,"[
  ""ApacheConf"",
  ""Batchfile"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CMake"",
  ""Elixir"",
  ""Emacs Lisp"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""M4"",
  ""Makefile"",
  ""Nix"",
  ""Objective-C"",
  ""PHP"",
  ""Python"",
  ""Ruby"",
  ""Rust"",
  ""Scala"",
  ""Shell"",
  ""TypeScript""
]"

,152,"[
  ""C"",
  ""C++"",
  ""CMake"",
  ""CSS"",
  ""Dockerfile"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Julia"",
  ""Makefile"",
  ""Python"",
  ""Shell"",
  ""Smarty""
]"
{,102,"[
  ""ApacheConf"",
  ""Batchfile"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CMake"",
  ""Emacs Lisp"",
  ""HTML"",
  ""JavaScript"",
  ""Makefile"",
  ""PHP"",
  ""Python"",
  ""Ruby"",
  ""Rust"",
  ""Shell""
]"
```php,84,"[
  ""ApacheConf"",
  ""C++"",
  ""HTML"",
  ""JavaScript"",
  ""M4"",
  ""Nix"",
  ""PHP"",
  ""Shell""
]"
```bash,79,"[
  ""Batchfile"",
  ""C"",
  ""CSS"",
  ""Dockerfile"",
  ""Elixir"",
  ""HTML"",
  ""JavaScript"",
  ""Makefile"",
  ""NSIS"",
  ""PHP"",
  ""Python"",
  ""QML"",
  ""Rust"",
  ""Shell"",
  ""TypeScript""
]"
```javascript,78,"[
  ""HTML"",
  ""JavaScript"",
  ""Shell"",
  ""TypeScript""
]"
});,68,"[
  ""HTML"",
  ""JavaScript"",
  ""Rust"",
  ""Shell""
]"
<?php,51,"[
  ""ApacheConf"",
  ""C++"",
  ""HTML"",
  ""JavaScript"",
  ""M4"",
  ""Nix"",
  ""PHP"",
  ""Shell""
]"
};,45,"[
  ""C"",
  ""C++"",
  ""CMake"",
  ""HTML"",
  ""JavaScript"",
  ""Rust"",
  ""Shell"",
  ""TypeScript""
]"
``` bash,43,"[
  ""Batchfile"",
  ""C#"",
  ""C++"",
  ""Emacs Lisp"",
  ""JavaScript"",
  ""Python"",
  ""Shell""
]"
?>,37,"[
  ""ApacheConf"",
  ""HTML"",
  ""JavaScript"",
  ""PHP""
]"
</tr>,36,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
<tr>,36,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
);,33,"[
  ""ApacheConf"",
  ""C"",
  ""C++"",
  ""CMake"",
  ""HTML"",
  ""JavaScript"",
  ""M4"",
  ""Nix"",
  ""PHP"",
  ""Shell""
]"
=========,29,"[
  ""Assembly"",
  ""Awk"",
  ""Batchfile"",
  ""Brainfuck"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CSS"",
  ""CoffeeScript"",
  ""Emacs Lisp"",
  ""HTML"",
  ""JavaScript"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
</a>,25,"[
  ""CSS"",
  ""HTML"",
  ""PHP"",
  ""Python"",
  ""Shell""
]"
</td>,24,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
"<td width=""50%"">",24,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
}),24,"[
  ""C"",
  ""C++"",
  ""CMake"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Rust"",
  ""Shell""
]"
==========,23,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""CSS"",
  ""CoffeeScript"",
  ""HTML"",
  ""JavaScript"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Rust"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
<br />,22,"[
  ""C"",
  ""C++"",
  ""CSS"",
  ""HTML"",
  ""JavaScript"",
  ""Python""
]"
============,21,"[
  ""CSS"",
  ""CoffeeScript"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Makefile"",
  ""Objective-C"",
  ""PHP"",
  ""Python"",
  ""Ruby"",
  ""Rust"",
  ""Shell""
]"
to,21,"[
  ""API Blueprint"",
  ""Batchfile"",
  ""Dockerfile"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Shell""
]"
- any *nix OS of your choice,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- cURL,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- drush (>= 5.x),20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- nginx,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php (>= 5.5),20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php-ssh2,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php5-curl,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php5-fpm,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php5-mcrypt,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
---,20,"[
  ""Batchfile"",
  ""C"",
  ""C++"",
  ""Fortran"",
  ""GLSL"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Makefile"",
  ""Pascal"",
  ""Shell"",
  ""SourcePawn"",
  ""TypeScript""
]"
<hr>,20,"[
  ""C"",
  ""C++""
]"
"After making sure you have all the dependencies configured in your system, PECE can be installed like any other Drupal 7 site.",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"All the software code written for PECE is released under the GNU GPL version 3. Access our [legal documents for more information](http://pece.readthedocs.io/en/docs/legal.html). All the documentation for the project is released under CC-BY-SA 4.0 International, unless stated otherwise.",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"Create an empty database and make sure to [configure the directory/file permissions before continuing](https://www.drupal.org/node/244924). Then, proceed with the regular install by accessing /install.php preceded by the URL of your new site (i.e. '''yoursite.org/install.php'''). Alternatively, you can use Drush for your own convenience instead of using the web interface:",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"Even though these are not hard dependencies, we highly recommend running your PECE site with following set-up for better security and performance:",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"First, you need to obtain the installation package:",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"Go grab a cup of coffee or tea, since the installation process might take up to 30 minutes to complete dependending on your server backend. For detailed information on the installation process, please check our [official documentation](http://pece.readthedocs.io/en/docs/installation.html).",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"If you have general questions about the platform, please refer to our [official documentation](http://pece.readthedocs.io/en/docs).",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"In addition to the [basic Drupal system requirements](https://www.drupal.org/requirements), you will need these extra libraries:",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
Our official documentation contains the information on authorship for the design and implementation of the platform. Please check the document [PECE Team](http://pece.readthedocs.io/en/docs/team.html) for more information.,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"PECE is a Free and Open Source (Drupal-based) digital platform that supports multi-sited, cross-scale ethnographic and historical research. PECE is built as a Drupal distribution, therefore it can be extended like any other Drupal project.",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
There are many ways of contributing to the PECE project. One of them is by reporting bugs or requesting features through Github in our [development repository](https://github.com/PECE-project/drupal-pece). Read our [contributors' guide](http://pece.readthedocs.io/en/docs/contributors.html) for more information about how to contribute code and bug fixes.,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"This repository holds the packaged distribution for PECE adopters. It contains the most updated version of PECE for public use. If you are an end-user who wants to run PECE for your research, this is the right place to get your copy. If you are a developer wishing to contribute to the development process, you must use the [development repository](https://github.com/PECE-project/drupal-pece) instead.",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
```$ sudo drush si pece --account-name=admin --account-pass=YOUR_ADMIN_PASS --db-url=mysql://YOUR_DB_USER:YOUR_DB_USER_PASSWD@locahost/YOUR_DB --notify```,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
```$ wget https://github.com/PECE-project/pece-distro/archive/v1.0.tar.gz && tar zxvf v1.0.tar.gz && rm v1.0.tar.gz```,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
```sh,20,"[
  ""C"",
  ""C++"",
  ""CSS"",
  ""CoffeeScript"",
  ""HTML"",
  ""JavaScript"",
  ""Python"",
  ""TypeScript""
]"
*/,19,"[
  ""HTML"",
  ""JavaScript"",
  ""PHP"",
  ""Scala""
]"
----------,18,"[
  ""Batchfile"",
  ""C#"",
  ""C++"",
  ""Emacs Lisp"",
  ""Go"",
  ""Haskell"",
  ""Java"",
  ""JavaScript"",
  ""Protocol Buffer"",
  ""Python"",
  ""Shell"",
  ""Swift""
]"
<br>
,18,"[
  ""C"",
  ""C++"",
  ""Makefile""
]"
License,18,"[
  ""Batchfile"",
  ""C#"",
  ""C++"",
  ""CSS"",
  ""CoffeeScript"",
  ""Emacs Lisp"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Makefile"",
  ""Python"",
  ""Shell""
]"
```c++,18,"[
  ""C"",
  ""C++"",
  ""CMake""
]"
```scala,18,"[
  ""Scala""
]"
public:,18,"[
  ""C"",
  ""C++"",
  ""CMake""
]"
--------,17,"[
  ""Batchfile"",
  ""C"",
  ""C#"",
  ""C++"",
  ""Emacs Lisp"",
  ""Go"",
  ""Java"",
  ""JavaScript"",
  ""Python"",
  ""Shell""
]"
-------------,17,"[
  ""Bro"",
  ""Groovy"",
  ""Java"",
  ""JavaScript"",
  ""PHP"",
  ""Ruby""
]"
```html,17,"[
  ""ApacheConf"",
  ""HTML"",
  ""JavaScript"",
  ""PHP"",
  ""Shell"",
  ""TypeScript""
]"
=================================,16,"[
  ""Assembly"",
  ""C"",
  ""C++"",
  ""Objective-C""
]"
"* asmjs -- Convert to the ""asm.js"" dialect of javascript",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* awk	-- Code for (almost) any version of AWK.,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"* bash -- GNU bash, uses arrays, arithimetic etc. (NO external programs or subshells used)",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* basic -- A couple of very random BASIC interpreters.,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"* bf -- Ook, Blub, fuck fuck, ""there once was a fish named Fred"" and similar transliterations. Also includes Cell doubler (and quad) mappings. Some can be compiled as C (most are *deoptimised* but -rle is not.) The optimiser can still run so this can be used as a BF->BF optimiser. For BF->BF optimisation best results are got with -Obf.",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* cgmp -- C using the Gnu MP library. This uses a linked list so the pointer movements are slower.,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* clojure -- Not a very nice conversion though. *no-opt*,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* cmd -- Windows batch files ... far too slow for testing *no-opt*,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"* crun -- Convert to C and run using libtcc or libdl. TCC quicker than bf2run ... just, GCC is a lot quicker, even without GCC doing any optimisation.",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* d -- The C replacement originally by 'Digital Mars',15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"* dc -- The unix command, has a -r (run) option that uses a special filter to allow character input. This is too complex for dc.sed.",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* elf -- Direct production of a 32bit Linux executable. *no-opt*,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"* gas -- x64 or x86 assembler. Use gcc to assemble and link: ""gcc -o bfp bfout.s"" *no-opt*",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* go -- Google's modern language,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"* jit -- OTOH this one uses LuaJIT's Dynasm, it's the fastest bf2any program.",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* julia -- [A modern language using LLVM](http://julialang.org),15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* lua,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* navision -- Now called Microsoft DynamicsNAV,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* neko -- [Neko programming language VM](http://nekovm.org),15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* pascal -- Free pascal.,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* perl,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* php,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* ps1 -- That's right MS Powershell,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* python,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* rc -- The Plan9 shell rc(1) (Can't input without external programs.) -- *deoptimised*,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* ruby,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* run -- a direct interpreter -- blisteringly quick too for one without JIT.,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* s-lang,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"* sh -- Bourne shell without bash extensions, not Unix v7 but later should be fine.",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* tcl,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
* v7sh -- Bourne shell from Unix v7. -- *deoptimised*,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
1 []><[][]><[][]><[][]><[][]><[][]><[][]><[][]><[][]><[][]><[],15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"1. The BF program ""bitwidth.b""; this is something of a torture test, if your interpreter correctly executes this anything else is likely to be dead easy.",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
2 []>+>+>++>++<[>[->++++<<+++>]<<]>----.>->+.+++++++..+++.<+[],15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
2. VIM Syntax highlighting file for brainfuck.,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
"3 [ This is hellbox, a 104 command Hello World               ]",15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
3. Tritium (officially ) this BF interpreter/compiler/JIT runner makes other programs look slow. It is simply the fastest BF interpreter you'll find.,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
4 [   >+>+>++>++<[>[->++++<<+++>]<<]>----.>>+.+++++++..+++   ],15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
4. Brainfuck to anything. Well not exactly anything but the list includes ...,15,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"


2025-02-12 18:41:40 - root - INFO - Please check the answer again by reviewing Retrieve all non-empty, non-commented lines from `README.md` files in GitHub repositories, excluding lines that are comments (either starting with `#` for Markdown or `//` for code comments). For each line, calculate how often each unique line appears across all repositories and return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically, with the results ordered by the frequency of occurrence in descending order., reviewing Relevant Tables and Columns and Possible Conditions and then give the final SQL query. Don't output other queries. If you think the answer is right, just output the current SQL.
If the task description does not specify the number of decimal places, retain all decimals to four places.
The answer format should be like: The non-empty, non-commented lines from `README.md` files, their occurrence across repositories, and the programming languages used in those repositories are presented below:

```csv
Line,Occurrence,Languages
line1:str,count1:int,language1_1:str,language1_2:str,...
line2:str,count2:int,language2_1:str,language2_2:str,...
...
```

*Note*: The results are ordered by the frequency of occurrence in descending order. The answer should match the number of rows, the column name of the format and the filled values in the format (e.g. filled year or month). Don't output extra rows or nested rows!
Current snswer: 
Too long, hard cut:
line,occurrence,languages
```,835,"[
  ""API Blueprint"",
  ""ApacheConf"",
  ""Assembly"",
  ""Awk"",
  ""Batchfile"",
  ""Brainfuck"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CMake"",
  ""CSS"",
  ""CoffeeScript"",
  ""Dockerfile"",
  ""Elixir"",
  ""Emacs Lisp"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Lex"",
  ""Lua"",
  ""M4"",
  ""Makefile"",
  ""NSIS"",
  ""Nix"",
  ""Objective-C"",
  ""PHP"",
  ""Perl"",
  ""Python"",
  ""QML"",
  ""QMake"",
  ""Raku"",
  ""Roff"",
  ""Ruby"",
  ""Rust"",
  ""Scala"",
  ""Shell"",
  ""Swift"",
  ""TypeScript"",
  ""Vim script"",
  ""sed""
]"
},195,"[
  ""ApacheConf"",
  ""Batchfile"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CMake"",
  ""Elixir"",
  ""Emacs Lisp"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""M4"",
  ""Makefile"",
  ""Nix"",
  ""Objective-C"",
  ""PHP"",
  ""Python"",
  ""Ruby"",
  ""Rust"",
  ""Scala"",
  ""Shell"",
  ""TypeScript""
]"

,152,"[
  ""C"",
  ""C++"",
  ""CMake"",
  ""CSS"",
  ""Dockerfile"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Julia"",
  ""Makefile"",
  ""Python"",
  ""Shell"",
  ""Smarty""
]"
{,102,"[
  ""ApacheConf"",
  ""Batchfile"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CMake"",
  ""Emacs Lisp"",
  ""HTML"",
  ""JavaScript"",
  ""Makefile"",
  ""PHP"",
  ""Python"",
  ""Ruby"",
  ""Rust"",
  ""Shell""
]"
```php,84,"[
  ""ApacheConf"",
  ""C++"",
  ""HTML"",
  ""JavaScript"",
  ""M4"",
  ""Nix"",
  ""PHP"",
  ""Shell""
]"
```bash,79,"[
  ""Batchfile"",
  ""C"",
  ""CSS"",
  ""Dockerfile"",
  ""Elixir"",
  ""HTML"",
  ""JavaScript"",
  ""Makefile"",
  ""NSIS"",
  ""PHP"",
  ""Python"",
  ""QML"",
  ""Rust"",
  ""Shell"",
  ""TypeScript""
]"
```javascript,78,"[
  ""HTML"",
  ""JavaScript"",
  ""Shell"",
  ""TypeScript""
]"
});,68,"[
  ""HTML"",
  ""JavaScript"",
  ""Rust"",
  ""Shell""
]"
<?php,51,"[
  ""ApacheConf"",
  ""C++"",
  ""HTML"",
  ""JavaScript"",
  ""M4"",
  ""Nix"",
  ""PHP"",
  ""Shell""
]"
};,45,"[
  ""C"",
  ""C++"",
  ""CMake"",
  ""HTML"",
  ""JavaScript"",
  ""Rust"",
  ""Shell"",
  ""TypeScript""
]"
``` bash,43,"[
  ""Batchfile"",
  ""C#"",
  ""C++"",
  ""Emacs Lisp"",
  ""JavaScript"",
  ""Python"",
  ""Shell""
]"
?>,37,"[
  ""ApacheConf"",
  ""HTML"",
  ""JavaScript"",
  ""PHP""
]"
</tr>,36,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
<tr>,36,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
);,33,"[
  ""ApacheConf"",
  ""C"",
  ""C++"",
  ""CMake"",
  ""HTML"",
  ""JavaScript"",
  ""M4"",
  ""Nix"",
  ""PHP"",
  ""Shell""
]"
=========,29,"[
  ""Assembly"",
  ""Awk"",
  ""Batchfile"",
  ""Brainfuck"",
  ""C"",
  ""C#"",
  ""C++"",
  ""CSS"",
  ""CoffeeScript"",
  ""Emacs Lisp"",
  ""HTML"",
  ""JavaScript"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
</a>,25,"[
  ""CSS"",
  ""HTML"",
  ""PHP"",
  ""Python"",
  ""Shell""
]"
</td>,24,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
"<td width=""50%"">",24,"[
  ""CSS"",
  ""HTML"",
  ""Python"",
  ""Shell""
]"
}),24,"[
  ""C"",
  ""C++"",
  ""CMake"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Rust"",
  ""Shell""
]"
==========,23,"[
  ""Assembly"",
  ""Awk"",
  ""Brainfuck"",
  ""C"",
  ""C++"",
  ""CSS"",
  ""CoffeeScript"",
  ""HTML"",
  ""JavaScript"",
  ""Lex"",
  ""Lua"",
  ""Makefile"",
  ""Perl"",
  ""Python"",
  ""Raku"",
  ""Ruby"",
  ""Rust"",
  ""Shell"",
  ""Vim script"",
  ""sed""
]"
<br />,22,"[
  ""C"",
  ""C++"",
  ""CSS"",
  ""HTML"",
  ""JavaScript"",
  ""Python""
]"
============,21,"[
  ""CSS"",
  ""CoffeeScript"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Makefile"",
  ""Objective-C"",
  ""PHP"",
  ""Python"",
  ""Ruby"",
  ""Rust"",
  ""Shell""
]"
to,21,"[
  ""API Blueprint"",
  ""Batchfile"",
  ""Dockerfile"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Shell""
]"
- any *nix OS of your choice,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- cURL,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- drush (>= 5.x),20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- nginx,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php (>= 5.5),20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php-ssh2,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php5-curl,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php5-fpm,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
- php5-mcrypt,20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
---,20,"[
  ""Batchfile"",
  ""C"",
  ""C++"",
  ""Fortran"",
  ""GLSL"",
  ""HTML"",
  ""Java"",
  ""JavaScript"",
  ""Makefile"",
  ""Pascal"",
  ""Shell"",
  ""SourcePawn"",
  ""TypeScript""
]"
<hr>,20,"[
  ""C"",
  ""C++""
]"
"After making sure you have all the dependencies configured in your system, PECE can be installed like any other Drupal 7 site.",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"All the software code written for PECE is released under the GNU GPL version 3. Access our [legal documents for more information](http://pece.readthedocs.io/en/docs/legal.html). All the documentation for the project is released under CC-BY-SA 4.0 International, unless stated otherwise.",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"Create an empty database and make sure to [configure the directory/file permissions before continuing](https://www.drupal.org/node/244924). Then, proceed with the regular install by accessing /install.php preceded by the URL of your new site (i.e. '''yoursite.org/install.php'''). Alternatively, you can use Drush for your own convenience instead of using the web interface:",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"Even though these are not hard dependencies, we highly recommend running your PECE site with following set-up for better security and performance:",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"First, you need to obtain the installation package:",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"Go grab a cup of coffee or tea, since the installation process might take up to 30 minutes to complete dependending on your server backend. For detailed information on the installation process, please check our [official documentation](http://pece.readthedocs.io/en/docs/installation.html).",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""TeX"",
  ""mIRC Script""
]"
"If you have general questions about the platform, please refer to our [official documentation](http://pece.readthedocs.io/en/docs).",20,"[
  ""CSS"",
  ""CoffeeScript"",
  ""Gherkin"",
  ""HTML"",
  ""Hack"",
  ""Java"",
  ""JavaScript"",
  ""Less"",
  ""Makefile"",
  ""NASL"",
  ""PHP"",
  ""Pug"",
  ""Python"",
  ""Ruby"",
  ""SCSS"",
  ""Sass"",
  ""Shell"",
  ""Smarty"",
  ""Te
Current sql:
SELECT
  lr."line",
  COUNT(*) AS "occurrence",
  ARRAY_AGG(DISTINCT lang_flat."language") WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) lr
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE:"name"::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON lr."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  lr."line"
ORDER BY
  "occurrence" DESC NULLS LAST, lr."line"
LIMIT 100;For tasks asking fullname or name, you should combine first name and last name into one column called name. Format: ```csv
name
name:str```
Values ['[\n  "API Blueprint",\n  "ApacheConf",\n  "Assembly",\n  "Awk",\n  "Batchfile",\n  "Brainfuck",\n  "C",\n  "C#",\n  "C++",\n  "CMake",\n  "CSS",\n  "CoffeeScript",\n  "Dockerfile",\n  "Elixir",\n  "Emacs Lisp",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "Lex",\n  "Lua",\n  "M4",\n  "Makefile",\n  "NSIS",\n  "Nix",\n  "Objective-C",\n  "PHP",\n  "Perl",\n  "Python",\n  "QML",\n  "QMake",\n  "Raku",\n  "Roff",\n  "Ruby",\n  "Rust",\n  "Scala",\n  "Shell",\n  "Swift",\n  "TypeScript",\n  "Vim script",\n  "sed"\n]', '[\n  "ApacheConf",\n  "Batchfile",\n  "C",\n  "C#",\n  "C++",\n  "CMake",\n  "Elixir",\n  "Emacs Lisp",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "M4",\n  "Makefile",\n  "Nix",\n  "Objective-C",\n  "PHP",\n  "Python",\n  "Ruby",\n  "Rust",\n  "Scala",\n  "Shell",\n  "TypeScript"\n]', '[\n  "C",\n  "C++",\n  "CMake",\n  "CSS",\n  "Dockerfile",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "Julia",\n  "Makefile",\n  "Python",\n  "Shell",\n  "Smarty"\n]', '[\n  "ApacheConf",\n  "Batchfile",\n  "C",\n  "C#",\n  "C++",\n  "CMake",\n  "Emacs Lisp",\n  "HTML",\n  "JavaScript",\n  "Makefile",\n  "PHP",\n  "Python",\n  "Ruby",\n  "Rust",\n  "Shell"\n]', '[\n  "ApacheConf",\n  "C++",\n  "HTML",\n  "JavaScript",\n  "M4",\n  "Nix",\n  "PHP",\n  "Shell"\n]', '[\n  "Batchfile",\n  "C",\n  "CSS",\n  "Dockerfile",\n  "Elixir",\n  "HTML",\n  "JavaScript",\n  "Makefile",\n  "NSIS",\n  "PHP",\n  "Python",\n  "QML",\n  "Rust",\n  "Shell",\n  "TypeScript"\n]', '[\n  "HTML",\n  "JavaScript",\n  "Shell",\n  "TypeScript"\n]', '[\n  "HTML",\n  "JavaScript",\n  "Rust",\n  "Shell"\n]', '[\n  "ApacheConf",\n  "C++",\n  "HTML",\n  "JavaScript",\n  "M4",\n  "Nix",\n  "PHP",\n  "Shell"\n]', '[\n  "C",\n  "C++",\n  "CMake",\n  "HTML",\n  "JavaScript",\n  "Rust",\n  "Shell",\n  "TypeScript"\n]', '[\n  "Batchfile",\n  "C#",\n  "C++",\n  "Emacs Lisp",\n  "JavaScript",\n  "Python",\n  "Shell"\n]', '[\n  "ApacheConf",\n  "HTML",\n  "JavaScript",\n  "PHP"\n]', '[\n  "CSS",\n  "HTML",\n  "Python",\n  "Shell"\n]', '[\n  "CSS",\n  "HTML",\n  "Python",\n  "Shell"\n]', '[\n  "ApacheConf",\n  "C",\n  "C++",\n  "CMake",\n  "HTML",\n  "JavaScript",\n  "M4",\n  "Nix",\n  "PHP",\n  "Shell"\n]', '[\n  "Assembly",\n  "Awk",\n  "Batchfile",\n  "Brainfuck",\n  "C",\n  "C#",\n  "C++",\n  "CSS",\n  "CoffeeScript",\n  "Emacs Lisp",\n  "HTML",\n  "JavaScript",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "CSS",\n  "HTML",\n  "PHP",\n  "Python",\n  "Shell"\n]', '[\n  "CSS",\n  "HTML",\n  "Python",\n  "Shell"\n]', '[\n  "CSS",\n  "HTML",\n  "Python",\n  "Shell"\n]', '[\n  "C",\n  "C++",\n  "CMake",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "Rust",\n  "Shell"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "CSS",\n  "CoffeeScript",\n  "HTML",\n  "JavaScript",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Rust",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "C",\n  "C++",\n  "CSS",\n  "HTML",\n  "JavaScript",\n  "Python"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "Makefile",\n  "Objective-C",\n  "PHP",\n  "Python",\n  "Ruby",\n  "Rust",\n  "Shell"\n]', '[\n  "API Blueprint",\n  "Batchfile",\n  "Dockerfile",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "Shell"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "Batchfile",\n  "C",\n  "C++",\n  "Fortran",\n  "GLSL",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "Makefile",\n  "Pascal",\n  "Shell",\n  "SourcePawn",\n  "TypeScript"\n]', '[\n  "C",\n  "C++"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "CSS",\n  "CoffeeScript",\n  "Gherkin",\n  "HTML",\n  "Hack",\n  "Java",\n  "JavaScript",\n  "Less",\n  "Makefile",\n  "NASL",\n  "PHP",\n  "Pug",\n  "Python",\n  "Ruby",\n  "SCSS",\n  "Sass",\n  "Shell",\n  "Smarty",\n  "TeX",\n  "mIRC Script"\n]', '[\n  "C",\n  "C++",\n  "CSS",\n  "CoffeeScript",\n  "HTML",\n  "JavaScript",\n  "Python",\n  "TypeScript"\n]', '[\n  "HTML",\n  "JavaScript",\n  "PHP",\n  "Scala"\n]', '[\n  "Batchfile",\n  "C#",\n  "C++",\n  "Emacs Lisp",\n  "Go",\n  "Haskell",\n  "Java",\n  "JavaScript",\n  "Protocol Buffer",\n  "Python",\n  "Shell",\n  "Swift"\n]', '[\n  "C",\n  "C++",\n  "Makefile"\n]', '[\n  "Batchfile",\n  "C#",\n  "C++",\n  "CSS",\n  "CoffeeScript",\n  "Emacs Lisp",\n  "HTML",\n  "Java",\n  "JavaScript",\n  "Makefile",\n  "Python",\n  "Shell"\n]', '[\n  "C",\n  "C++",\n  "CMake"\n]', '[\n  "Scala"\n]', '[\n  "C",\n  "C++",\n  "CMake"\n]', '[\n  "Batchfile",\n  "C",\n  "C#",\n  "C++",\n  "Emacs Lisp",\n  "Go",\n  "Java",\n  "JavaScript",\n  "Python",\n  "Shell"\n]', '[\n  "Bro",\n  "Groovy",\n  "Java",\n  "JavaScript",\n  "PHP",\n  "Ruby"\n]', '[\n  "ApacheConf",\n  "HTML",\n  "JavaScript",\n  "PHP",\n  "Shell",\n  "TypeScript"\n]', '[\n  "Assembly",\n  "C",\n  "C++",\n  "Objective-C"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]', '[\n  "Assembly",\n  "Awk",\n  "Brainfuck",\n  "C",\n  "C++",\n  "Lex",\n  "Lua",\n  "Makefile",\n  "Perl",\n  "Python",\n  "Raku",\n  "Ruby",\n  "Shell",\n  "Vim script",\n  "sed"\n]'] are nested. Please correct them. e.g. Transfer '[
A,
 B
]' to 'A, B'.

2025-02-12 18:42:04 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:42:04 - root - INFO - ```sql
SELECT
  lr."line",
  COUNT(*) AS "occurrence",
  LISTAGG(DISTINCT lang_flat."language", ', ') WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) lr
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE:"name"::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON lr."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  lr."line"
ORDER BY
  "occurrence" DESC NULLS LAST, lr."line"
LIMIT 100;
```
2025-02-12 18:42:04 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:42:04 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:42:04 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:42:05 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:42:05 - snowflake.connector.connection - INFO - closed
2025-02-12 18:42:05 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:42:05 - root - INFO - itercount: 2
2025-02-12 18:42:05 - root - INFO - 0
2025-02-12 18:42:05 - root - INFO - results: 
line,occurrence,languages
```,835,"API Blueprint, ApacheConf, Assembly, Awk, Batchfile, Brainfuck, C, C#, C++, CMake, CSS, CoffeeScript, Dockerfile, Elixir, Emacs Lisp, HTML, Java, JavaScript, Lex, Lua, M4, Makefile, NSIS, Nix, Objective-C, PHP, Perl, Python, QML, QMake, Raku, Roff, Ruby, Rust, Scala, Shell, Swift, TypeScript, Vim script, sed"
},195,"ApacheConf, Batchfile, C, C#, C++, CMake, Elixir, Emacs Lisp, HTML, Java, JavaScript, M4, Makefile, Nix, Objective-C, PHP, Python, Ruby, Rust, Scala, Shell, TypeScript"

,152,"C, C++, CMake, CSS, Dockerfile, HTML, Java, JavaScript, Julia, Makefile, Python, Shell, Smarty"
{,102,"ApacheConf, Batchfile, C, C#, C++, CMake, Emacs Lisp, HTML, JavaScript, Makefile, PHP, Python, Ruby, Rust, Shell"
```php,84,"ApacheConf, C++, HTML, JavaScript, M4, Nix, PHP, Shell"
```bash,79,"Batchfile, C, CSS, Dockerfile, Elixir, HTML, JavaScript, Makefile, NSIS, PHP, Python, QML, Rust, Shell, TypeScript"
```javascript,78,"HTML, JavaScript, Shell, TypeScript"
});,68,"HTML, JavaScript, Rust, Shell"
<?php,51,"ApacheConf, C++, HTML, JavaScript, M4, Nix, PHP, Shell"
};,45,"C, C++, CMake, HTML, JavaScript, Rust, Shell, TypeScript"
``` bash,43,"Batchfile, C#, C++, Emacs Lisp, JavaScript, Python, Shell"
?>,37,"ApacheConf, HTML, JavaScript, PHP"
</tr>,36,"CSS, HTML, Python, Shell"
<tr>,36,"CSS, HTML, Python, Shell"
);,33,"ApacheConf, C, C++, CMake, HTML, JavaScript, M4, Nix, PHP, Shell"
=========,29,"Assembly, Awk, Batchfile, Brainfuck, C, C#, C++, CSS, CoffeeScript, Emacs Lisp, HTML, JavaScript, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
</a>,25,"CSS, HTML, PHP, Python, Shell"
</td>,24,"CSS, HTML, Python, Shell"
"<td width=""50%"">",24,"CSS, HTML, Python, Shell"
}),24,"C, C++, CMake, HTML, Java, JavaScript, Rust, Shell"
==========,23,"Assembly, Awk, Brainfuck, C, C++, CSS, CoffeeScript, HTML, JavaScript, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Rust, Shell, Vim script, sed"
<br />,22,"C, C++, CSS, HTML, JavaScript, Python"
============,21,"CSS, CoffeeScript, HTML, Java, JavaScript, Makefile, Objective-C, PHP, Python, Ruby, Rust, Shell"
to,21,"API Blueprint, Batchfile, Dockerfile, HTML, Java, JavaScript, Shell"
- any *nix OS of your choice,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- cURL,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- drush (>= 5.x),20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- nginx,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php (>= 5.5),20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php-ssh2,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php5-curl,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php5-fpm,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php5-mcrypt,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
---,20,"Batchfile, C, C++, Fortran, GLSL, HTML, Java, JavaScript, Makefile, Pascal, Shell, SourcePawn, TypeScript"
<hr>,20,"C, C++"
"After making sure you have all the dependencies configured in your system, PECE can be installed like any other Drupal 7 site.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"All the software code written for PECE is released under the GNU GPL version 3. Access our [legal documents for more information](http://pece.readthedocs.io/en/docs/legal.html). All the documentation for the project is released under CC-BY-SA 4.0 International, unless stated otherwise.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"Create an empty database and make sure to [configure the directory/file permissions before continuing](https://www.drupal.org/node/244924). Then, proceed with the regular install by accessing /install.php preceded by the URL of your new site (i.e. '''yoursite.org/install.php'''). Alternatively, you can use Drush for your own convenience instead of using the web interface:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"Even though these are not hard dependencies, we highly recommend running your PECE site with following set-up for better security and performance:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"First, you need to obtain the installation package:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"Go grab a cup of coffee or tea, since the installation process might take up to 30 minutes to complete dependending on your server backend. For detailed information on the installation process, please check our [official documentation](http://pece.readthedocs.io/en/docs/installation.html).",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"If you have general questions about the platform, please refer to our [official documentation](http://pece.readthedocs.io/en/docs).",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"In addition to the [basic Drupal system requirements](https://www.drupal.org/requirements), you will need these extra libraries:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
Our official documentation contains the information on authorship for the design and implementation of the platform. Please check the document [PECE Team](http://pece.readthedocs.io/en/docs/team.html) for more information.,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"PECE is a Free and Open Source (Drupal-based) digital platform that supports multi-sited, cross-scale ethnographic and historical research. PECE is built as a Drupal distribution, therefore it can be extended like any other Drupal project.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
There are many ways of contributing to the PECE project. One of them is by reporting bugs or requesting features through Github in our [development repository](https://github.com/PECE-project/drupal-pece). Read our [contributors' guide](http://pece.readthedocs.io/en/docs/contributors.html) for more information about how to contribute code and bug fixes.,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"This repository holds the packaged distribution for PECE adopters. It contains the most updated version of PECE for public use. If you are an end-user who wants to run PECE for your research, this is the right place to get your copy. If you are a developer wishing to contribute to the development process, you must use the [development repository](https://github.com/PECE-project/drupal-pece) instead.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
```$ sudo drush si pece --account-name=admin --account-pass=YOUR_ADMIN_PASS --db-url=mysql://YOUR_DB_USER:YOUR_DB_USER_PASSWD@locahost/YOUR_DB --notify```,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
```$ wget https://github.com/PECE-project/pece-distro/archive/v1.0.tar.gz && tar zxvf v1.0.tar.gz && rm v1.0.tar.gz```,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
```sh,20,"C, C++, CSS, CoffeeScript, HTML, JavaScript, Python, TypeScript"
*/,19,"HTML, JavaScript, PHP, Scala"
----------,18,"Batchfile, C#, C++, Emacs Lisp, Go, Haskell, Java, JavaScript, Protocol Buffer, Python, Shell, Swift"
<br>
,18,"C, C++, Makefile"
License,18,"Batchfile, C#, C++, CSS, CoffeeScript, Emacs Lisp, HTML, Java, JavaScript, Makefile, Python, Shell"
```c++,18,"C, C++, CMake"
```scala,18,Scala
public:,18,"C, C++, CMake"
--------,17,"Batchfile, C, C#, C++, Emacs Lisp, Go, Java, JavaScript, Python, Shell"
-------------,17,"Bro, Groovy, Java, JavaScript, PHP, Ruby"
```html,17,"ApacheConf, HTML, JavaScript, PHP, Shell, TypeScript"
=================================,16,"Assembly, C, C++, Objective-C"
"* asmjs -- Convert to the ""asm.js"" dialect of javascript",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* awk	-- Code for (almost) any version of AWK.,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"* bash -- GNU bash, uses arrays, arithimetic etc. (NO external programs or subshells used)",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* basic -- A couple of very random BASIC interpreters.,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"* bf -- Ook, Blub, fuck fuck, ""there once was a fish named Fred"" and similar transliterations. Also includes Cell doubler (and quad) mappings. Some can be compiled as C (most are *deoptimised* but -rle is not.) The optimiser can still run so this can be used as a BF->BF optimiser. For BF->BF optimisation best results are got with -Obf.",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* cgmp -- C using the Gnu MP library. This uses a linked list so the pointer movements are slower.,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* clojure -- Not a very nice conversion though. *no-opt*,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* cmd -- Windows batch files ... far too slow for testing *no-opt*,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"* crun -- Convert to C and run using libtcc or libdl. TCC quicker than bf2run ... just, GCC is a lot quicker, even without GCC doing any optimisation.",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* d -- The C replacement originally by 'Digital Mars',15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"* dc -- The unix command, has a -r (run) option that uses a special filter to allow character input. This is too complex for dc.sed.",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* elf -- Direct production of a 32bit Linux executable. *no-opt*,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"* gas -- x64 or x86 assembler. Use gcc to assemble and link: ""gcc -o bfp bfout.s"" *no-opt*",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* go -- Google's modern language,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"* jit -- OTOH this one uses LuaJIT's Dynasm, it's the fastest bf2any program.",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* julia -- [A modern language using LLVM](http://julialang.org),15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* lua,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* navision -- Now called Microsoft DynamicsNAV,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* neko -- [Neko programming language VM](http://nekovm.org),15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* pascal -- Free pascal.,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* perl,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* php,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* ps1 -- That's right MS Powershell,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* python,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* rc -- The Plan9 shell rc(1) (Can't input without external programs.) -- *deoptimised*,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* ruby,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* run -- a direct interpreter -- blisteringly quick too for one without JIT.,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* s-lang,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"* sh -- Bourne shell without bash extensions, not Unix v7 but later should be fine.",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* tcl,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* v7sh -- Bourne shell from Unix v7. -- *deoptimised*,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
1 []><[][]><[][]><[][]><[][]><[][]><[][]><[][]><[][]><[][]><[],15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"1. The BF program ""bitwidth.b""; this is something of a torture test, if your interpreter correctly executes this anything else is likely to be dead easy.",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
2 []>+>+>++>++<[>[->++++<<+++>]<<]>----.>->+.+++++++..+++.<+[],15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
2. VIM Syntax highlighting file for brainfuck.,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
"3 [ This is hellbox, a 104 command Hello World               ]",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
3. Tritium (officially ) this BF interpreter/compiler/JIT runner makes other programs look slow. It is simply the fastest BF interpreter you'll find.,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
4 [   >+>+>++>++<[>[->++++<<+++>]<<]>----.>>+.+++++++..+++   ],15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
4. Brainfuck to anything. Well not exactly anything but the list includes ...,15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"


2025-02-12 18:42:05 - root - INFO - Please check the answer again by reviewing Retrieve all non-empty, non-commented lines from `README.md` files in GitHub repositories, excluding lines that are comments (either starting with `#` for Markdown or `//` for code comments). For each line, calculate how often each unique line appears across all repositories and return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically, with the results ordered by the frequency of occurrence in descending order., reviewing Relevant Tables and Columns and Possible Conditions and then give the final SQL query. Don't output other queries. If you think the answer is right, just output the current SQL.
If the task description does not specify the number of decimal places, retain all decimals to four places.
The answer format should be like: The non-empty, non-commented lines from `README.md` files, their occurrence across repositories, and the programming languages used in those repositories are presented below:

```csv
Line,Occurrence,Languages
line1:str,count1:int,language1_1:str,language1_2:str,...
line2:str,count2:int,language2_1:str,language2_2:str,...
...
```

*Note*: The results are ordered by the frequency of occurrence in descending order. The answer should match the number of rows, the column name of the format and the filled values in the format (e.g. filled year or month). Don't output extra rows or nested rows!
Current snswer: 
Too long, hard cut:
line,occurrence,languages
```,835,"API Blueprint, ApacheConf, Assembly, Awk, Batchfile, Brainfuck, C, C#, C++, CMake, CSS, CoffeeScript, Dockerfile, Elixir, Emacs Lisp, HTML, Java, JavaScript, Lex, Lua, M4, Makefile, NSIS, Nix, Objective-C, PHP, Perl, Python, QML, QMake, Raku, Roff, Ruby, Rust, Scala, Shell, Swift, TypeScript, Vim script, sed"
},195,"ApacheConf, Batchfile, C, C#, C++, CMake, Elixir, Emacs Lisp, HTML, Java, JavaScript, M4, Makefile, Nix, Objective-C, PHP, Python, Ruby, Rust, Scala, Shell, TypeScript"

,152,"C, C++, CMake, CSS, Dockerfile, HTML, Java, JavaScript, Julia, Makefile, Python, Shell, Smarty"
{,102,"ApacheConf, Batchfile, C, C#, C++, CMake, Emacs Lisp, HTML, JavaScript, Makefile, PHP, Python, Ruby, Rust, Shell"
```php,84,"ApacheConf, C++, HTML, JavaScript, M4, Nix, PHP, Shell"
```bash,79,"Batchfile, C, CSS, Dockerfile, Elixir, HTML, JavaScript, Makefile, NSIS, PHP, Python, QML, Rust, Shell, TypeScript"
```javascript,78,"HTML, JavaScript, Shell, TypeScript"
});,68,"HTML, JavaScript, Rust, Shell"
<?php,51,"ApacheConf, C++, HTML, JavaScript, M4, Nix, PHP, Shell"
};,45,"C, C++, CMake, HTML, JavaScript, Rust, Shell, TypeScript"
``` bash,43,"Batchfile, C#, C++, Emacs Lisp, JavaScript, Python, Shell"
?>,37,"ApacheConf, HTML, JavaScript, PHP"
</tr>,36,"CSS, HTML, Python, Shell"
<tr>,36,"CSS, HTML, Python, Shell"
);,33,"ApacheConf, C, C++, CMake, HTML, JavaScript, M4, Nix, PHP, Shell"
=========,29,"Assembly, Awk, Batchfile, Brainfuck, C, C#, C++, CSS, CoffeeScript, Emacs Lisp, HTML, JavaScript, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
</a>,25,"CSS, HTML, PHP, Python, Shell"
</td>,24,"CSS, HTML, Python, Shell"
"<td width=""50%"">",24,"CSS, HTML, Python, Shell"
}),24,"C, C++, CMake, HTML, Java, JavaScript, Rust, Shell"
==========,23,"Assembly, Awk, Brainfuck, C, C++, CSS, CoffeeScript, HTML, JavaScript, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Rust, Shell, Vim script, sed"
<br />,22,"C, C++, CSS, HTML, JavaScript, Python"
============,21,"CSS, CoffeeScript, HTML, Java, JavaScript, Makefile, Objective-C, PHP, Python, Ruby, Rust, Shell"
to,21,"API Blueprint, Batchfile, Dockerfile, HTML, Java, JavaScript, Shell"
- any *nix OS of your choice,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- cURL,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- drush (>= 5.x),20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- nginx,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php (>= 5.5),20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php-ssh2,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php5-curl,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php5-fpm,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
- php5-mcrypt,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
---,20,"Batchfile, C, C++, Fortran, GLSL, HTML, Java, JavaScript, Makefile, Pascal, Shell, SourcePawn, TypeScript"
<hr>,20,"C, C++"
"After making sure you have all the dependencies configured in your system, PECE can be installed like any other Drupal 7 site.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"All the software code written for PECE is released under the GNU GPL version 3. Access our [legal documents for more information](http://pece.readthedocs.io/en/docs/legal.html). All the documentation for the project is released under CC-BY-SA 4.0 International, unless stated otherwise.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"Create an empty database and make sure to [configure the directory/file permissions before continuing](https://www.drupal.org/node/244924). Then, proceed with the regular install by accessing /install.php preceded by the URL of your new site (i.e. '''yoursite.org/install.php'''). Alternatively, you can use Drush for your own convenience instead of using the web interface:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"Even though these are not hard dependencies, we highly recommend running your PECE site with following set-up for better security and performance:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"First, you need to obtain the installation package:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"Go grab a cup of coffee or tea, since the installation process might take up to 30 minutes to complete dependending on your server backend. For detailed information on the installation process, please check our [official documentation](http://pece.readthedocs.io/en/docs/installation.html).",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"If you have general questions about the platform, please refer to our [official documentation](http://pece.readthedocs.io/en/docs).",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"In addition to the [basic Drupal system requirements](https://www.drupal.org/requirements), you will need these extra libraries:",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
Our official documentation contains the information on authorship for the design and implementation of the platform. Please check the document [PECE Team](http://pece.readthedocs.io/en/docs/team.html) for more information.,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"PECE is a Free and Open Source (Drupal-based) digital platform that supports multi-sited, cross-scale ethnographic and historical research. PECE is built as a Drupal distribution, therefore it can be extended like any other Drupal project.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
There are many ways of contributing to the PECE project. One of them is by reporting bugs or requesting features through Github in our [development repository](https://github.com/PECE-project/drupal-pece). Read our [contributors' guide](http://pece.readthedocs.io/en/docs/contributors.html) for more information about how to contribute code and bug fixes.,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
"This repository holds the packaged distribution for PECE adopters. It contains the most updated version of PECE for public use. If you are an end-user who wants to run PECE for your research, this is the right place to get your copy. If you are a developer wishing to contribute to the development process, you must use the [development repository](https://github.com/PECE-project/drupal-pece) instead.",20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
```$ sudo drush si pece --account-name=admin --account-pass=YOUR_ADMIN_PASS --db-url=mysql://YOUR_DB_USER:YOUR_DB_USER_PASSWD@locahost/YOUR_DB --notify```,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
```$ wget https://github.com/PECE-project/pece-distro/archive/v1.0.tar.gz && tar zxvf v1.0.tar.gz && rm v1.0.tar.gz```,20,"CSS, CoffeeScript, Gherkin, HTML, Hack, Java, JavaScript, Less, Makefile, NASL, PHP, Pug, Python, Ruby, SCSS, Sass, Shell, Smarty, TeX, mIRC Script"
```sh,20,"C, C++, CSS, CoffeeScript, HTML, JavaScript, Python, TypeScript"
*/,19,"HTML, JavaScript, PHP, Scala"
----------,18,"Batchfile, C#, C++, Emacs Lisp, Go, Haskell, Java, JavaScript, Protocol Buffer, Python, Shell, Swift"
<br>
,18,"C, C++, Makefile"
License,18,"Batchfile, C#, C++, CSS, CoffeeScript, Emacs Lisp, HTML, Java, JavaScript, Makefile, Python, Shell"
```c++,18,"C, C++, CMake"
```scala,18,Scala
public:,18,"C, C++, CMake"
--------,17,"Batchfile, C, C#, C++, Emacs Lisp, Go, Java, JavaScript, Python, Shell"
-------------,17,"Bro, Groovy, Java, JavaScript, PHP, Ruby"
```html,17,"ApacheConf, HTML, JavaScript, PHP, Shell, TypeScript"
=================================,16,"Assembly, C, C++, Objective-C"
"* asmjs -- Convert to the ""asm.js"" dialect of javascript",15,"Assembly, Awk, Brainfuck, C, C++, Lex, Lua, Makefile, Perl, Python, Raku, Ruby, Shell, Vim script, sed"
* awk	-- Code for (almost) any version of AWK.,15,"Assembly, Awk, Brainfuck, C, C++, 
Current sql:
SELECT
  lr."line",
  COUNT(*) AS "occurrence",
  LISTAGG(DISTINCT lang_flat."language", ', ') WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) lr
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE:"name"::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON lr."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  lr."line"
ORDER BY
  "occurrence" DESC NULLS LAST, lr."line"
LIMIT 100;For tasks asking fullname or name, you should combine first name and last name into one column called name. Format: ```csv
name
name:str```

2025-02-12 18:42:37 - httpx - INFO - HTTP Request: POST https://sfc-ml-sweden.openai.azure.com//openai/deployments/o1-preview/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-02-12 18:42:37 - root - INFO - ```sql
SELECT
  lr."line",
  COUNT(*) AS "occurrence",
  LISTAGG(DISTINCT lang_flat."language", ', ') WITHIN GROUP (ORDER BY lang_flat."language") AS "languages"
FROM (
  SELECT
    c."sample_repo_name",
    TRIM(line.VALUE::STRING) AS "line"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."SAMPLE_CONTENTS" c,
    LATERAL FLATTEN(input => SPLIT(c."content", '\n')) line
  WHERE
    c."sample_path" = 'README.md'
    AND c."binary" = FALSE
    AND c."content" IS NOT NULL
    AND TRIM(line.VALUE::STRING) != ''
    AND NOT TRIM(line.VALUE::STRING) LIKE '#%'
    AND NOT TRIM(line.VALUE::STRING) LIKE '//%'
) lr
JOIN (
  SELECT
    l."repo_name",
    lang.VALUE:"name"::STRING AS "language"
  FROM
    "GITHUB_REPOS"."GITHUB_REPOS"."LANGUAGES" l,
    LATERAL FLATTEN(input => l."language") lang
) lang_flat
  ON lr."sample_repo_name" = lang_flat."repo_name"
GROUP BY
  lr."line"
ORDER BY
  "occurrence" DESC NULLS LAST, lr."line"
LIMIT 100;
```
2025-02-12 18:42:37 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.16, Platform: Linux-6.5.0-45-generic-x86_64-with-glibc2.35
2025-02-12 18:42:37 - snowflake.connector.connection - INFO - Connecting to GLOBAL Snowflake domain
2025-02-12 18:42:37 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-02-12 18:42:38 - snowflake.connector.cursor - INFO - Number of results in first chunk: 100
2025-02-12 18:42:38 - snowflake.connector.connection - INFO - closed
2025-02-12 18:42:38 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
2025-02-12 18:42:38 - root - INFO - itercount: 3
2025-02-12 18:42:38 - root - INFO - 0
2025-02-12 18:42:38 - root - INFO - Total iteration counts: 3
